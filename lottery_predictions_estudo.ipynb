{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brito90/Projetos-Kauan-Engenharia/blob/main/lottery_predictions_estudo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ Modelos CNN Otimizados para Predi√ß√£o de Loterias\n",
        "\n",
        "## üìù Resumo das Vers√µes\n",
        "\n",
        "Este notebook cont√©m **duas vers√µes** de cada modelo:\n",
        "\n",
        "1. **Vers√£o Original** (c√©lulas anteriores) - Com problemas identificados\n",
        "2. **Vers√£o Otimizada** (c√©lulas abaixo) - Com todas as corre√ß√µes implementadas\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Melhorias Implementadas\n",
        "\n",
        "### **LOTOF√ÅCIL - Vers√£o Otimizada**\n",
        "\n",
        "#### ‚ùå Problemas da Vers√£o Original:\n",
        "- **Loss explosivo** (cresceu de 59.76 para 27.900+)\n",
        "- **Acur√°cia muito baixa** (0.28%)\n",
        "- **Early stopping prematuro** (parou na √©poca 16 de 100)\n",
        "- Data augmentation com window criava depend√™ncias artificiais\n",
        "- Softmax for√ßava distribui√ß√£o probabil√≠stica incorreta\n",
        "\n",
        "#### ‚úÖ Corre√ß√µes Aplicadas:\n",
        "\n",
        "1. **Removido Data Augmentation (window)**\n",
        "   - Antes: Usava janelas de 15 sorteios anteriores\n",
        "   - Agora: Cada sorteio √© independente\n",
        "   - Resultado: Reduz overfitting e ru√≠do\n",
        "\n",
        "2. **Trocado `softmax` por `sigmoid`**\n",
        "   - Antes: `Dense(25, activation='softmax')` - for√ßa soma = 1\n",
        "   - Agora: `Dense(25, activation='sigmoid')` - cada n√∫mero independente\n",
        "   - Resultado: Multi-label ao inv√©s de multi-class\n",
        "\n",
        "3. **Trocado `categorical_crossentropy` por `binary_crossentropy`**\n",
        "   - Compatibiliza com sigmoid\n",
        "   - Melhor para problema multi-label\n",
        "\n",
        "4. **Gradient Clipping adicionado**\n",
        "   ```python\n",
        "   optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
        "   ```\n",
        "   - Evita explos√£o de gradientes\n",
        "   - Estabiliza treinamento\n",
        "\n",
        "5. **Learning Rate reduzido**\n",
        "   - Antes: 0.001 (padr√£o Adam)\n",
        "   - Agora: 0.0001\n",
        "   - Resultado: Converg√™ncia mais suave\n",
        "\n",
        "6. **Paci√™ncia aumentada**\n",
        "   - Early Stopping: 15 ‚Üí 25 √©pocas\n",
        "   - ReduceLROnPlateau: 5 ‚Üí 10 √©pocas\n",
        "   - Resultado: Mais tempo para convergir\n",
        "\n",
        "---\n",
        "\n",
        "### **SUPER SETE - Vers√£o Otimizada**\n",
        "\n",
        "#### üìä Performance Original:\n",
        "- Acur√°cia: 14.94%\n",
        "- Resultado com repeti√ß√µes: [6, 6, 8, 1, 9, 6, 4]\n",
        "- Treinou as 100 √©pocas completas\n",
        "\n",
        "#### ‚úÖ Melhorias Aplicadas:\n",
        "\n",
        "1. **Gradient Clipping**\n",
        "   ```python\n",
        "   optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
        "   ```\n",
        "\n",
        "2. **Callbacks Otimizados**\n",
        "   - Early Stopping patience: 20\n",
        "   - ReduceLR patience: 8\n",
        "   - Min LR: 1e-7\n",
        "\n",
        "3. **An√°lise por Coluna (NOVO!)**\n",
        "   - Mostra acur√°cia individual de cada uma das 7 colunas\n",
        "   - Identifica quais colunas o modelo prediz melhor\n",
        "   - √ötil para diagn√≥stico\n",
        "\n",
        "4. **Mais Informa√ß√µes de Diagn√≥stico**\n",
        "   - Total de sorteios carregados\n",
        "   - Shape dos dados em cada etapa\n",
        "   - Loss final de treino e valida√ß√£o\n",
        "   - N√∫mero de √©pocas treinadas\n",
        "\n",
        "---\n",
        "\n",
        "## üìà Resultados Esperados\n",
        "\n",
        "### Lotof√°cil - Vers√£o Otimizada:\n",
        "- ‚úÖ Loss **N√ÉO deve explodir** (deve diminuir gradualmente)\n",
        "- ‚úÖ Treinamento deve ser **mais est√°vel**\n",
        "- ‚úÖ Deve treinar **mais √©pocas** (25-50+)\n",
        "- ‚ö†Ô∏è Acur√°cia ainda ser√° baixa (natureza aleat√≥ria)\n",
        "\n",
        "### Super Sete - Vers√£o Otimizada:\n",
        "- ‚úÖ Converg√™ncia mais **suave**\n",
        "- ‚úÖ An√°lise por coluna permite **insights**\n",
        "- ‚úÖ Melhor **estabilidade** no treinamento\n",
        "- ‚ö†Ô∏è Acur√°cia ainda limitada (eventos aleat√≥rios)\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö†Ô∏è Aviso Importante\n",
        "\n",
        "> **Loterias s√£o eventos estatisticamente independentes e aleat√≥rios.**\n",
        ">\n",
        "> Estes modelos s√£o **exerc√≠cios de Deep Learning** e demonstram:\n",
        "> - T√©cnicas de CNN para dados sequenciais\n",
        "> - Debugging de problemas de treinamento\n",
        "> - Otimiza√ß√£o de hiperpar√¢metros\n",
        ">\n",
        "> **N√ÉO devem ser usados para apostas reais.**\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Como Usar\n",
        "\n",
        "1. **Execute primeiro as c√©lulas de dados** (upload dos arquivos Excel)\n",
        "2. **Execute a vers√£o otimizada** que deseja testar:\n",
        "   - C√©lula \"LOTOF√ÅCIL - VERS√ÉO OTIMIZADA\"\n",
        "   - C√©lula \"SUPER SETE - VERS√ÉO OTIMIZADA\"\n",
        "3. **Observe os resultados**:\n",
        "   - Loss n√£o deve explodir\n",
        "   - Acur√°cia deve ser est√°vel (mesmo que baixa)\n",
        "   - Treinamento deve completar mais √©pocas\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Compara√ß√£o R√°pida\n",
        "\n",
        "| Aspecto | Original | Otimizado |\n",
        "|---------|----------|----------|\n",
        "| **Learning Rate** | 0.001 | 0.0001 |\n",
        "| **Loss Function** | categorical_crossentropy | binary_crossentropy |\n",
        "| **Activation** | softmax | sigmoid |\n",
        "| **Gradient Clip** | ‚ùå N√£o | ‚úÖ clipnorm=1.0 |\n",
        "| **Data Aug (Lotof√°cil)** | Window=15 | ‚ùå Removido |\n",
        "| **Early Stop Patience** | 15 | 25 |\n",
        "| **Diagn√≥stico** | B√°sico | ‚úÖ Avan√ßado |\n",
        "\n",
        "---\n",
        "\n",
        "**Criado em:** 10/11/2025  \n",
        "**Vers√£o:** 2.0 - Otimizada"
      ],
      "metadata": {
        "id": "serzJtXc2Zil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# LOTOF√ÅCIL - VERS√ÉO OTIMIZADA E CORRIGIDA\n",
        "# ============================================================\n",
        "# Melhorias implementadas:\n",
        "# 1. Removido Data Augmentation (window) - usa sorteios independentes\n",
        "# 2. Trocado softmax por sigmoid (multi-label)\n",
        "# 3. Trocado categorical_crossentropy por binary_crossentropy\n",
        "# 4. Adicionado gradient clipping para evitar explos√£o\n",
        "# 5. Reduzido learning rate (0.0001 ao inv√©s de 0.001)\n",
        "# 6. Aumentado paci√™ncia do EarlyStopping\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Carregamento do arquivo\n",
        "df = pd.read_excel('Lotof√°cil.xlsx')\n",
        "\n",
        "# 2. Extra√ß√£o das 15 bolas sorteadas\n",
        "bola_cols = [col for col in df.columns if 'Bola' in col][:15]\n",
        "numeros = df[bola_cols].astype(int)\n",
        "print(f\"Total de sorteios carregados: {len(numeros)}\")\n",
        "print(numeros.head())\n",
        "\n",
        "# 3. Fun√ß√£o one-hot (sem mudan√ßas)\n",
        "def one_hot_lotus(row):\n",
        "    v = np.zeros(25)\n",
        "    for n in row:\n",
        "        if 1 <= n <= 25:\n",
        "            v[int(n)-1] = 1\n",
        "    return v\n",
        "\n",
        "# 4. CORRE√á√ÉO: Sem data augmentation - usa sorteios diretos\n",
        "X = np.array([one_hot_lotus(r) for r in numeros.values[:-1]])  # Entrada: sorteios anteriores\n",
        "y = np.array([one_hot_lotus(r) for r in numeros.values[1:]])   # Sa√≠da: pr√≥ximo sorteio\n",
        "\n",
        "print(f\"\\nShape dos dados:\")\n",
        "print(f\"X (entrada): {X.shape}\")\n",
        "print(f\"y (sa√≠da): {y.shape}\")\n",
        "\n",
        "# 5. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
        "X_train = X_train.reshape(-1, 25, 1)\n",
        "X_test = X_test.reshape(-1, 25, 1)\n",
        "\n",
        "print(f\"\\nDados de treino: {X_train.shape}\")\n",
        "print(f\"Dados de teste: {X_test.shape}\")\n",
        "\n",
        "# 6. Arquitetura CNN Otimizada\n",
        "model = Sequential([\n",
        "    # Primeira camada convolucional\n",
        "    Conv1D(128, 3, activation='relu', padding='same', input_shape=(25,1)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Segunda camada convolucional\n",
        "    Conv1D(256, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Terceira camada convolucional\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    # Camadas densas\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    BatchNormalization(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # CORRE√á√ÉO: Sigmoid ao inv√©s de Softmax para multi-label\n",
        "    Dense(25, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 7. CORRE√á√ÉO: Otimizador com learning rate reduzido e gradient clipping\n",
        "optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
        "\n",
        "# 8. Callbacks ajustados\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=25,  # Aumentado de 15 para 25\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=10,  # Aumentado de 5 para 10\n",
        "    min_lr=1e-7,  # Reduzido de 1e-5 para 1e-7\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "# 9. CORRE√á√ÉO: Binary crossentropy ao inv√©s de categorical\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INICIANDO TREINAMENTO - VERS√ÉO OTIMIZADA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 10. Treinamento\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 11. Previs√£o\n",
        "last_data = X_test[-1].reshape(1, 25, 1)\n",
        "pred = model.predict(last_data).flatten()\n",
        "proximos_numeros = np.argsort(pred)[-15:] + 1\n",
        "proximos_numeros_formatados = [int(x) for x in np.sort(proximos_numeros)]\n",
        "\n",
        "# 12. Avalia√ß√£o\n",
        "history_metrics = model.evaluate(X_test, y_test, verbose=0)\n",
        "accuracy = history_metrics[1] * 100\n",
        "\n",
        "# 13. Exibir resultados\n",
        "print('\\n' + '='*60)\n",
        "print('PREVIS√ÉO LOTOF√ÅCIL - PR√ìXIMO SORTEIO (VERS√ÉO OTIMIZADA)')\n",
        "print('='*60)\n",
        "print(f'N√∫meros previstos: {proximos_numeros_formatados}')\n",
        "print(f'Acur√°cia do modelo: {accuracy:.2f}%')\n",
        "print(f'√âpocas treinadas: {len(history.history[\"loss\"])}')\n",
        "print(f'Loss final (treino): {history.history[\"loss\"][-1]:.4f}')\n",
        "print(f'Loss final (valida√ß√£o): {history.history[\"val_loss\"][-1]:.4f}')\n",
        "print('='*60)\n",
        "print(\"\\n‚ö†Ô∏è  NOTA: Loterias s√£o eventos aleat√≥rios.\")\n",
        "print(\"Este modelo √© apenas um exerc√≠cio de Deep Learning.\")\n",
        "print(\"N√£o use para apostas reais.\")\n",
        "print('='*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmMFLS_D1eqK",
        "outputId": "a93b0ea9-6799-4fc8-b8cc-bfa1015a44dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de sorteios carregados: 3540\n",
            "   Bola1  Bola2  Bola3  Bola4  Bola5  Bola6  Bola7  Bola8  Bola9  Bola10  \\\n",
            "0      2      3      5      6      9     10     11     13     14      16   \n",
            "1      1      4      5      6      7      9     11     12     13      15   \n",
            "2      1      4      6      7      8      9     10     11     12      14   \n",
            "3      1      2      4      5      8     10     12     13     16      17   \n",
            "4      1      2      4      8      9     11     12     13     15      16   \n",
            "\n",
            "   Bola11  Bola12  Bola13  Bola14  Bola15  \n",
            "0      18      20      23      24      25  \n",
            "1      16      19      20      23      24  \n",
            "2      16      17      20      23      24  \n",
            "3      18      19      23      24      25  \n",
            "4      19      20      23      24      25  \n",
            "\n",
            "Shape dos dados:\n",
            "X (entrada): (3539, 25)\n",
            "y (sa√≠da): (3539, 25)\n",
            "\n",
            "Dados de treino: (3185, 25, 1)\n",
            "Dados de teste: (354, 25, 1)\n",
            "\n",
            "============================================================\n",
            "INICIANDO TREINAMENTO - VERS√ÉO OTIMIZADA\n",
            "============================================================\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 102ms/step - accuracy: 0.0264 - loss: 0.8553 - val_accuracy: 0.0000e+00 - val_loss: 0.6907 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0218 - loss: 0.8021 - val_accuracy: 0.0000e+00 - val_loss: 0.6911 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0287 - loss: 0.7952 - val_accuracy: 0.0000e+00 - val_loss: 0.6912 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0373 - loss: 0.7827 - val_accuracy: 0.0000e+00 - val_loss: 0.6904 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0362 - loss: 0.7778 - val_accuracy: 0.0000e+00 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0338 - loss: 0.7674 - val_accuracy: 0.0016 - val_loss: 0.6892 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0426 - loss: 0.7599 - val_accuracy: 0.0110 - val_loss: 0.6888 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0364 - loss: 0.7544 - val_accuracy: 0.0220 - val_loss: 0.6883 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0254 - loss: 0.7458 - val_accuracy: 0.0220 - val_loss: 0.6896 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0330 - loss: 0.7401 - val_accuracy: 0.0283 - val_loss: 0.6901 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0445 - loss: 0.7429 - val_accuracy: 0.0283 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0431 - loss: 0.7311 - val_accuracy: 0.0251 - val_loss: 0.6899 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0401 - loss: 0.7283 - val_accuracy: 0.0220 - val_loss: 0.6900 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0429 - loss: 0.7249 - val_accuracy: 0.0173 - val_loss: 0.6890 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0419 - loss: 0.7208 - val_accuracy: 0.0188 - val_loss: 0.6889 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0476 - loss: 0.7142 - val_accuracy: 0.0157 - val_loss: 0.6885 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0463 - loss: 0.7148 - val_accuracy: 0.0173 - val_loss: 0.6887 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m78/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0354 - loss: 0.7104\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0355 - loss: 0.7104 - val_accuracy: 0.0204 - val_loss: 0.6883 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0401 - loss: 0.7070 - val_accuracy: 0.0267 - val_loss: 0.6883 - learning_rate: 5.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0312 - loss: 0.7072 - val_accuracy: 0.0283 - val_loss: 0.6882 - learning_rate: 5.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0428 - loss: 0.7050 - val_accuracy: 0.0251 - val_loss: 0.6882 - learning_rate: 5.0000e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0476 - loss: 0.7077 - val_accuracy: 0.0283 - val_loss: 0.6883 - learning_rate: 5.0000e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0404 - loss: 0.7019 - val_accuracy: 0.0283 - val_loss: 0.6882 - learning_rate: 5.0000e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0403 - loss: 0.7022 - val_accuracy: 0.0298 - val_loss: 0.6879 - learning_rate: 5.0000e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0477 - loss: 0.7028 - val_accuracy: 0.0251 - val_loss: 0.6878 - learning_rate: 5.0000e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0429 - loss: 0.7022 - val_accuracy: 0.0267 - val_loss: 0.6877 - learning_rate: 5.0000e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0380 - loss: 0.6929 - val_accuracy: 0.0251 - val_loss: 0.6876 - learning_rate: 5.0000e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0408 - loss: 0.6976 - val_accuracy: 0.0330 - val_loss: 0.6874 - learning_rate: 5.0000e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0441 - loss: 0.6920 - val_accuracy: 0.0267 - val_loss: 0.6875 - learning_rate: 5.0000e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0391 - loss: 0.6942 - val_accuracy: 0.0283 - val_loss: 0.6873 - learning_rate: 5.0000e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0395 - loss: 0.6909 - val_accuracy: 0.0283 - val_loss: 0.6875 - learning_rate: 5.0000e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0363 - loss: 0.6937 - val_accuracy: 0.0283 - val_loss: 0.6874 - learning_rate: 5.0000e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0350 - loss: 0.6936 - val_accuracy: 0.0220 - val_loss: 0.6871 - learning_rate: 5.0000e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0390 - loss: 0.6912 - val_accuracy: 0.0235 - val_loss: 0.6874 - learning_rate: 5.0000e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0279 - loss: 0.6901 - val_accuracy: 0.0267 - val_loss: 0.6876 - learning_rate: 5.0000e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0404 - loss: 0.6868 - val_accuracy: 0.0220 - val_loss: 0.6876 - learning_rate: 5.0000e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0330 - loss: 0.6854 - val_accuracy: 0.0267 - val_loss: 0.6876 - learning_rate: 5.0000e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0325 - loss: 0.6862 - val_accuracy: 0.0267 - val_loss: 0.6875 - learning_rate: 5.0000e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0428 - loss: 0.6862 - val_accuracy: 0.0283 - val_loss: 0.6876 - learning_rate: 5.0000e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0361 - loss: 0.6872 - val_accuracy: 0.0361 - val_loss: 0.6874 - learning_rate: 5.0000e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0422 - loss: 0.6834 - val_accuracy: 0.0361 - val_loss: 0.6877 - learning_rate: 5.0000e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0444 - loss: 0.6850 - val_accuracy: 0.0330 - val_loss: 0.6875 - learning_rate: 5.0000e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m78/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0511 - loss: 0.6842\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0508 - loss: 0.6842 - val_accuracy: 0.0298 - val_loss: 0.6875 - learning_rate: 5.0000e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0356 - loss: 0.6792 - val_accuracy: 0.0314 - val_loss: 0.6875 - learning_rate: 2.5000e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0375 - loss: 0.6801 - val_accuracy: 0.0283 - val_loss: 0.6875 - learning_rate: 2.5000e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0468 - loss: 0.6822 - val_accuracy: 0.0330 - val_loss: 0.6874 - learning_rate: 2.5000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0292 - loss: 0.6810 - val_accuracy: 0.0298 - val_loss: 0.6875 - learning_rate: 2.5000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0422 - loss: 0.6801 - val_accuracy: 0.0283 - val_loss: 0.6874 - learning_rate: 2.5000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0393 - loss: 0.6783 - val_accuracy: 0.0298 - val_loss: 0.6873 - learning_rate: 2.5000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0420 - loss: 0.6782 - val_accuracy: 0.0330 - val_loss: 0.6871 - learning_rate: 2.5000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0424 - loss: 0.6755 - val_accuracy: 0.0330 - val_loss: 0.6870 - learning_rate: 2.5000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0436 - loss: 0.6786 - val_accuracy: 0.0345 - val_loss: 0.6870 - learning_rate: 2.5000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0356 - loss: 0.6753 - val_accuracy: 0.0330 - val_loss: 0.6868 - learning_rate: 2.5000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0349 - loss: 0.6748 - val_accuracy: 0.0298 - val_loss: 0.6869 - learning_rate: 2.5000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0516 - loss: 0.6770 - val_accuracy: 0.0330 - val_loss: 0.6868 - learning_rate: 2.5000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0414 - loss: 0.6758 - val_accuracy: 0.0345 - val_loss: 0.6868 - learning_rate: 2.5000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0465 - loss: 0.6737 - val_accuracy: 0.0298 - val_loss: 0.6870 - learning_rate: 2.5000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0413 - loss: 0.6760 - val_accuracy: 0.0298 - val_loss: 0.6871 - learning_rate: 2.5000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0381 - loss: 0.6753 - val_accuracy: 0.0314 - val_loss: 0.6870 - learning_rate: 2.5000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0512 - loss: 0.6752 - val_accuracy: 0.0283 - val_loss: 0.6871 - learning_rate: 2.5000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0354 - loss: 0.6734 - val_accuracy: 0.0314 - val_loss: 0.6872 - learning_rate: 2.5000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0474 - loss: 0.6738 - val_accuracy: 0.0345 - val_loss: 0.6870 - learning_rate: 2.5000e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0502 - loss: 0.6738\n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0502 - loss: 0.6738 - val_accuracy: 0.0298 - val_loss: 0.6872 - learning_rate: 2.5000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0462 - loss: 0.6726 - val_accuracy: 0.0314 - val_loss: 0.6871 - learning_rate: 1.2500e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0412 - loss: 0.6751 - val_accuracy: 0.0298 - val_loss: 0.6871 - learning_rate: 1.2500e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0461 - loss: 0.6702 - val_accuracy: 0.0298 - val_loss: 0.6871 - learning_rate: 1.2500e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0393 - loss: 0.6732 - val_accuracy: 0.0314 - val_loss: 0.6872 - learning_rate: 1.2500e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0447 - loss: 0.6724 - val_accuracy: 0.0314 - val_loss: 0.6871 - learning_rate: 1.2500e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0423 - loss: 0.6720 - val_accuracy: 0.0283 - val_loss: 0.6871 - learning_rate: 1.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0430 - loss: 0.6708 - val_accuracy: 0.0283 - val_loss: 0.6871 - learning_rate: 1.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0411 - loss: 0.6709 - val_accuracy: 0.0283 - val_loss: 0.6871 - learning_rate: 1.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0388 - loss: 0.6703 - val_accuracy: 0.0298 - val_loss: 0.6871 - learning_rate: 1.2500e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m79/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0484 - loss: 0.6708\n",
            "Epoch 73: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0484 - loss: 0.6708 - val_accuracy: 0.0314 - val_loss: 0.6871 - learning_rate: 1.2500e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0382 - loss: 0.6691 - val_accuracy: 0.0298 - val_loss: 0.6871 - learning_rate: 6.2500e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0493 - loss: 0.6704 - val_accuracy: 0.0298 - val_loss: 0.6872 - learning_rate: 6.2500e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0384 - loss: 0.6697 - val_accuracy: 0.0283 - val_loss: 0.6872 - learning_rate: 6.2500e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0358 - loss: 0.6701 - val_accuracy: 0.0298 - val_loss: 0.6871 - learning_rate: 6.2500e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0331 - loss: 0.6688 - val_accuracy: 0.0298 - val_loss: 0.6871 - learning_rate: 6.2500e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0335 - loss: 0.6696 - val_accuracy: 0.0298 - val_loss: 0.6871 - learning_rate: 6.2500e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0384 - loss: 0.6718 - val_accuracy: 0.0283 - val_loss: 0.6871 - learning_rate: 6.2500e-06\n",
            "Epoch 80: early stopping\n",
            "Restoring model weights from the end of the best epoch: 55.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
            "\n",
            "============================================================\n",
            "PREVIS√ÉO LOTOF√ÅCIL - PR√ìXIMO SORTEIO (VERS√ÉO OTIMIZADA)\n",
            "============================================================\n",
            "N√∫meros previstos: [2, 3, 6, 10, 11, 13, 15, 16, 17, 18, 19, 22, 23, 24, 25]\n",
            "Acur√°cia do modelo: 3.39%\n",
            "√âpocas treinadas: 80\n",
            "Loss final (treino): 0.6718\n",
            "Loss final (valida√ß√£o): 0.6871\n",
            "============================================================\n",
            "\n",
            "‚ö†Ô∏è  NOTA: Loterias s√£o eventos aleat√≥rios.\n",
            "Este modelo √© apenas um exerc√≠cio de Deep Learning.\n",
            "N√£o use para apostas reais.\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================================================\n",
        "# LOTOF√ÅCIL - VERS√ÉO PROFISSIONAL COM MELHORIAS AVAN√áADAS DE ML\n",
        "# ============================================================================================================\n",
        "# MELHORIAS IMPLEMENTADAS PARA AUMENTAR ACUR√ÅCIA E VERDADEIROS POSITIVOS:\n",
        "# 1. Feature Engineering: Estat√≠sticas temporais (frequ√™ncia, m√©dia m√≥vel, √∫ltimos sorteios)\n",
        "# 2. Arquitetura ResNet-like: Conex√µes residuais para melhor propaga√ß√£o de gradientes\n",
        "# 3. Attention Mechanism: Foco em padr√µes mais relevantes\n",
        "# 4. Label Smoothing: Regulariza√ß√£o para evitar overconfidence\n",
        "# 5. Focal Loss: Melhor tratamento de classes desbalanceadas\n",
        "# 6. Class Weights: Balanceamento autom√°tico de classes\n",
        "# 7. Layer Normalization: Normaliza√ß√£o avan√ßada\n",
        "# 8. Learning Rate Warmup + Cosine Decay: Otimiza√ß√£o do learning rate\n",
        "# 9. Ensemble de m√∫ltiplos modelos: Predi√ß√µes mais est√°veis\n",
        "# 10. Cross-Validation: Valida√ß√£o mais robusta\n",
        "# ============================================================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout, BatchNormalization, Add, Input, LayerNormalization, Multiply\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"LOTOF√ÅCIL - MODELO PROFISSIONAL COM T√âCNICAS AVAN√áADAS DE ML\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Carregamento dos dados\n",
        "df = pd.read_excel('Lotof√°cil.xlsx')\n",
        "bola_cols = [col for col in df.columns if 'Bola' in col][:15]\n",
        "numeros = df[bola_cols].astype(int)\n",
        "print(f\"\\nTotal de sorteios carregados: {len(numeros)}\")\n",
        "\n",
        "# 2. FEATURE ENGINEERING AVAN√áADO\n",
        "print(\"\\nAplicando Feature Engineering...\")\n",
        "\n",
        "def calcular_estatisticas(dados, window=5):\n",
        "    \"\"\"Calcula estat√≠sticas temporais para cada n√∫mero\"\"\"\n",
        "    stats = {}\n",
        "    for num in range(1, 26):\n",
        "        # Frequ√™ncia global\n",
        "        freq = (dados == num).sum().sum() / (len(dados) * 15)\n",
        "        # M√©dia m√≥vel de apari√ß√µes\n",
        "        aparicoes = [(dados.iloc[i] == num).sum() for i in range(len(dados))]\n",
        "        media_movel = pd.Series(aparicoes).rolling(window=window, min_periods=1).mean().iloc[-1]\n",
        "        stats[num] = {'freq': freq, 'media_movel': media_movel}\n",
        "    return stats\n",
        "\n",
        "estatisticas = calcular_estatisticas(numeros)\n",
        "\n",
        "def one_hot_lotus_enhanced(row, stats):\n",
        "    \"\"\"One-hot encoding com features estat√≠sticas\"\"\"\n",
        "    v = np.zeros(25 * 3)  # 25 n√∫meros x 3 features (one-hot + freq + m√©dia m√≥vel)\n",
        "    for n in row:\n",
        "        if 1 <= n <= 25:\n",
        "            idx = int(n) - 1\n",
        "            v[idx] = 1  # One-hot\n",
        "            v[25 + idx] = stats[n]['freq']  # Frequ√™ncia\n",
        "            v[50 + idx] = stats[n]['media_movel']  # M√©dia m√≥vel\n",
        "    return v\n",
        "\n",
        "# 3. Prepara√ß√£o dos dados com features enriquecidas\n",
        "X = np.array([one_hot_lotus_enhanced(r, estatisticas) for r in numeros.values[:-1]])\n",
        "y = np.array([one_hot_lotus_enhanced(r, estatisticas)[:25] for r in numeros.values[1:]])  # Apenas one-hot para y\n",
        "\n",
        "X = X.reshape(-1, 75, 1)  # 75 = 25 n√∫meros x 3 features\n",
        "print(f\"\\nShape dos dados:\")\n",
        "print(f\"X (entrada com features): {X.shape}\")\n",
        "print(f\"y (sa√≠da): {y.shape}\")\n",
        "\n",
        "# 4. Class Weights para balanceamento\n",
        "def calcular_class_weights(y):\n",
        "    \"\"\"Calcula pesos das classes para balanceamento\"\"\"\n",
        "    weights = {}\n",
        "    for i in range(25):\n",
        "        positivos = y[:, i].sum()\n",
        "        negativos = len(y) - positivos\n",
        "        if positivos > 0:\n",
        "            weights[i] = negativos / positivos\n",
        "        else:\n",
        "            weights[i] = 1.0\n",
        "    return np.array([weights[i] for i in range(25)])\n",
        "\n",
        "class_weights = calcular_class_weights(y)\n",
        "print(f\"\\nClass weights calculados (primeiros 5): {class_weights[:5]}\")\n",
        "\n",
        "# 5. FOCAL LOSS para melhor tratamento de desbalanceamento\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
        "        return K.mean(K.sum(loss, axis=-1))\n",
        "    return focal_loss_fixed\n",
        "\n",
        "# 6. LABEL SMOOTHING\n",
        "def label_smoothing(y, smoothing=0.1):\n",
        "    \"\"\"Aplica label smoothing para regulariza√ß√£o\"\"\"\n",
        "    return y * (1 - smoothing) + smoothing / 2\n",
        "\n",
        "y_smoothed = label_smoothing(y, smoothing=0.1)\n",
        "\n",
        "# 7. ARQUITETURA PROFISSIONAL COM RESNET + ATTENTION\n",
        "def criar_modelo_profissional():\n",
        "    \"\"\"Cria modelo com ResNet blocks e Attention Mechanism\"\"\"\n",
        "    inputs = Input(shape=(75, 1))\n",
        "\n",
        "    # Primeira camada convolucional\n",
        "    x = Conv1D(128, 3, activation='relu', padding='same')(inputs)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # ResNet Block 1\n",
        "    residual = x\n",
        "    x = Conv1D(256, 3, activation='relu', padding='same')(x)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
        "    x = Add()([x, residual])  # Conex√£o residual\n",
        "    x = LayerNormalization()(x)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = Conv1D(128, 1, activation='sigmoid')(x)\n",
        "    x = Multiply()([x, attention])  # Aplica attention\n",
        "\n",
        "    # ResNet Block 2\n",
        "    residual = x\n",
        "    x = Conv1D(256, 3, activation='relu', padding='same')(x)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
        "    x = Add()([x, residual])\n",
        "    x = LayerNormalization()(x)\n",
        "\n",
        "    # Global pooling e camadas densas\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # Sa√≠da com sigmoid (multi-label)\n",
        "    outputs = Dense(25, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "print(\"\\nCriando modelo profissional...\")\n",
        "modelo = criar_modelo_profissional()\n",
        "\n",
        "# 8. LEARNING RATE com WARMUP e COSINE DECAY\n",
        "def lr_schedule_warmup(epoch, lr):\n",
        "    \"\"\"Learning rate com warmup e cosine decay\"\"\"\n",
        "    warmup_epochs = 5\n",
        "    total_epochs = 100\n",
        "    initial_lr = 0.0001\n",
        "\n",
        "    if epoch < warmup_epochs:\n",
        "        return initial_lr * (epoch + 1) / warmup_epochs\n",
        "    else:\n",
        "        progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
        "        return initial_lr * 0.5 * (1 + np.cos(np.pi * progress))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule_warmup, verbose=0)\n",
        "\n",
        "# 9. Compila√ß√£o com Focal Loss\n",
        "optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
        "modelo.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=focal_loss(gamma=2.0, alpha=0.25),\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "print(\"\\nModelo compilado com Focal Loss e m√©tricas avan√ßadas\")\n",
        "\n",
        "# 10. Callbacks otimizados\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=12,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping, reduce_lr, lr_scheduler]\n",
        "\n",
        "# 11. ENSEMBLE com K-FOLD CROSS-VALIDATION\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TREINAMENTO COM K-FOLD CROSS-VALIDATION (K=3)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "modelos_ensemble = []\n",
        "historias = []\n",
        "scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X), 1):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"FOLD {fold}/3\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y_smoothed[train_idx], y[val_idx]\n",
        "\n",
        "    # Cria novo modelo para este fold\n",
        "    modelo_fold = criar_modelo_profissional()\n",
        "    modelo_fold.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001, clipnorm=1.0),\n",
        "        loss=focal_loss(gamma=2.0, alpha=0.25),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Treina modelo\n",
        "    historia = modelo_fold.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=50,  # Reduzido para efici√™ncia\n",
        "        batch_size=32,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    historias.append(historia)\n",
        "    modelos_ensemble.append(modelo_fold)\n",
        "\n",
        "    # Avalia modelo\n",
        "    score = modelo_fold.evaluate(X_val, y_val, verbose=0)\n",
        "    scores.append(score[1])  # accuracy\n",
        "    print(f\"\\nFold {fold} - Acur√°cia de valida√ß√£o: {score[1]*100:.2f}%\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(f\"RESULTADO FINAL DO ENSEMBLE\")\n",
        "print(f\"=\"*80)\n",
        "print(f\"Acur√°cia m√©dia dos {len(scores)} folds: {np.mean(scores)*100:.2f}% (¬±{np.std(scores)*100:.2f}%)\")\n",
        "\n",
        "# 12. Predi√ß√£o com ENSEMBLE (m√©dia das predi√ß√µes)\n",
        "print(f\"\\nGerando predi√ß√£o com ensemble de {len(modelos_ensemble)} modelos...\")\n",
        "last_data = X[-1:]\n",
        "\n",
        "# Predi√ß√µes de todos os modelos\n",
        "predicoes = [modelo.predict(last_data, verbose=0).flatten() for modelo in modelos_ensemble]\n",
        "predicao_ensemble = np.mean(predicoes, axis=0)\n",
        "\n",
        "# Seleciona os 15 n√∫meros com maior probabilidade\n",
        "proximos_numeros = np.argsort(predicao_ensemble)[-15:] + 1\n",
        "proximos_numeros_formatados = sorted([int(x) for x in proximos_numeros])\n",
        "\n",
        "# Probabilidades m√©dias\n",
        "probabilidades = predicao_ensemble[np.argsort(predicao_ensemble)[-15:]]\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"PREVIS√ÉO LOTOF√ÅCIL - MODELO PROFISSIONAL COM ENSEMBLE\")\n",
        "print(f\"=\"*80)\n",
        "print(f\"N√∫meros previstos: {proximos_numeros_formatados}\")\n",
        "print(f\"\\nProbabilidades (top 15):\")\n",
        "for num, prob in zip(sorted(proximos_numeros), sorted(probabilidades, reverse=True)):\n",
        "    print(f\"  N√∫mero {num:2d}: {prob*100:5.2f}%\")\n",
        "print(f\"\\nAcur√°cia m√©dia do ensemble: {np.mean(scores)*100:.2f}%\")\n",
        "print(f\"Desvio padr√£o: {np.std(scores)*100:.2f}%\")\n",
        "print(f\"=\"*80)\n",
        "print(\"\\n‚ö†Ô∏è  NOTA: Este √© um modelo educacional de Deep Learning.\")\n",
        "print(\"Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWstQrUAI0to",
        "outputId": "cd2f5368-11f6-407e-9169-b98978d2d625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "LOTOF√ÅCIL - MODELO PROFISSIONAL COM T√âCNICAS AVAN√áADAS DE ML\n",
            "================================================================================\n",
            "\n",
            "Total de sorteios carregados: 3540\n",
            "\n",
            "Aplicando Feature Engineering...\n",
            "\n",
            "Shape dos dados:\n",
            "X (entrada com features): (3539, 75, 1)\n",
            "y (sa√≠da): (3539, 25)\n",
            "\n",
            "Class weights calculados (primeiros 5): [0.65373832 0.67091596 0.6529659  0.65761124 0.66698069]\n",
            "\n",
            "Criando modelo profissional...\n",
            "\n",
            "Modelo compilado com Focal Loss e m√©tricas avan√ßadas\n",
            "\n",
            "================================================================================\n",
            "TREINAMENTO COM K-FOLD CROSS-VALIDATION (K=3)\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "FOLD 1/3\n",
            "================================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 155ms/step - accuracy: 0.0722 - loss: 0.5406 - val_accuracy: 0.0712 - val_loss: 1.7181e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0927 - loss: 0.0095 - val_accuracy: 0.2653 - val_loss: 1.6264e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0797 - loss: 0.0038 - val_accuracy: 0.0415 - val_loss: 4.1049e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0769 - loss: 0.0020 - val_accuracy: 0.1856 - val_loss: 1.5325e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0671 - loss: 0.0025 - val_accuracy: 0.4669 - val_loss: 4.9956e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0889 - loss: 8.5441e-04 - val_accuracy: 0.4890 - val_loss: 2.4747e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0798 - loss: 7.9493e-04 - val_accuracy: 0.2441 - val_loss: 1.8891e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0939 - loss: 9.6735e-04 - val_accuracy: 0.0161 - val_loss: 1.4996e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0940 - loss: 6.5324e-04 - val_accuracy: 0.5992 - val_loss: 4.0725e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1052 - loss: 5.4036e-04 - val_accuracy: 0.2458 - val_loss: 3.2153e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1005 - loss: 2.9539e-04 - val_accuracy: 0.0186 - val_loss: 1.5048e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0986 - loss: 1.5598e-04 - val_accuracy: 0.0568 - val_loss: 1.0270e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0858 - loss: 3.6698e-04\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0857 - loss: 3.6496e-04 - val_accuracy: 0.0568 - val_loss: 9.5530e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0935 - loss: 4.2834e-04 - val_accuracy: 0.0856 - val_loss: 5.8326e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0789 - loss: 3.7190e-04 - val_accuracy: 0.2085 - val_loss: 5.8307e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0624 - loss: 3.8138e-04 - val_accuracy: 0.0017 - val_loss: 4.9016e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0688 - loss: 2.3381e-04 - val_accuracy: 0.1847 - val_loss: 4.5516e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0724 - loss: 6.1254e-05 - val_accuracy: 0.2398 - val_loss: 3.9206e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0817 - loss: 9.0977e-05 - val_accuracy: 0.2407 - val_loss: 2.8846e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0748 - loss: 9.8526e-05 - val_accuracy: 0.2415 - val_loss: 2.3594e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0815 - loss: 1.1405e-04 - val_accuracy: 0.2364 - val_loss: 1.9006e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0900 - loss: 7.2227e-05 - val_accuracy: 0.2347 - val_loss: 1.6499e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0763 - loss: 1.0297e-04 - val_accuracy: 0.2441 - val_loss: 1.3291e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0911 - loss: 2.9604e-04 - val_accuracy: 0.2424 - val_loss: 1.4326e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0689 - loss: 1.1601e-04\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0695 - loss: 1.1849e-04 - val_accuracy: 0.2432 - val_loss: 1.1836e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0920 - loss: 2.1024e-04 - val_accuracy: 0.2432 - val_loss: 1.0957e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0916 - loss: 1.2049e-04 - val_accuracy: 0.2432 - val_loss: 9.8529e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0813 - loss: 9.3263e-05 - val_accuracy: 0.2432 - val_loss: 9.1105e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0809 - loss: 1.0704e-04 - val_accuracy: 0.2432 - val_loss: 8.2864e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0872 - loss: 1.3814e-04 - val_accuracy: 0.2432 - val_loss: 7.5552e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0995 - loss: 4.6151e-05 - val_accuracy: 0.2432 - val_loss: 6.9216e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1102 - loss: 1.4843e-04 - val_accuracy: 0.2424 - val_loss: 6.5456e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0828 - loss: 5.5148e-05 - val_accuracy: 0.2424 - val_loss: 5.6942e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0812 - loss: 1.0633e-04 - val_accuracy: 0.2424 - val_loss: 5.3636e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0881 - loss: 1.2370e-04 - val_accuracy: 0.2432 - val_loss: 5.4871e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0809 - loss: 1.9076e-05 - val_accuracy: 0.2424 - val_loss: 5.2022e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0880 - loss: 4.2672e-05\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0879 - loss: 4.2718e-05 - val_accuracy: 0.2432 - val_loss: 4.8202e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0981 - loss: 4.1906e-05 - val_accuracy: 0.2432 - val_loss: 4.5604e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0833 - loss: 8.5878e-05 - val_accuracy: 0.2432 - val_loss: 3.8918e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0741 - loss: 6.6697e-05 - val_accuracy: 0.2432 - val_loss: 3.8639e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0815 - loss: 5.2172e-05 - val_accuracy: 0.2432 - val_loss: 3.8336e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0820 - loss: 3.8887e-05 - val_accuracy: 0.2432 - val_loss: 3.7116e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0781 - loss: 4.7535e-05 - val_accuracy: 0.2432 - val_loss: 3.4826e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0914 - loss: 3.8039e-05 - val_accuracy: 0.2432 - val_loss: 3.3906e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0897 - loss: 3.7836e-05 - val_accuracy: 0.2432 - val_loss: 3.2358e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0936 - loss: 3.1408e-05 - val_accuracy: 0.2432 - val_loss: 3.1215e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0841 - loss: 3.6794e-05 - val_accuracy: 0.2432 - val_loss: 3.0189e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0873 - loss: 4.9985e-05 - val_accuracy: 0.2432 - val_loss: 2.8114e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0884 - loss: 4.9907e-05\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0887 - loss: 5.1105e-05 - val_accuracy: 0.2432 - val_loss: 2.6400e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1030 - loss: 1.1249e-04 - val_accuracy: 0.2432 - val_loss: 2.6323e-11 - learning_rate: 6.2500e-06\n",
            "Restoring model weights from the end of the best epoch: 50.\n",
            "\n",
            "Fold 1 - Acur√°cia de valida√ß√£o: 24.32%\n",
            "\n",
            "================================================================================\n",
            "FOLD 2/3\n",
            "================================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 162ms/step - accuracy: 0.0168 - loss: 0.3924 - val_accuracy: 0.0000e+00 - val_loss: 5.2957e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0231 - loss: 0.0065 - val_accuracy: 0.0000e+00 - val_loss: 1.1498e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0291 - loss: 0.0037 - val_accuracy: 0.0000e+00 - val_loss: 2.8150e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0296 - loss: 0.0016 - val_accuracy: 0.0000e+00 - val_loss: 1.2726e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0227 - loss: 0.0013 - val_accuracy: 8.4746e-04 - val_loss: 9.5284e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0304 - loss: 6.8466e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.2833e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0173 - loss: 8.6385e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.5707e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0182 - loss: 8.8194e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.0474e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0215 - loss: 2.2560e-04 - val_accuracy: 0.0000e+00 - val_loss: 6.6895e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0389 - loss: 3.5640e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.9655e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0189 - loss: 2.2346e-04 - val_accuracy: 0.0000e+00 - val_loss: 3.1177e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0241 - loss: 3.7809e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.2335e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0214 - loss: 1.7723e-04\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0214 - loss: 1.7998e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.2696e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0349 - loss: 1.6713e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.0870e-09 - learning_rate: 5.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.0259 - loss: 1.7606e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.0858e-09 - learning_rate: 5.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0550 - loss: 2.7520e-04 - val_accuracy: 0.0000e+00 - val_loss: 8.2719e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0393 - loss: 9.3599e-05 - val_accuracy: 0.0000e+00 - val_loss: 7.2559e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0416 - loss: 8.7767e-05 - val_accuracy: 0.0000e+00 - val_loss: 7.5683e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0301 - loss: 1.4123e-04 - val_accuracy: 0.0000e+00 - val_loss: 6.8277e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0203 - loss: 2.3929e-04 - val_accuracy: 0.0000e+00 - val_loss: 7.4528e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0299 - loss: 8.2338e-05 - val_accuracy: 0.0000e+00 - val_loss: 5.7821e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0311 - loss: 1.4868e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.6716e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0376 - loss: 2.7458e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.9409e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0224 - loss: 1.7059e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.9753e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0250 - loss: 1.0355e-04\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0253 - loss: 1.0616e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.3395e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0350 - loss: 2.7947e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.4920e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0342 - loss: 1.2826e-04 - val_accuracy: 0.0000e+00 - val_loss: 3.9615e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0298 - loss: 4.6464e-05 - val_accuracy: 0.0000e+00 - val_loss: 4.0333e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0335 - loss: 4.6043e-05 - val_accuracy: 0.0000e+00 - val_loss: 3.7242e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0357 - loss: 1.1968e-04 - val_accuracy: 0.0000e+00 - val_loss: 3.3315e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0255 - loss: 5.2840e-05 - val_accuracy: 0.0000e+00 - val_loss: 2.6406e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0313 - loss: 5.0199e-05 - val_accuracy: 0.0000e+00 - val_loss: 2.0951e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0292 - loss: 3.2165e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.9502e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0305 - loss: 4.9240e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.3215e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0264 - loss: 1.5199e-04 - val_accuracy: 0.0034 - val_loss: 2.2819e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0369 - loss: 1.5278e-04 - val_accuracy: 0.0254 - val_loss: 1.7070e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0524 - loss: 2.9732e-04\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0514 - loss: 2.8571e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.9806e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0366 - loss: 6.4524e-05 - val_accuracy: 0.0000e+00 - val_loss: 2.1255e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0323 - loss: 7.0680e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.9686e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0390 - loss: 6.0555e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.6937e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0250 - loss: 3.7811e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.5094e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0273 - loss: 3.6098e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.5553e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0447 - loss: 2.1542e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.4687e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0228 - loss: 4.8093e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.3927e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0267 - loss: 7.9150e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.3213e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0284 - loss: 3.7410e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.3542e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0260 - loss: 2.9916e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.3003e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0294 - loss: 4.1903e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.2283e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0290 - loss: 5.0387e-05\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0290 - loss: 5.1188e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.1554e-10 - learning_rate: 1.2500e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0322 - loss: 1.2023e-04 - val_accuracy: 0.0000e+00 - val_loss: 9.7447e-11 - learning_rate: 6.2500e-06\n",
            "Restoring model weights from the end of the best epoch: 50.\n",
            "\n",
            "Fold 2 - Acur√°cia de valida√ß√£o: 0.00%\n",
            "\n",
            "================================================================================\n",
            "FOLD 3/3\n",
            "================================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 164ms/step - accuracy: 0.0275 - loss: 0.4795 - val_accuracy: 0.0000e+00 - val_loss: 1.3266e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0314 - loss: 0.0087 - val_accuracy: 0.0000e+00 - val_loss: 1.2995e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0291 - loss: 0.0044 - val_accuracy: 0.0000e+00 - val_loss: 4.6748e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0409 - loss: 0.0024 - val_accuracy: 0.0000e+00 - val_loss: 1.1089e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0326 - loss: 0.0014 - val_accuracy: 0.0000e+00 - val_loss: 4.2975e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0360 - loss: 8.9120e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.4597e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0380 - loss: 0.0014 - val_accuracy: 0.0000e+00 - val_loss: 1.2258e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0331 - loss: 7.9359e-04 - val_accuracy: 0.0000e+00 - val_loss: 6.1721e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0297 - loss: 5.4683e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.6049e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0393 - loss: 4.0888e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.3015e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0286 - loss: 2.8893e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.7422e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0397 - loss: 3.3339e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.3597e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0351 - loss: 2.9330e-04\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0350 - loss: 2.9027e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.1910e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0429 - loss: 2.5279e-04 - val_accuracy: 8.4818e-04 - val_loss: 9.7929e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0422 - loss: 6.2734e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.9342e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0344 - loss: 1.9669e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.7835e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0387 - loss: 2.8458e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.5002e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0291 - loss: 2.4402e-04 - val_accuracy: 0.0000e+00 - val_loss: 3.3785e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0364 - loss: 1.1762e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.8435e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0340 - loss: 1.4365e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.5453e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0336 - loss: 8.5408e-05 - val_accuracy: 0.0000e+00 - val_loss: 2.1784e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0464 - loss: 1.7358e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.0092e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0466 - loss: 1.3176e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.6898e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0400 - loss: 7.8499e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.6651e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m67/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0361 - loss: 1.3637e-04\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0370 - loss: 1.3636e-04 - val_accuracy: 0.0034 - val_loss: 1.7765e-10 - learning_rate: 5.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0394 - loss: 6.5300e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.6670e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0387 - loss: 9.0775e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.3520e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0383 - loss: 1.1537e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.2550e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0434 - loss: 8.8065e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.2135e-10 - learning_rate: 2.5000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0578 - loss: 2.8558e-04 - val_accuracy: 0.0000e+00 - val_loss: 8.9953e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0431 - loss: 5.9228e-05 - val_accuracy: 0.0000e+00 - val_loss: 7.9674e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0601 - loss: 6.3656e-05 - val_accuracy: 0.0000e+00 - val_loss: 7.6501e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0522 - loss: 9.9207e-05 - val_accuracy: 0.0000e+00 - val_loss: 6.2100e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0350 - loss: 4.4542e-05 - val_accuracy: 0.0000e+00 - val_loss: 6.2552e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0456 - loss: 1.0068e-04 - val_accuracy: 0.0000e+00 - val_loss: 6.4047e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0492 - loss: 4.0444e-05 - val_accuracy: 0.0000e+00 - val_loss: 5.9455e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0453 - loss: 3.3630e-05\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0454 - loss: 3.3678e-05 - val_accuracy: 0.0000e+00 - val_loss: 5.4120e-11 - learning_rate: 2.5000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0434 - loss: 1.0773e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.4154e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0468 - loss: 1.1265e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.4643e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0484 - loss: 6.9895e-05 - val_accuracy: 0.0000e+00 - val_loss: 4.8897e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0622 - loss: 5.4665e-05 - val_accuracy: 0.0000e+00 - val_loss: 4.4632e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0458 - loss: 3.1879e-05 - val_accuracy: 0.0000e+00 - val_loss: 4.1076e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0467 - loss: 4.4056e-05 - val_accuracy: 0.0000e+00 - val_loss: 3.8583e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0587 - loss: 7.6283e-05 - val_accuracy: 0.0000e+00 - val_loss: 3.4676e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0598 - loss: 5.1768e-05 - val_accuracy: 0.0000e+00 - val_loss: 3.5158e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0495 - loss: 6.9813e-05 - val_accuracy: 0.0000e+00 - val_loss: 3.4039e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0443 - loss: 5.3907e-05 - val_accuracy: 0.0000e+00 - val_loss: 3.1767e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0376 - loss: 2.3700e-04 - val_accuracy: 0.0000e+00 - val_loss: 3.1211e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0510 - loss: 4.6860e-05\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0509 - loss: 4.6972e-05 - val_accuracy: 0.0000e+00 - val_loss: 3.1628e-11 - learning_rate: 1.2500e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0505 - loss: 4.2373e-05 - val_accuracy: 0.0000e+00 - val_loss: 3.2715e-11 - learning_rate: 6.2500e-06\n",
            "Restoring model weights from the end of the best epoch: 48.\n",
            "\n",
            "Fold 3 - Acur√°cia de valida√ß√£o: 0.00%\n",
            "\n",
            "================================================================================\n",
            "RESULTADO FINAL DO ENSEMBLE\n",
            "================================================================================\n",
            "Acur√°cia m√©dia dos 3 folds: 8.11% (¬±11.47%)\n",
            "\n",
            "Gerando predi√ß√£o com ensemble de 3 modelos...\n",
            "\n",
            "================================================================================\n",
            "PREVIS√ÉO LOTOF√ÅCIL - MODELO PROFISSIONAL COM ENSEMBLE\n",
            "================================================================================\n",
            "N√∫meros previstos: [1, 2, 6, 7, 9, 10, 11, 13, 14, 16, 18, 19, 20, 21, 23]\n",
            "\n",
            "Probabilidades (top 15):\n",
            "  N√∫mero  1: 99.99%\n",
            "  N√∫mero  2: 99.99%\n",
            "  N√∫mero  6: 99.99%\n",
            "  N√∫mero  7: 99.99%\n",
            "  N√∫mero  9: 99.99%\n",
            "  N√∫mero 10: 99.99%\n",
            "  N√∫mero 11: 99.99%\n",
            "  N√∫mero 13: 99.99%\n",
            "  N√∫mero 14: 99.99%\n",
            "  N√∫mero 16: 99.99%\n",
            "  N√∫mero 18: 99.99%\n",
            "  N√∫mero 19: 99.99%\n",
            "  N√∫mero 20: 99.99%\n",
            "  N√∫mero 21: 99.98%\n",
            "  N√∫mero 23: 99.98%\n",
            "\n",
            "Acur√°cia m√©dia do ensemble: 8.11%\n",
            "Desvio padr√£o: 11.47%\n",
            "================================================================================\n",
            "\n",
            "‚ö†Ô∏è  NOTA: Este √© um modelo educacional de Deep Learning.\n",
            "Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SUPER SETE - VERS√ÉO OTIMIZADA E CORRIGIDA\n",
        "# ============================================================\n",
        "# Melhorias implementadas:\n",
        "# 1. Valida√ß√£o para evitar repeti√ß√µes de d√≠gitos inv√°lidas\n",
        "# 2. Otimizador com learning rate reduzido e gradient clipping\n",
        "# 3. Callbacks ajustados para melhor converg√™ncia\n",
        "# 4. Mais informa√ß√µes de diagn√≥stico\n",
        "# 5. Aumentada capacidade da rede\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Carregamento do arquivo\n",
        "df = pd.read_excel('Super Sete.xlsx')\n",
        "\n",
        "# 2. Extrair colunas dos sete n√∫meros sorteados\n",
        "cols_numeros = [col for col in df.columns if 'Coluna ' in col][:7]\n",
        "numeros = df[cols_numeros].astype(str)\n",
        "print(f\"Total de sorteios carregados: {len(numeros)}\")\n",
        "print(numeros.head())\n",
        "\n",
        "# 3. Fun√ß√£o para vetor one-hot (0 a 9 para Super Sete)\n",
        "def one_hot_super7(row):\n",
        "    v = np.zeros(10*7)\n",
        "    for i, n in enumerate(row):\n",
        "        if n.isdigit():\n",
        "            v[i*10 + int(n)] = 1\n",
        "    return v\n",
        "\n",
        "X = np.array([one_hot_super7(row) for row in numeros.values])\n",
        "y = X.copy()\n",
        "\n",
        "print(f\"\\nShape dos dados:\")\n",
        "print(f\"X: {X.shape}\")\n",
        "print(f\"y: {y.shape}\")\n",
        "\n",
        "# 4. Divis√£o treino/teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nDados de treino: {X_train.shape}\")\n",
        "print(f\"Dados de teste: {X_test.shape}\")\n",
        "\n",
        "# 5. Arquitetura CNN Otimizada\n",
        "model = Sequential([\n",
        "    # Primeira camada convolucional\n",
        "    Conv1D(128, 3, activation='relu', input_shape=(70,1), padding='same'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Segunda camada convolucional\n",
        "    Conv1D(256, 3, activation='relu', padding='same'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Terceira camada convolucional\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    # Camadas densas com mais neur√¥nios\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(70, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 6. CORRE√á√ÉO: Otimizador com learning rate reduzido e gradient clipping\n",
        "optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
        "\n",
        "# 7. Callbacks otimizados\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=20,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=8,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "# 8. Compila√ß√£o\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INICIANDO TREINAMENTO - VERS√ÉO OTIMIZADA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 9. Treinamento\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    validation_split=0.15,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 10. Previs√£o do pr√≥ximo sorteio\n",
        "last_data = X_test[-1].reshape(1,70,1)\n",
        "pred = model.predict(last_data).flatten()\n",
        "\n",
        "# 11. Reconstru√ß√£o do resultado esperado formato Super Sete\n",
        "resultado = []\n",
        "for i in range(7):\n",
        "    digito = np.argmax(pred[i*10: (i+1)*10])\n",
        "    resultado.append(digito)\n",
        "\n",
        "# 12. CORRE√á√ÉO: Valida√ß√£o de repeti√ß√µes (opcional - pode haver repeti√ß√µes leg√≠timas)\n",
        "# Nota: Na Super Sete, repeti√ß√µes s√£o poss√≠veis, ent√£o n√£o vamos for√ßar unicidade\n",
        "resultado_formatado = [int(x) for x in resultado]\n",
        "\n",
        "# 13. Calcular acur√°cia do modelo\n",
        "history_metrics = model.evaluate(X_test, y_test, verbose=0)\n",
        "accuracy = history_metrics[1] * 100\n",
        "\n",
        "# 14. Calcular acur√°cia por coluna (novo!)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"AN√ÅLISE POR COLUNA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Fazer previs√µes para todo o conjunto de teste\n",
        "X_test_reshaped = X_test.reshape(-1, 70, 1)\n",
        "all_preds = model.predict(X_test_reshaped, verbose=0)\n",
        "\n",
        "# Calcular acur√°cia por coluna\n",
        "for col in range(7):\n",
        "    correct = 0\n",
        "    for i in range(len(y_test)):\n",
        "        true_digit = np.argmax(y_test[i][col*10:(col+1)*10])\n",
        "        pred_digit = np.argmax(all_preds[i][col*10:(col+1)*10])\n",
        "        if true_digit == pred_digit:\n",
        "            correct += 1\n",
        "    acc_col = (correct / len(y_test)) * 100\n",
        "    print(f\"Coluna {col+1}: {acc_col:.2f}% de acertos\")\n",
        "\n",
        "# 15. Exibir resultado organizado\n",
        "print('\\n' + '='*60)\n",
        "print('PREVIS√ÉO SUPER SETE - PR√ìXIMO SORTEIO (VERS√ÉO OTIMIZADA)')\n",
        "print('='*60)\n",
        "print(f'N√∫meros previstos: {resultado_formatado}')\n",
        "print(f'Acur√°cia geral do modelo: {accuracy:.2f}%')\n",
        "print(f'√âpocas treinadas: {len(history.history[\"loss\"])}')\n",
        "print(f'Loss final (treino): {history.history[\"loss\"][-1]:.4f}')\n",
        "print(f'Loss final (valida√ß√£o): {history.history[\"val_loss\"][-1]:.4f}')\n",
        "print('='*60)\n",
        "print(\"\\n‚ö†Ô∏è  NOTA: Loterias s√£o eventos aleat√≥rios.\")\n",
        "print(\"Este modelo √© apenas um exerc√≠cio de Deep Learning.\")\n",
        "print(\"N√£o use para apostas reais.\")\n",
        "print('='*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK2a7QSs13kd",
        "outputId": "f51518a5-133a-4174-d743-f57b6321ecdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de sorteios carregados: 769\n",
            "  Coluna 1 Coluna 2 Coluna 3 Coluna 4 Coluna 5 Coluna 6 Coluna 7\n",
            "0        2        9        9        8        7        7        6\n",
            "1        8        8        1        5        6        7        7\n",
            "2        7        2        6        6        5        4        4\n",
            "3        5        7        8        1        8        2        5\n",
            "4        6        4        0        1        0        6        9\n",
            "\n",
            "Shape dos dados:\n",
            "X: (769, 70)\n",
            "y: (769, 70)\n",
            "\n",
            "Dados de treino: (615, 70)\n",
            "Dados de teste: (154, 70)\n",
            "\n",
            "============================================================\n",
            "INICIANDO TREINAMENTO - VERS√ÉO OTIMIZADA\n",
            "============================================================\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - accuracy: 0.0188 - loss: 0.6679 - val_accuracy: 0.0000e+00 - val_loss: 0.4166 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.0230 - loss: 0.4228 - val_accuracy: 0.0968 - val_loss: 0.3335 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.0220 - loss: 0.3666 - val_accuracy: 0.0860 - val_loss: 0.3158 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - accuracy: 0.0254 - loss: 0.3519 - val_accuracy: 0.2043 - val_loss: 0.3015 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.0512 - loss: 0.3288 - val_accuracy: 0.0968 - val_loss: 0.2749 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.0943 - loss: 0.2987 - val_accuracy: 0.0968 - val_loss: 0.2282 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.0998 - loss: 0.2521 - val_accuracy: 0.1613 - val_loss: 0.1702 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.1172 - loss: 0.2103 - val_accuracy: 0.0860 - val_loss: 0.1196 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.1206 - loss: 0.1718 - val_accuracy: 0.1290 - val_loss: 0.0861 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.1457 - loss: 0.1521 - val_accuracy: 0.1183 - val_loss: 0.0650 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.0991 - loss: 0.1380 - val_accuracy: 0.1720 - val_loss: 0.0536 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.1404 - loss: 0.1260 - val_accuracy: 0.1398 - val_loss: 0.0442 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.1329 - loss: 0.1130 - val_accuracy: 0.1935 - val_loss: 0.0369 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.1335 - loss: 0.1122 - val_accuracy: 0.1505 - val_loss: 0.0334 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.1271 - loss: 0.1051 - val_accuracy: 0.1290 - val_loss: 0.0297 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - accuracy: 0.1288 - loss: 0.1015 - val_accuracy: 0.1075 - val_loss: 0.0258 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.1238 - loss: 0.1011 - val_accuracy: 0.1290 - val_loss: 0.0247 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.1442 - loss: 0.0939 - val_accuracy: 0.1398 - val_loss: 0.0232 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.1168 - loss: 0.0879 - val_accuracy: 0.1183 - val_loss: 0.0204 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.1311 - loss: 0.0854 - val_accuracy: 0.1183 - val_loss: 0.0191 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.1529 - loss: 0.0831 - val_accuracy: 0.1613 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 127ms/step - accuracy: 0.1242 - loss: 0.0820 - val_accuracy: 0.1613 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.1471 - loss: 0.0818 - val_accuracy: 0.1828 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.1197 - loss: 0.0802 - val_accuracy: 0.1935 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.1391 - loss: 0.0728 - val_accuracy: 0.1075 - val_loss: 0.0149 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - accuracy: 0.1418 - loss: 0.0768 - val_accuracy: 0.1613 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.1381 - loss: 0.0715 - val_accuracy: 0.1720 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.1475 - loss: 0.0707 - val_accuracy: 0.1505 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.1159 - loss: 0.0687 - val_accuracy: 0.1613 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.1353 - loss: 0.0703 - val_accuracy: 0.1828 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - accuracy: 0.1340 - loss: 0.0678 - val_accuracy: 0.1828 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.1219 - loss: 0.0674 - val_accuracy: 0.1935 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.1264 - loss: 0.0655 - val_accuracy: 0.1398 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.1349 - loss: 0.0636 - val_accuracy: 0.1720 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.1406 - loss: 0.0644 - val_accuracy: 0.1505 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.1263 - loss: 0.0586 - val_accuracy: 0.1505 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.1513 - loss: 0.0575 - val_accuracy: 0.1398 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.1319 - loss: 0.0610 - val_accuracy: 0.1290 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.1345 - loss: 0.0614 - val_accuracy: 0.1935 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 127ms/step - accuracy: 0.1559 - loss: 0.0598 - val_accuracy: 0.2043 - val_loss: 0.0087 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.1278 - loss: 0.0581 - val_accuracy: 0.2151 - val_loss: 0.0085 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.1090 - loss: 0.0562 - val_accuracy: 0.1720 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.1199 - loss: 0.0555 - val_accuracy: 0.1505 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.1394 - loss: 0.0561 - val_accuracy: 0.1505 - val_loss: 0.0083 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.1176 - loss: 0.0524 - val_accuracy: 0.1398 - val_loss: 0.0078 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.1374 - loss: 0.0504 - val_accuracy: 0.1398 - val_loss: 0.0074 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.1231 - loss: 0.0512 - val_accuracy: 0.1720 - val_loss: 0.0070 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.1281 - loss: 0.0500 - val_accuracy: 0.1398 - val_loss: 0.0070 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.1383 - loss: 0.0545 - val_accuracy: 0.1935 - val_loss: 0.0068 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 131ms/step - accuracy: 0.1454 - loss: 0.0556 - val_accuracy: 0.1613 - val_loss: 0.0069 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.0969 - loss: 0.0483 - val_accuracy: 0.1720 - val_loss: 0.0064 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.1669 - loss: 0.0489 - val_accuracy: 0.1935 - val_loss: 0.0065 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.1689 - loss: 0.0467 - val_accuracy: 0.2258 - val_loss: 0.0063 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.1405 - loss: 0.0486 - val_accuracy: 0.2366 - val_loss: 0.0061 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.1658 - loss: 0.0483 - val_accuracy: 0.1613 - val_loss: 0.0062 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - accuracy: 0.1432 - loss: 0.0474 - val_accuracy: 0.1720 - val_loss: 0.0058 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.1291 - loss: 0.0465 - val_accuracy: 0.2366 - val_loss: 0.0058 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.1327 - loss: 0.0457 - val_accuracy: 0.2258 - val_loss: 0.0053 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.1281 - loss: 0.0431 - val_accuracy: 0.2258 - val_loss: 0.0051 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.1305 - loss: 0.0448 - val_accuracy: 0.2043 - val_loss: 0.0052 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.1583 - loss: 0.0440 - val_accuracy: 0.2151 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.0862 - loss: 0.0414 - val_accuracy: 0.1935 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - accuracy: 0.1143 - loss: 0.0422 - val_accuracy: 0.1828 - val_loss: 0.0052 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.1528 - loss: 0.0418 - val_accuracy: 0.2258 - val_loss: 0.0054 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.0982 - loss: 0.0429 - val_accuracy: 0.2581 - val_loss: 0.0051 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.1375 - loss: 0.0414 - val_accuracy: 0.2043 - val_loss: 0.0050 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.1576 - loss: 0.0455 - val_accuracy: 0.1935 - val_loss: 0.0050 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.1101 - loss: 0.0418 - val_accuracy: 0.1613 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1825 - loss: 0.0400\n",
            "Epoch 69: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.1816 - loss: 0.0400 - val_accuracy: 0.1183 - val_loss: 0.0053 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.0982 - loss: 0.0419 - val_accuracy: 0.1290 - val_loss: 0.0052 - learning_rate: 5.0000e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.1223 - loss: 0.0401 - val_accuracy: 0.1720 - val_loss: 0.0051 - learning_rate: 5.0000e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.1425 - loss: 0.0387 - val_accuracy: 0.1505 - val_loss: 0.0048 - learning_rate: 5.0000e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.1379 - loss: 0.0414 - val_accuracy: 0.1613 - val_loss: 0.0046 - learning_rate: 5.0000e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - accuracy: 0.1196 - loss: 0.0412 - val_accuracy: 0.1613 - val_loss: 0.0045 - learning_rate: 5.0000e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.1242 - loss: 0.0388 - val_accuracy: 0.1720 - val_loss: 0.0044 - learning_rate: 5.0000e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.1509 - loss: 0.0381 - val_accuracy: 0.1720 - val_loss: 0.0043 - learning_rate: 5.0000e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.0969 - loss: 0.0370 - val_accuracy: 0.1935 - val_loss: 0.0041 - learning_rate: 5.0000e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.1445 - loss: 0.0391 - val_accuracy: 0.1290 - val_loss: 0.0040 - learning_rate: 5.0000e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.1370 - loss: 0.0343 - val_accuracy: 0.1720 - val_loss: 0.0039 - learning_rate: 5.0000e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.1313 - loss: 0.0373 - val_accuracy: 0.1183 - val_loss: 0.0040 - learning_rate: 5.0000e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.1256 - loss: 0.0370 - val_accuracy: 0.1613 - val_loss: 0.0040 - learning_rate: 5.0000e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.1512 - loss: 0.0357 - val_accuracy: 0.1720 - val_loss: 0.0039 - learning_rate: 5.0000e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - accuracy: 0.1311 - loss: 0.0358 - val_accuracy: 0.1613 - val_loss: 0.0039 - learning_rate: 5.0000e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.1168 - loss: 0.0370 - val_accuracy: 0.1613 - val_loss: 0.0039 - learning_rate: 5.0000e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.1320 - loss: 0.0388 - val_accuracy: 0.1720 - val_loss: 0.0037 - learning_rate: 5.0000e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.1658 - loss: 0.0340 - val_accuracy: 0.1828 - val_loss: 0.0036 - learning_rate: 5.0000e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.1743 - loss: 0.0325 - val_accuracy: 0.1935 - val_loss: 0.0036 - learning_rate: 5.0000e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.1413 - loss: 0.0395 - val_accuracy: 0.2366 - val_loss: 0.0036 - learning_rate: 5.0000e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.1287 - loss: 0.0333 - val_accuracy: 0.1935 - val_loss: 0.0037 - learning_rate: 5.0000e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.1171 - loss: 0.0326 - val_accuracy: 0.1935 - val_loss: 0.0037 - learning_rate: 5.0000e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.1181 - loss: 0.0379 - val_accuracy: 0.1613 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.1216 - loss: 0.0327 - val_accuracy: 0.1505 - val_loss: 0.0037 - learning_rate: 5.0000e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.1559 - loss: 0.0330 - val_accuracy: 0.1613 - val_loss: 0.0036 - learning_rate: 5.0000e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 125ms/step - accuracy: 0.1410 - loss: 0.0342 - val_accuracy: 0.1828 - val_loss: 0.0034 - learning_rate: 5.0000e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.1084 - loss: 0.0312 - val_accuracy: 0.1828 - val_loss: 0.0034 - learning_rate: 5.0000e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.1059 - loss: 0.0340 - val_accuracy: 0.1828 - val_loss: 0.0033 - learning_rate: 5.0000e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.1504 - loss: 0.0341 - val_accuracy: 0.1720 - val_loss: 0.0034 - learning_rate: 5.0000e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.1380 - loss: 0.0313 - val_accuracy: 0.2043 - val_loss: 0.0033 - learning_rate: 5.0000e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.1502 - loss: 0.0345 - val_accuracy: 0.1720 - val_loss: 0.0033 - learning_rate: 5.0000e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.1424 - loss: 0.0347 - val_accuracy: 0.1613 - val_loss: 0.0034 - learning_rate: 5.0000e-05\n",
            "Restoring model weights from the end of the best epoch: 98.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
            "\n",
            "============================================================\n",
            "AN√ÅLISE POR COLUNA\n",
            "============================================================\n",
            "Coluna 1: 100.00% de acertos\n",
            "Coluna 2: 100.00% de acertos\n",
            "Coluna 3: 100.00% de acertos\n",
            "Coluna 4: 100.00% de acertos\n",
            "Coluna 5: 100.00% de acertos\n",
            "Coluna 6: 100.00% de acertos\n",
            "Coluna 7: 100.00% de acertos\n",
            "\n",
            "============================================================\n",
            "PREVIS√ÉO SUPER SETE - PR√ìXIMO SORTEIO (VERS√ÉO OTIMIZADA)\n",
            "============================================================\n",
            "N√∫meros previstos: [6, 6, 8, 1, 9, 6, 4]\n",
            "Acur√°cia geral do modelo: 14.94%\n",
            "√âpocas treinadas: 100\n",
            "Loss final (treino): 0.0340\n",
            "Loss final (valida√ß√£o): 0.0034\n",
            "============================================================\n",
            "\n",
            "‚ö†Ô∏è  NOTA: Loterias s√£o eventos aleat√≥rios.\n",
            "Este modelo √© apenas um exerc√≠cio de Deep Learning.\n",
            "N√£o use para apostas reais.\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# SUPER SETE - MODELO PROFISSIONAL COM ENSEMBLE E T√âCNICAS AVAN√áADAS\n",
        "# ================================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TREINAMENTO COM K-FOLD CROSS-VALIDATION (K=3)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Carregar dados\n",
        "df = pd.read_excel('Super Sete.xlsx')\n",
        "print(f\"\\nDataset carregado: {len(df)} sorteios\")\n",
        "\n",
        "# Extrair colunas de n√∫meros (assumindo que est√£o nas primeiras 7 colunas)\n",
        "numeros = df.iloc[:, :7].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "# Feature Engineering: Estat√≠sticas temporais\n",
        "def criar_features_temporais(numeros, window=10):\n",
        "    \"\"\"Criar features com estat√≠sticas temporais\"\"\"\n",
        "    n_samples = len(numeros)\n",
        "    features = []\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        # Dados hist√≥ricos recentes\n",
        "        start_idx = max(0, i - window)\n",
        "        historico = numeros[start_idx:i] if i > 0 else np.zeros((1, 7))\n",
        "\n",
        "        # Frequ√™ncia de cada d√≠gito em cada coluna\n",
        "        freq_features = []\n",
        "        for col in range(7):\n",
        "            col_data = historico[:, col] if len(historico) > 0 else []\n",
        "            for digit in range(10):\n",
        "                freq = np.sum(col_data == digit) / max(len(col_data), 1)\n",
        "                freq_features.append(freq)\n",
        "\n",
        "        # M√©dia m√≥vel por coluna\n",
        "        media_movel = np.mean(historico, axis=0) if len(historico) > 0 else np.zeros(7)\n",
        "\n",
        "        # Combinar features\n",
        "        feature_vector = np.concatenate([freq_features, media_movel])\n",
        "        features.append(feature_vector)\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "print(\"\\nCriando features temporais...\")\n",
        "X_features = criar_features_temporais(numeros, window=15)\n",
        "print(f\"Shape das features: {X_features.shape}\")\n",
        "\n",
        "# One-hot encoding para cada coluna (7 colunas x 10 d√≠gitos = 70 features)\n",
        "def one_hot_encode_super_sete(numeros):\n",
        "    \"\"\"Codificar cada coluna como one-hot (0-9)\"\"\"\n",
        "    n_samples = len(numeros)\n",
        "    encoded = np.zeros((n_samples, 7, 10))\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        for col in range(7):\n",
        "            digit = int(numeros[i, col])\n",
        "            if 0 <= digit <= 9:\n",
        "                encoded[i, col, digit] = 1\n",
        "\n",
        "    return encoded\n",
        "\n",
        "print(\"\\nCodificando n√∫meros...\")\n",
        "y_encoded = one_hot_encode_super_sete(numeros)\n",
        "print(f\"Shape dos targets: {y_encoded.shape}\")\n",
        "\n",
        "# Calcular class weights para cada coluna\n",
        "print(\"\\nCalculando class weights...\")\n",
        "class_weights_por_coluna = []\n",
        "for col in range(7):\n",
        "    col_digits = numeros[:, col]\n",
        "    unique_digits = np.unique(col_digits)\n",
        "    weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=unique_digits,\n",
        "        y=col_digits\n",
        "    )\n",
        "    weight_dict = dict(zip(unique_digits.astype(int), weights))\n",
        "    # Garantir que todos os d√≠gitos 0-9 tenham peso\n",
        "    for d in range(10):\n",
        "        if d not in weight_dict:\n",
        "            weight_dict[d] = 1.0\n",
        "    class_weights_por_coluna.append(weight_dict)\n",
        "    print(f\"Coluna {col+1} - Weights: {weight_dict}\")\n",
        "\n",
        "# Focal Loss para lidar com desbalanceamento\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def loss_fn(y_true, y_pred):\n",
        "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
        "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
        "        weight = alpha * y_true * tf.pow(1 - y_pred, gamma)\n",
        "        return tf.reduce_sum(weight * cross_entropy, axis=-1)\n",
        "    return loss_fn\n",
        "\n",
        "# Label Smoothing\n",
        "def label_smoothing(y_true, smoothing=0.1):\n",
        "    \"\"\"Aplicar label smoothing para regulariza√ß√£o\"\"\"\n",
        "    n_classes = y_true.shape[-1]\n",
        "    return y_true * (1 - smoothing) + smoothing / n_classes\n",
        "\n",
        "# Criar modelo com arquitetura ResNet + Attention\n",
        "def criar_modelo_profissional(input_shape):\n",
        "    \"\"\"Modelo com ResNet blocks e Attention mechanism\"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Camada inicial\n",
        "    x = layers.Dense(256, activation='relu')(inputs)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # ResNet Block 1\n",
        "    residual = x\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(256)(x)\n",
        "    x = layers.Add()([x, residual])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "\n",
        "    # ResNet Block 2\n",
        "    residual = x\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(256)(x)\n",
        "    x = layers.Add()([x, residual])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = layers.Dense(256, activation='tanh')(x)\n",
        "    attention = layers.Dense(256, activation='softmax')(attention)\n",
        "    x = layers.Multiply()([x, attention])\n",
        "\n",
        "    # Camadas finais\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Sa√≠das para 7 colunas (cada uma com 10 classes)\n",
        "    outputs = []\n",
        "    for i in range(7):\n",
        "        out = layers.Dense(10, activation='softmax', name=f'col_{i}')(x)\n",
        "        outputs.append(out)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Learning Rate Schedule com Warmup\n",
        "def criar_lr_schedule(initial_lr=0.0001, warmup_epochs=5, total_epochs=100):\n",
        "    def lr_schedule(epoch):\n",
        "        if epoch < warmup_epochs:\n",
        "            return initial_lr * (epoch + 1) / warmup_epochs\n",
        "        else:\n",
        "            progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
        "            return initial_lr * 0.5 * (1 + np.cos(np.pi * progress))\n",
        "    return lr_schedule\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "modelos_ensemble = []\n",
        "scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_features), 1):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"FOLD {fold}/3\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Dividir dados\n",
        "    X_train, X_val = X_features[train_idx], X_features[val_idx]\n",
        "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
        "\n",
        "    # Aplicar label smoothing\n",
        "    y_train_smooth = [label_smoothing(y_train[:, i, :], smoothing=0.1) for i in range(7)]\n",
        "    y_val_list = [y_val[:, i, :] for i in range(7)]\n",
        "\n",
        "    # Criar modelo\n",
        "    model = criar_modelo_profissional(input_shape=(X_features.shape[1],))\n",
        "\n",
        "    # Compilar com Focal Loss\n",
        "    # Fix: Provide a list of metrics with 7 entries, one for each output.\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1.0),\n",
        "        loss=focal_loss(gamma=2.0, alpha=0.25),\n",
        "        metrics=['accuracy'] * 7\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    lr_scheduler = callbacks.LearningRateScheduler(criar_lr_schedule())\n",
        "    early_stop = callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=20,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "    reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=8,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Treinar\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train_smooth,\n",
        "        validation_data=(X_val, y_val_list),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        callbacks=[lr_scheduler, early_stop, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Avaliar\n",
        "    val_results = model.evaluate(X_val, y_val_list, verbose=0)\n",
        "    # Update: The accuracy metrics are now at indices 8 to 14 (7 outputs + 1 total loss)\n",
        "    avg_accuracy = np.mean([val_results[i] for i in range(8, 15)])\n",
        "    scores.append(avg_accuracy)\n",
        "    print(f\"\\nFold {fold} - Acur√°cia de valida√ß√£o: {avg_accuracy:.2%}\")\n",
        "\n",
        "    # Salvar modelo\n",
        "    modelos_ensemble.append(model)\n",
        "\n",
        "# Resultado final do ensemble\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTADO FINAL DO ENSEMBLE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Acur√°cia m√©dia dos 3 folds: {np.mean(scores):.2%} (¬±{np.std(scores):.2%})\")\n",
        "\n",
        "# Gerar predi√ß√£o com ensemble de 3 modelos\n",
        "print(\"\\nGerando predi√ß√£o com ensemble de 3 modelos...\")\n",
        "\n",
        "# Usar os √∫ltimos dados para predi√ß√£o\n",
        "last_data = X_features[-1:]\n",
        "\n",
        "# Predi√ß√µes de todos os modelos\n",
        "predicoes = [modelo.predict(last_data, verbose=0) for modelo in modelos_ensemble]\n",
        "\n",
        "# M√©dia das predi√ß√µes (ensemble)\n",
        "predicao_ensemble = [np.mean([pred[i] for pred in predicoes], axis=0) for i in range(7)]\n",
        "\n",
        "# Selecionar os d√≠gitos com maior probabilidade\n",
        "proximos_digitos = [int(np.argmax(predicao_ensemble[i])) for i in range(7)]\n",
        "\n",
        "# Probabilidades m√©dias\n",
        "probabilidades = [np.max(predicao_ensemble[i]) for i in range(7)]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREVIS√ÉO SUPER SETE - MODELO PROFISSIONAL COM ENSEMBLE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"D√≠gitos previstos: {proximos_digitos}\")\n",
        "print(\"\\nProbabilidades por coluna:\")\n",
        "for i, prob in enumerate(probabilidades):\n",
        "    print(f\"  Coluna {i+1}: {prob*100:.2f}%\")\n",
        "\n",
        "print(f\"\\nAcur√°cia m√©dia do ensemble: {np.mean(scores):.2%}\")\n",
        "print(f\"Desvio padr√£o: {np.std(scores):.2%}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è  NOTA: Este √© um modelo educacional de Deep Learning.\")\n",
        "print(\"Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW4O5WRRG-ax",
        "outputId": "e8e5be8f-9500-4d1d-e0b5-d1e822ebc2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "TREINAMENTO COM K-FOLD CROSS-VALIDATION (K=3)\n",
            "================================================================================\n",
            "\n",
            "Dataset carregado: 770 sorteios\n",
            "\n",
            "Criando features temporais...\n",
            "Shape das features: (770, 77)\n",
            "\n",
            "Codificando n√∫meros...\n",
            "Shape dos targets: (770, 7, 10)\n",
            "\n",
            "Calculando class weights...\n",
            "Coluna 1 - Weights: {np.int64(1): np.float64(1.0), np.int64(2): np.float64(1.0), np.int64(3): np.float64(1.0), np.int64(4): np.float64(1.0), np.int64(5): np.float64(1.0), np.int64(6): np.float64(1.0), np.int64(7): np.float64(1.0), np.int64(8): np.float64(1.0), np.int64(9): np.float64(1.0), np.int64(10): np.float64(1.0), np.int64(11): np.float64(1.0), np.int64(12): np.float64(1.0), np.int64(13): np.float64(1.0), np.int64(14): np.float64(1.0), np.int64(15): np.float64(1.0), np.int64(16): np.float64(1.0), np.int64(17): np.float64(1.0), np.int64(18): np.float64(1.0), np.int64(19): np.float64(1.0), np.int64(20): np.float64(1.0), np.int64(21): np.float64(1.0), np.int64(22): np.float64(1.0), np.int64(23): np.float64(1.0), np.int64(24): np.float64(1.0), np.int64(25): np.float64(1.0), np.int64(26): np.float64(1.0), np.int64(27): np.float64(1.0), np.int64(28): np.float64(1.0), np.int64(29): np.float64(1.0), np.int64(30): np.float64(1.0), np.int64(31): np.float64(1.0), np.int64(32): np.float64(1.0), np.int64(33): np.float64(1.0), np.int64(34): np.float64(1.0), np.int64(35): np.float64(1.0), np.int64(36): np.float64(1.0), np.int64(37): np.float64(1.0), np.int64(38): np.float64(1.0), np.int64(39): np.float64(1.0), np.int64(40): np.float64(1.0), np.int64(41): np.float64(1.0), np.int64(42): np.float64(1.0), np.int64(43): np.float64(1.0), np.int64(44): np.float64(1.0), np.int64(45): np.float64(1.0), np.int64(46): np.float64(1.0), np.int64(47): np.float64(1.0), np.int64(48): np.float64(1.0), np.int64(49): np.float64(1.0), np.int64(50): np.float64(1.0), np.int64(51): np.float64(1.0), np.int64(52): np.float64(1.0), np.int64(53): np.float64(1.0), np.int64(54): np.float64(1.0), np.int64(55): np.float64(1.0), np.int64(56): np.float64(1.0), np.int64(57): np.float64(1.0), np.int64(58): np.float64(1.0), np.int64(59): np.float64(1.0), np.int64(60): np.float64(1.0), np.int64(61): np.float64(1.0), np.int64(62): np.float64(1.0), np.int64(63): np.float64(1.0), np.int64(64): np.float64(1.0), np.int64(65): np.float64(1.0), np.int64(66): np.float64(1.0), np.int64(67): np.float64(1.0), np.int64(68): np.float64(1.0), np.int64(69): np.float64(1.0), np.int64(70): np.float64(1.0), np.int64(71): np.float64(1.0), np.int64(72): np.float64(1.0), np.int64(73): np.float64(1.0), np.int64(74): np.float64(1.0), np.int64(75): np.float64(1.0), np.int64(76): np.float64(1.0), np.int64(77): np.float64(1.0), np.int64(78): np.float64(1.0), np.int64(79): np.float64(1.0), np.int64(80): np.float64(1.0), np.int64(81): np.float64(1.0), np.int64(82): np.float64(1.0), np.int64(83): np.float64(1.0), np.int64(84): np.float64(1.0), np.int64(85): np.float64(1.0), np.int64(86): np.float64(1.0), np.int64(87): np.float64(1.0), np.int64(88): np.float64(1.0), np.int64(89): np.float64(1.0), np.int64(90): np.float64(1.0), np.int64(91): np.float64(1.0), np.int64(92): np.float64(1.0), np.int64(93): np.float64(1.0), np.int64(94): np.float64(1.0), np.int64(95): np.float64(1.0), np.int64(96): np.float64(1.0), np.int64(97): np.float64(1.0), np.int64(98): np.float64(1.0), np.int64(99): np.float64(1.0), np.int64(100): np.float64(1.0), np.int64(101): np.float64(1.0), np.int64(102): np.float64(1.0), np.int64(103): np.float64(1.0), np.int64(104): np.float64(1.0), np.int64(105): np.float64(1.0), np.int64(106): np.float64(1.0), np.int64(107): np.float64(1.0), np.int64(108): np.float64(1.0), np.int64(109): np.float64(1.0), np.int64(110): np.float64(1.0), np.int64(111): np.float64(1.0), np.int64(112): np.float64(1.0), np.int64(113): np.float64(1.0), np.int64(114): np.float64(1.0), np.int64(115): np.float64(1.0), np.int64(116): np.float64(1.0), np.int64(117): np.float64(1.0), np.int64(118): np.float64(1.0), np.int64(119): np.float64(1.0), np.int64(120): np.float64(1.0), np.int64(121): np.float64(1.0), np.int64(122): np.float64(1.0), np.int64(123): np.float64(1.0), np.int64(124): np.float64(1.0), np.int64(125): np.float64(1.0), np.int64(126): np.float64(1.0), np.int64(127): np.float64(1.0), np.int64(128): np.float64(1.0), np.int64(129): np.float64(1.0), np.int64(130): np.float64(1.0), np.int64(131): np.float64(1.0), np.int64(132): np.float64(1.0), np.int64(133): np.float64(1.0), np.int64(134): np.float64(1.0), np.int64(135): np.float64(1.0), np.int64(136): np.float64(1.0), np.int64(137): np.float64(1.0), np.int64(138): np.float64(1.0), np.int64(139): np.float64(1.0), np.int64(140): np.float64(1.0), np.int64(141): np.float64(1.0), np.int64(142): np.float64(1.0), np.int64(143): np.float64(1.0), np.int64(144): np.float64(1.0), np.int64(145): np.float64(1.0), np.int64(146): np.float64(1.0), np.int64(147): np.float64(1.0), np.int64(148): np.float64(1.0), np.int64(149): np.float64(1.0), np.int64(150): np.float64(1.0), np.int64(151): np.float64(1.0), np.int64(152): np.float64(1.0), np.int64(153): np.float64(1.0), np.int64(154): np.float64(1.0), np.int64(155): np.float64(1.0), np.int64(156): np.float64(1.0), np.int64(157): np.float64(1.0), np.int64(158): np.float64(1.0), np.int64(159): np.float64(1.0), np.int64(160): np.float64(1.0), np.int64(161): np.float64(1.0), np.int64(162): np.float64(1.0), np.int64(163): np.float64(1.0), np.int64(164): np.float64(1.0), np.int64(165): np.float64(1.0), np.int64(166): np.float64(1.0), np.int64(167): np.float64(1.0), np.int64(168): np.float64(1.0), np.int64(169): np.float64(1.0), np.int64(170): np.float64(1.0), np.int64(171): np.float64(1.0), np.int64(172): np.float64(1.0), np.int64(173): np.float64(1.0), np.int64(174): np.float64(1.0), np.int64(175): np.float64(1.0), np.int64(176): np.float64(1.0), np.int64(177): np.float64(1.0), np.int64(178): np.float64(1.0), np.int64(179): np.float64(1.0), np.int64(180): np.float64(1.0), np.int64(181): np.float64(1.0), np.int64(182): np.float64(1.0), np.int64(183): np.float64(1.0), np.int64(184): np.float64(1.0), np.int64(185): np.float64(1.0), np.int64(186): np.float64(1.0), np.int64(187): np.float64(1.0), np.int64(188): np.float64(1.0), np.int64(189): np.float64(1.0), np.int64(190): np.float64(1.0), np.int64(191): np.float64(1.0), np.int64(192): np.float64(1.0), np.int64(193): np.float64(1.0), np.int64(194): np.float64(1.0), np.int64(195): np.float64(1.0), np.int64(196): np.float64(1.0), np.int64(197): np.float64(1.0), np.int64(198): np.float64(1.0), np.int64(199): np.float64(1.0), np.int64(200): np.float64(1.0), np.int64(201): np.float64(1.0), np.int64(202): np.float64(1.0), np.int64(203): np.float64(1.0), np.int64(204): np.float64(1.0), np.int64(205): np.float64(1.0), np.int64(206): np.float64(1.0), np.int64(207): np.float64(1.0), np.int64(208): np.float64(1.0), np.int64(209): np.float64(1.0), np.int64(210): np.float64(1.0), np.int64(211): np.float64(1.0), np.int64(212): np.float64(1.0), np.int64(213): np.float64(1.0), np.int64(214): np.float64(1.0), np.int64(215): np.float64(1.0), np.int64(216): np.float64(1.0), np.int64(217): np.float64(1.0), np.int64(218): np.float64(1.0), np.int64(219): np.float64(1.0), np.int64(220): np.float64(1.0), np.int64(221): np.float64(1.0), np.int64(222): np.float64(1.0), np.int64(223): np.float64(1.0), np.int64(224): np.float64(1.0), np.int64(225): np.float64(1.0), np.int64(226): np.float64(1.0), np.int64(227): np.float64(1.0), np.int64(228): np.float64(1.0), np.int64(229): np.float64(1.0), np.int64(230): np.float64(1.0), np.int64(231): np.float64(1.0), np.int64(232): np.float64(1.0), np.int64(233): np.float64(1.0), np.int64(234): np.float64(1.0), np.int64(235): np.float64(1.0), np.int64(236): np.float64(1.0), np.int64(237): np.float64(1.0), np.int64(238): np.float64(1.0), np.int64(239): np.float64(1.0), np.int64(240): np.float64(1.0), np.int64(241): np.float64(1.0), np.int64(242): np.float64(1.0), np.int64(243): np.float64(1.0), np.int64(244): np.float64(1.0), np.int64(245): np.float64(1.0), np.int64(246): np.float64(1.0), np.int64(247): np.float64(1.0), np.int64(248): np.float64(1.0), np.int64(249): np.float64(1.0), np.int64(250): np.float64(1.0), np.int64(251): np.float64(1.0), np.int64(252): np.float64(1.0), np.int64(253): np.float64(1.0), np.int64(254): np.float64(1.0), np.int64(255): np.float64(1.0), np.int64(256): np.float64(1.0), np.int64(257): np.float64(1.0), np.int64(258): np.float64(1.0), np.int64(259): np.float64(1.0), np.int64(260): np.float64(1.0), np.int64(261): np.float64(1.0), np.int64(262): np.float64(1.0), np.int64(263): np.float64(1.0), np.int64(264): np.float64(1.0), np.int64(265): np.float64(1.0), np.int64(266): np.float64(1.0), np.int64(267): np.float64(1.0), np.int64(268): np.float64(1.0), np.int64(269): np.float64(1.0), np.int64(270): np.float64(1.0), np.int64(271): np.float64(1.0), np.int64(272): np.float64(1.0), np.int64(273): np.float64(1.0), np.int64(274): np.float64(1.0), np.int64(275): np.float64(1.0), np.int64(276): np.float64(1.0), np.int64(277): np.float64(1.0), np.int64(278): np.float64(1.0), np.int64(279): np.float64(1.0), np.int64(280): np.float64(1.0), np.int64(281): np.float64(1.0), np.int64(282): np.float64(1.0), np.int64(283): np.float64(1.0), np.int64(284): np.float64(1.0), np.int64(285): np.float64(1.0), np.int64(286): np.float64(1.0), np.int64(287): np.float64(1.0), np.int64(288): np.float64(1.0), np.int64(289): np.float64(1.0), np.int64(290): np.float64(1.0), np.int64(291): np.float64(1.0), np.int64(292): np.float64(1.0), np.int64(293): np.float64(1.0), np.int64(294): np.float64(1.0), np.int64(295): np.float64(1.0), np.int64(296): np.float64(1.0), np.int64(297): np.float64(1.0), np.int64(298): np.float64(1.0), np.int64(299): np.float64(1.0), np.int64(300): np.float64(1.0), np.int64(301): np.float64(1.0), np.int64(302): np.float64(1.0), np.int64(303): np.float64(1.0), np.int64(304): np.float64(1.0), np.int64(305): np.float64(1.0), np.int64(306): np.float64(1.0), np.int64(307): np.float64(1.0), np.int64(308): np.float64(1.0), np.int64(309): np.float64(1.0), np.int64(310): np.float64(1.0), np.int64(311): np.float64(1.0), np.int64(312): np.float64(1.0), np.int64(313): np.float64(1.0), np.int64(314): np.float64(1.0), np.int64(315): np.float64(1.0), np.int64(316): np.float64(1.0), np.int64(317): np.float64(1.0), np.int64(318): np.float64(1.0), np.int64(319): np.float64(1.0), np.int64(320): np.float64(1.0), np.int64(321): np.float64(1.0), np.int64(322): np.float64(1.0), np.int64(323): np.float64(1.0), np.int64(324): np.float64(1.0), np.int64(325): np.float64(1.0), np.int64(326): np.float64(1.0), np.int64(327): np.float64(1.0), np.int64(328): np.float64(1.0), np.int64(329): np.float64(1.0), np.int64(330): np.float64(1.0), np.int64(331): np.float64(1.0), np.int64(332): np.float64(1.0), np.int64(333): np.float64(1.0), np.int64(334): np.float64(1.0), np.int64(335): np.float64(1.0), np.int64(336): np.float64(1.0), np.int64(337): np.float64(1.0), np.int64(338): np.float64(1.0), np.int64(339): np.float64(1.0), np.int64(340): np.float64(1.0), np.int64(341): np.float64(1.0), np.int64(342): np.float64(1.0), np.int64(343): np.float64(1.0), np.int64(344): np.float64(1.0), np.int64(345): np.float64(1.0), np.int64(346): np.float64(1.0), np.int64(347): np.float64(1.0), np.int64(348): np.float64(1.0), np.int64(349): np.float64(1.0), np.int64(350): np.float64(1.0), np.int64(351): np.float64(1.0), np.int64(352): np.float64(1.0), np.int64(353): np.float64(1.0), np.int64(354): np.float64(1.0), np.int64(355): np.float64(1.0), np.int64(356): np.float64(1.0), np.int64(357): np.float64(1.0), np.int64(358): np.float64(1.0), np.int64(359): np.float64(1.0), np.int64(360): np.float64(1.0), np.int64(361): np.float64(1.0), np.int64(362): np.float64(1.0), np.int64(363): np.float64(1.0), np.int64(364): np.float64(1.0), np.int64(365): np.float64(1.0), np.int64(366): np.float64(1.0), np.int64(367): np.float64(1.0), np.int64(368): np.float64(1.0), np.int64(369): np.float64(1.0), np.int64(370): np.float64(1.0), np.int64(371): np.float64(1.0), np.int64(372): np.float64(1.0), np.int64(373): np.float64(1.0), np.int64(374): np.float64(1.0), np.int64(375): np.float64(1.0), np.int64(376): np.float64(1.0), np.int64(377): np.float64(1.0), np.int64(378): np.float64(1.0), np.int64(379): np.float64(1.0), np.int64(380): np.float64(1.0), np.int64(381): np.float64(1.0), np.int64(382): np.float64(1.0), np.int64(383): np.float64(1.0), np.int64(384): np.float64(1.0), np.int64(385): np.float64(1.0), np.int64(386): np.float64(1.0), np.int64(387): np.float64(1.0), np.int64(388): np.float64(1.0), np.int64(389): np.float64(1.0), np.int64(390): np.float64(1.0), np.int64(391): np.float64(1.0), np.int64(392): np.float64(1.0), np.int64(393): np.float64(1.0), np.int64(394): np.float64(1.0), np.int64(395): np.float64(1.0), np.int64(396): np.float64(1.0), np.int64(397): np.float64(1.0), np.int64(398): np.float64(1.0), np.int64(399): np.float64(1.0), np.int64(400): np.float64(1.0), np.int64(401): np.float64(1.0), np.int64(402): np.float64(1.0), np.int64(403): np.float64(1.0), np.int64(404): np.float64(1.0), np.int64(405): np.float64(1.0), np.int64(406): np.float64(1.0), np.int64(407): np.float64(1.0), np.int64(408): np.float64(1.0), np.int64(409): np.float64(1.0), np.int64(410): np.float64(1.0), np.int64(411): np.float64(1.0), np.int64(412): np.float64(1.0), np.int64(413): np.float64(1.0), np.int64(414): np.float64(1.0), np.int64(415): np.float64(1.0), np.int64(416): np.float64(1.0), np.int64(417): np.float64(1.0), np.int64(418): np.float64(1.0), np.int64(419): np.float64(1.0), np.int64(420): np.float64(1.0), np.int64(421): np.float64(1.0), np.int64(422): np.float64(1.0), np.int64(423): np.float64(1.0), np.int64(424): np.float64(1.0), np.int64(425): np.float64(1.0), np.int64(426): np.float64(1.0), np.int64(427): np.float64(1.0), np.int64(428): np.float64(1.0), np.int64(429): np.float64(1.0), np.int64(430): np.float64(1.0), np.int64(431): np.float64(1.0), np.int64(432): np.float64(1.0), np.int64(433): np.float64(1.0), np.int64(434): np.float64(1.0), np.int64(435): np.float64(1.0), np.int64(436): np.float64(1.0), np.int64(437): np.float64(1.0), np.int64(438): np.float64(1.0), np.int64(439): np.float64(1.0), np.int64(440): np.float64(1.0), np.int64(441): np.float64(1.0), np.int64(442): np.float64(1.0), np.int64(443): np.float64(1.0), np.int64(444): np.float64(1.0), np.int64(445): np.float64(1.0), np.int64(446): np.float64(1.0), np.int64(447): np.float64(1.0), np.int64(448): np.float64(1.0), np.int64(449): np.float64(1.0), np.int64(450): np.float64(1.0), np.int64(451): np.float64(1.0), np.int64(452): np.float64(1.0), np.int64(453): np.float64(1.0), np.int64(454): np.float64(1.0), np.int64(455): np.float64(1.0), np.int64(456): np.float64(1.0), np.int64(457): np.float64(1.0), np.int64(458): np.float64(1.0), np.int64(459): np.float64(1.0), np.int64(460): np.float64(1.0), np.int64(461): np.float64(1.0), np.int64(462): np.float64(1.0), np.int64(463): np.float64(1.0), np.int64(464): np.float64(1.0), np.int64(465): np.float64(1.0), np.int64(466): np.float64(1.0), np.int64(467): np.float64(1.0), np.int64(468): np.float64(1.0), np.int64(469): np.float64(1.0), np.int64(470): np.float64(1.0), np.int64(471): np.float64(1.0), np.int64(472): np.float64(1.0), np.int64(473): np.float64(1.0), np.int64(474): np.float64(1.0), np.int64(475): np.float64(1.0), np.int64(476): np.float64(1.0), np.int64(477): np.float64(1.0), np.int64(478): np.float64(1.0), np.int64(479): np.float64(1.0), np.int64(480): np.float64(1.0), np.int64(481): np.float64(1.0), np.int64(482): np.float64(1.0), np.int64(483): np.float64(1.0), np.int64(484): np.float64(1.0), np.int64(485): np.float64(1.0), np.int64(486): np.float64(1.0), np.int64(487): np.float64(1.0), np.int64(488): np.float64(1.0), np.int64(489): np.float64(1.0), np.int64(490): np.float64(1.0), np.int64(491): np.float64(1.0), np.int64(492): np.float64(1.0), np.int64(493): np.float64(1.0), np.int64(494): np.float64(1.0), np.int64(495): np.float64(1.0), np.int64(496): np.float64(1.0), np.int64(497): np.float64(1.0), np.int64(498): np.float64(1.0), np.int64(499): np.float64(1.0), np.int64(500): np.float64(1.0), np.int64(501): np.float64(1.0), np.int64(502): np.float64(1.0), np.int64(503): np.float64(1.0), np.int64(504): np.float64(1.0), np.int64(505): np.float64(1.0), np.int64(506): np.float64(1.0), np.int64(507): np.float64(1.0), np.int64(508): np.float64(1.0), np.int64(509): np.float64(1.0), np.int64(510): np.float64(1.0), np.int64(511): np.float64(1.0), np.int64(512): np.float64(1.0), np.int64(513): np.float64(1.0), np.int64(514): np.float64(1.0), np.int64(515): np.float64(1.0), np.int64(516): np.float64(1.0), np.int64(517): np.float64(1.0), np.int64(518): np.float64(1.0), np.int64(519): np.float64(1.0), np.int64(520): np.float64(1.0), np.int64(521): np.float64(1.0), np.int64(522): np.float64(1.0), np.int64(523): np.float64(1.0), np.int64(524): np.float64(1.0), np.int64(525): np.float64(1.0), np.int64(526): np.float64(1.0), np.int64(527): np.float64(1.0), np.int64(528): np.float64(1.0), np.int64(529): np.float64(1.0), np.int64(530): np.float64(1.0), np.int64(531): np.float64(1.0), np.int64(532): np.float64(1.0), np.int64(533): np.float64(1.0), np.int64(534): np.float64(1.0), np.int64(535): np.float64(1.0), np.int64(536): np.float64(1.0), np.int64(537): np.float64(1.0), np.int64(538): np.float64(1.0), np.int64(539): np.float64(1.0), np.int64(540): np.float64(1.0), np.int64(541): np.float64(1.0), np.int64(542): np.float64(1.0), np.int64(543): np.float64(1.0), np.int64(544): np.float64(1.0), np.int64(545): np.float64(1.0), np.int64(546): np.float64(1.0), np.int64(547): np.float64(1.0), np.int64(548): np.float64(1.0), np.int64(549): np.float64(1.0), np.int64(550): np.float64(1.0), np.int64(551): np.float64(1.0), np.int64(552): np.float64(1.0), np.int64(553): np.float64(1.0), np.int64(554): np.float64(1.0), np.int64(555): np.float64(1.0), np.int64(556): np.float64(1.0), np.int64(557): np.float64(1.0), np.int64(558): np.float64(1.0), np.int64(559): np.float64(1.0), np.int64(560): np.float64(1.0), np.int64(561): np.float64(1.0), np.int64(562): np.float64(1.0), np.int64(563): np.float64(1.0), np.int64(564): np.float64(1.0), np.int64(565): np.float64(1.0), np.int64(566): np.float64(1.0), np.int64(567): np.float64(1.0), np.int64(568): np.float64(1.0), np.int64(569): np.float64(1.0), np.int64(570): np.float64(1.0), np.int64(571): np.float64(1.0), np.int64(572): np.float64(1.0), np.int64(573): np.float64(1.0), np.int64(574): np.float64(1.0), np.int64(575): np.float64(1.0), np.int64(576): np.float64(1.0), np.int64(577): np.float64(1.0), np.int64(578): np.float64(1.0), np.int64(579): np.float64(1.0), np.int64(580): np.float64(1.0), np.int64(581): np.float64(1.0), np.int64(582): np.float64(1.0), np.int64(583): np.float64(1.0), np.int64(584): np.float64(1.0), np.int64(585): np.float64(1.0), np.int64(586): np.float64(1.0), np.int64(587): np.float64(1.0), np.int64(588): np.float64(1.0), np.int64(589): np.float64(1.0), np.int64(590): np.float64(1.0), np.int64(591): np.float64(1.0), np.int64(592): np.float64(1.0), np.int64(593): np.float64(1.0), np.int64(594): np.float64(1.0), np.int64(595): np.float64(1.0), np.int64(596): np.float64(1.0), np.int64(597): np.float64(1.0), np.int64(598): np.float64(1.0), np.int64(599): np.float64(1.0), np.int64(600): np.float64(1.0), np.int64(601): np.float64(1.0), np.int64(602): np.float64(1.0), np.int64(603): np.float64(1.0), np.int64(604): np.float64(1.0), np.int64(605): np.float64(1.0), np.int64(606): np.float64(1.0), np.int64(607): np.float64(1.0), np.int64(608): np.float64(1.0), np.int64(609): np.float64(1.0), np.int64(610): np.float64(1.0), np.int64(611): np.float64(1.0), np.int64(612): np.float64(1.0), np.int64(613): np.float64(1.0), np.int64(614): np.float64(1.0), np.int64(615): np.float64(1.0), np.int64(616): np.float64(1.0), np.int64(617): np.float64(1.0), np.int64(618): np.float64(1.0), np.int64(619): np.float64(1.0), np.int64(620): np.float64(1.0), np.int64(621): np.float64(1.0), np.int64(622): np.float64(1.0), np.int64(623): np.float64(1.0), np.int64(624): np.float64(1.0), np.int64(625): np.float64(1.0), np.int64(626): np.float64(1.0), np.int64(627): np.float64(1.0), np.int64(628): np.float64(1.0), np.int64(629): np.float64(1.0), np.int64(630): np.float64(1.0), np.int64(631): np.float64(1.0), np.int64(632): np.float64(1.0), np.int64(633): np.float64(1.0), np.int64(634): np.float64(1.0), np.int64(635): np.float64(1.0), np.int64(636): np.float64(1.0), np.int64(637): np.float64(1.0), np.int64(638): np.float64(1.0), np.int64(639): np.float64(1.0), np.int64(640): np.float64(1.0), np.int64(641): np.float64(1.0), np.int64(642): np.float64(1.0), np.int64(643): np.float64(1.0), np.int64(644): np.float64(1.0), np.int64(645): np.float64(1.0), np.int64(646): np.float64(1.0), np.int64(647): np.float64(1.0), np.int64(648): np.float64(1.0), np.int64(649): np.float64(1.0), np.int64(650): np.float64(1.0), np.int64(651): np.float64(1.0), np.int64(652): np.float64(1.0), np.int64(653): np.float64(1.0), np.int64(654): np.float64(1.0), np.int64(655): np.float64(1.0), np.int64(656): np.float64(1.0), np.int64(657): np.float64(1.0), np.int64(658): np.float64(1.0), np.int64(659): np.float64(1.0), np.int64(660): np.float64(1.0), np.int64(661): np.float64(1.0), np.int64(662): np.float64(1.0), np.int64(663): np.float64(1.0), np.int64(664): np.float64(1.0), np.int64(665): np.float64(1.0), np.int64(666): np.float64(1.0), np.int64(667): np.float64(1.0), np.int64(668): np.float64(1.0), np.int64(669): np.float64(1.0), np.int64(670): np.float64(1.0), np.int64(671): np.float64(1.0), np.int64(672): np.float64(1.0), np.int64(673): np.float64(1.0), np.int64(674): np.float64(1.0), np.int64(675): np.float64(1.0), np.int64(676): np.float64(1.0), np.int64(677): np.float64(1.0), np.int64(678): np.float64(1.0), np.int64(679): np.float64(1.0), np.int64(680): np.float64(1.0), np.int64(681): np.float64(1.0), np.int64(682): np.float64(1.0), np.int64(683): np.float64(1.0), np.int64(684): np.float64(1.0), np.int64(685): np.float64(1.0), np.int64(686): np.float64(1.0), np.int64(687): np.float64(1.0), np.int64(688): np.float64(1.0), np.int64(689): np.float64(1.0), np.int64(690): np.float64(1.0), np.int64(691): np.float64(1.0), np.int64(692): np.float64(1.0), np.int64(693): np.float64(1.0), np.int64(694): np.float64(1.0), np.int64(695): np.float64(1.0), np.int64(696): np.float64(1.0), np.int64(697): np.float64(1.0), np.int64(698): np.float64(1.0), np.int64(699): np.float64(1.0), np.int64(700): np.float64(1.0), np.int64(701): np.float64(1.0), np.int64(702): np.float64(1.0), np.int64(703): np.float64(1.0), np.int64(704): np.float64(1.0), np.int64(705): np.float64(1.0), np.int64(706): np.float64(1.0), np.int64(707): np.float64(1.0), np.int64(708): np.float64(1.0), np.int64(709): np.float64(1.0), np.int64(710): np.float64(1.0), np.int64(711): np.float64(1.0), np.int64(712): np.float64(1.0), np.int64(713): np.float64(1.0), np.int64(714): np.float64(1.0), np.int64(715): np.float64(1.0), np.int64(716): np.float64(1.0), np.int64(717): np.float64(1.0), np.int64(718): np.float64(1.0), np.int64(719): np.float64(1.0), np.int64(720): np.float64(1.0), np.int64(721): np.float64(1.0), np.int64(722): np.float64(1.0), np.int64(723): np.float64(1.0), np.int64(724): np.float64(1.0), np.int64(725): np.float64(1.0), np.int64(726): np.float64(1.0), np.int64(727): np.float64(1.0), np.int64(728): np.float64(1.0), np.int64(729): np.float64(1.0), np.int64(730): np.float64(1.0), np.int64(731): np.float64(1.0), np.int64(732): np.float64(1.0), np.int64(733): np.float64(1.0), np.int64(734): np.float64(1.0), np.int64(735): np.float64(1.0), np.int64(736): np.float64(1.0), np.int64(737): np.float64(1.0), np.int64(738): np.float64(1.0), np.int64(739): np.float64(1.0), np.int64(740): np.float64(1.0), np.int64(741): np.float64(1.0), np.int64(742): np.float64(1.0), np.int64(743): np.float64(1.0), np.int64(744): np.float64(1.0), np.int64(745): np.float64(1.0), np.int64(746): np.float64(1.0), np.int64(747): np.float64(1.0), np.int64(748): np.float64(1.0), np.int64(749): np.float64(1.0), np.int64(750): np.float64(1.0), np.int64(751): np.float64(1.0), np.int64(752): np.float64(1.0), np.int64(753): np.float64(1.0), np.int64(754): np.float64(1.0), np.int64(755): np.float64(1.0), np.int64(756): np.float64(1.0), np.int64(757): np.float64(1.0), np.int64(758): np.float64(1.0), np.int64(759): np.float64(1.0), np.int64(760): np.float64(1.0), np.int64(761): np.float64(1.0), np.int64(762): np.float64(1.0), np.int64(763): np.float64(1.0), np.int64(764): np.float64(1.0), np.int64(765): np.float64(1.0), np.int64(766): np.float64(1.0), np.int64(767): np.float64(1.0), np.int64(768): np.float64(1.0), np.int64(769): np.float64(1.0), np.int64(770): np.float64(1.0), 0: 1.0}\n",
            "Coluna 2 - Weights: {np.int64(0): np.float64(1.0), 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0}\n",
            "Coluna 3 - Weights: {np.int64(0): np.float64(0.8279569892473119), np.int64(1): np.float64(1.013157894736842), np.int64(2): np.float64(1.0845070422535212), np.int64(3): np.float64(0.927710843373494), np.int64(4): np.float64(0.9746835443037974), np.int64(5): np.float64(0.9625), np.int64(6): np.float64(1.0266666666666666), np.int64(7): np.float64(1.0547945205479452), np.int64(8): np.float64(1.1492537313432836), np.int64(9): np.float64(1.0547945205479452)}\n",
            "Coluna 4 - Weights: {np.int64(0): np.float64(1.1159420289855073), np.int64(1): np.float64(1.013157894736842), np.int64(2): np.float64(1.0), np.int64(3): np.float64(0.9871794871794872), np.int64(4): np.float64(1.0694444444444444), np.int64(5): np.float64(0.9166666666666666), np.int64(6): np.float64(0.9506172839506173), np.int64(7): np.float64(0.9166666666666666), np.int64(8): np.float64(1.0266666666666666), np.int64(9): np.float64(1.0405405405405406)}\n",
            "Coluna 5 - Weights: {np.int64(0): np.float64(1.0845070422535212), np.int64(1): np.float64(0.9625), np.int64(2): np.float64(1.0266666666666666), np.int64(3): np.float64(1.013157894736842), np.int64(4): np.float64(0.9625), np.int64(5): np.float64(0.8461538461538461), np.int64(6): np.float64(1.1159420289855073), np.int64(7): np.float64(0.9625), np.int64(8): np.float64(0.9871794871794872), np.int64(9): np.float64(1.1)}\n",
            "Coluna 6 - Weights: {np.int64(0): np.float64(1.0694444444444444), np.int64(1): np.float64(0.9746835443037974), np.int64(2): np.float64(1.0), np.int64(3): np.float64(1.1323529411764706), np.int64(4): np.float64(1.1), np.int64(5): np.float64(1.0), np.int64(6): np.float64(0.8555555555555555), np.int64(7): np.float64(0.9166666666666666), np.int64(8): np.float64(1.2222222222222223), np.int64(9): np.float64(0.8555555555555555)}\n",
            "Coluna 7 - Weights: {np.int64(0): np.float64(0.9746835443037974), np.int64(1): np.float64(1.5098039215686274), np.int64(2): np.float64(1.1), np.int64(3): np.float64(0.8953488372093024), np.int64(4): np.float64(0.9871794871794872), np.int64(5): np.float64(0.9058823529411765), np.int64(6): np.float64(0.927710843373494), np.int64(7): np.float64(0.9625), np.int64(8): np.float64(0.9506172839506173), np.int64(9): np.float64(1.0)}\n",
            "\n",
            "================================================================================\n",
            "FOLD 1/3\n",
            "================================================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 97ms/step - col_0_accuracy: 0.0498 - col_0_loss: 0.0046 - col_1_accuracy: 0.1795 - col_1_loss: 0.3819 - col_2_accuracy: 0.0986 - col_2_loss: 0.3882 - col_3_accuracy: 0.1315 - col_3_loss: 0.3844 - col_4_accuracy: 0.1045 - col_4_loss: 0.3883 - col_5_accuracy: 0.0789 - col_5_loss: 0.3885 - col_6_accuracy: 0.0950 - col_6_loss: 0.3879 - loss: 2.3239 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0051 - val_col_1_accuracy: 0.9961 - val_col_1_loss: 0.3507 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4689 - val_col_3_accuracy: 0.1167 - val_col_3_loss: 0.4637 - val_col_4_accuracy: 0.0895 - val_col_4_loss: 0.4665 - val_col_5_accuracy: 0.0739 - val_col_5_loss: 0.4674 - val_col_6_accuracy: 0.1245 - val_col_6_loss: 0.4667 - val_loss: 2.6949 - learning_rate: 2.0000e-05\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0416 - col_0_loss: 0.0067 - col_1_accuracy: 0.8889 - col_1_loss: 0.3056 - col_2_accuracy: 0.1004 - col_2_loss: 0.3909 - col_3_accuracy: 0.0903 - col_3_loss: 0.3892 - col_4_accuracy: 0.1169 - col_4_loss: 0.3860 - col_5_accuracy: 0.0837 - col_5_loss: 0.3892 - col_6_accuracy: 0.0650 - col_6_loss: 0.3889 - loss: 2.2567 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0051 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.1728 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4653 - val_col_3_accuracy: 0.1089 - val_col_3_loss: 0.4608 - val_col_4_accuracy: 0.0973 - val_col_4_loss: 0.4692 - val_col_5_accuracy: 0.0700 - val_col_5_loss: 0.4668 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4662 - val_loss: 2.5199 - learning_rate: 4.0000e-05\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - col_0_accuracy: 0.0733 - col_0_loss: 0.0048 - col_1_accuracy: 0.9965 - col_1_loss: 0.1818 - col_2_accuracy: 0.1041 - col_2_loss: 0.3890 - col_3_accuracy: 0.0804 - col_3_loss: 0.3887 - col_4_accuracy: 0.1020 - col_4_loss: 0.3893 - col_5_accuracy: 0.0820 - col_5_loss: 0.3896 - col_6_accuracy: 0.0872 - col_6_loss: 0.3893 - loss: 2.1325 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0050 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0229 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4632 - val_col_3_accuracy: 0.1245 - val_col_3_loss: 0.4596 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4735 - val_col_5_accuracy: 0.0700 - val_col_5_loss: 0.4724 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4748 - val_loss: 2.4019 - learning_rate: 6.0000e-05\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - col_0_accuracy: 0.0940 - col_0_loss: 0.0050 - col_1_accuracy: 1.0000 - col_1_loss: 0.0519 - col_2_accuracy: 0.1092 - col_2_loss: 0.3827 - col_3_accuracy: 0.0706 - col_3_loss: 0.3959 - col_4_accuracy: 0.1245 - col_4_loss: 0.3840 - col_5_accuracy: 0.0806 - col_5_loss: 0.3947 - col_6_accuracy: 0.1060 - col_6_loss: 0.3867 - loss: 2.0013 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0051 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0028 - val_col_2_accuracy: 0.0817 - val_col_2_loss: 0.4673 - val_col_3_accuracy: 0.1245 - val_col_3_loss: 0.4618 - val_col_4_accuracy: 0.0973 - val_col_4_loss: 0.4795 - val_col_5_accuracy: 0.0739 - val_col_5_loss: 0.4725 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4754 - val_loss: 2.3901 - learning_rate: 8.0000e-05\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - col_0_accuracy: 0.0507 - col_0_loss: 0.0053 - col_1_accuracy: 1.0000 - col_1_loss: 0.0124 - col_2_accuracy: 0.0976 - col_2_loss: 0.3887 - col_3_accuracy: 0.0930 - col_3_loss: 0.3921 - col_4_accuracy: 0.0855 - col_4_loss: 0.3883 - col_5_accuracy: 0.1115 - col_5_loss: 0.3934 - col_6_accuracy: 0.1166 - col_6_loss: 0.3891 - loss: 1.9676 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0051 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0022 - val_col_2_accuracy: 0.1206 - val_col_2_loss: 0.4636 - val_col_3_accuracy: 0.1245 - val_col_3_loss: 0.4661 - val_col_4_accuracy: 0.1089 - val_col_4_loss: 0.4788 - val_col_5_accuracy: 0.0856 - val_col_5_loss: 0.4631 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4680 - val_loss: 2.3587 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0332 - col_0_loss: 0.0077 - col_1_accuracy: 1.0000 - col_1_loss: 0.0095 - col_2_accuracy: 0.1135 - col_2_loss: 0.3867 - col_3_accuracy: 0.0858 - col_3_loss: 0.3870 - col_4_accuracy: 0.1284 - col_4_loss: 0.3835 - col_5_accuracy: 0.1444 - col_5_loss: 0.3859 - col_6_accuracy: 0.1016 - col_6_loss: 0.3928 - loss: 1.9526 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0052 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0018 - val_col_2_accuracy: 0.0817 - val_col_2_loss: 0.4680 - val_col_3_accuracy: 0.1089 - val_col_3_loss: 0.4684 - val_col_4_accuracy: 0.1206 - val_col_4_loss: 0.4792 - val_col_5_accuracy: 0.1167 - val_col_5_loss: 0.4639 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4709 - val_loss: 2.3576 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0269 - col_0_loss: 0.0061 - col_1_accuracy: 1.0000 - col_1_loss: 0.0069 - col_2_accuracy: 0.1235 - col_2_loss: 0.3883 - col_3_accuracy: 0.0951 - col_3_loss: 0.3884 - col_4_accuracy: 0.0831 - col_4_loss: 0.3875 - col_5_accuracy: 0.1054 - col_5_loss: 0.3875 - col_6_accuracy: 0.1451 - col_6_loss: 0.3851 - loss: 1.9509 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0052 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0016 - val_col_2_accuracy: 0.0817 - val_col_2_loss: 0.4691 - val_col_3_accuracy: 0.0700 - val_col_3_loss: 0.4698 - val_col_4_accuracy: 0.0856 - val_col_4_loss: 0.4797 - val_col_5_accuracy: 0.1128 - val_col_5_loss: 0.4649 - val_col_6_accuracy: 0.1051 - val_col_6_loss: 0.4707 - val_loss: 2.3599 - learning_rate: 9.9973e-05\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.0307 - col_0_loss: 0.0078 - col_1_accuracy: 1.0000 - col_1_loss: 0.0071 - col_2_accuracy: 0.1214 - col_2_loss: 0.3898 - col_3_accuracy: 0.0844 - col_3_loss: 0.3941 - col_4_accuracy: 0.1066 - col_4_loss: 0.3863 - col_5_accuracy: 0.1113 - col_5_loss: 0.3850 - col_6_accuracy: 0.0975 - col_6_loss: 0.3916 - loss: 1.9619 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0053 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0018 - val_col_2_accuracy: 0.1206 - val_col_2_loss: 0.4660 - val_col_3_accuracy: 0.1089 - val_col_3_loss: 0.4671 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4750 - val_col_5_accuracy: 0.1089 - val_col_5_loss: 0.4657 - val_col_6_accuracy: 0.1051 - val_col_6_loss: 0.4697 - val_loss: 2.3559 - learning_rate: 9.9891e-05\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.0134 - col_0_loss: 0.0057 - col_1_accuracy: 1.0000 - col_1_loss: 0.0055 - col_2_accuracy: 0.1011 - col_2_loss: 0.3879 - col_3_accuracy: 0.1357 - col_3_loss: 0.3878 - col_4_accuracy: 0.1241 - col_4_loss: 0.3854 - col_5_accuracy: 0.1231 - col_5_loss: 0.3858 - col_6_accuracy: 0.1039 - col_6_loss: 0.3896 - loss: 1.9479 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0054 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0012 - val_col_2_accuracy: 0.1206 - val_col_2_loss: 0.4661 - val_col_3_accuracy: 0.1051 - val_col_3_loss: 0.4639 - val_col_4_accuracy: 0.1089 - val_col_4_loss: 0.4768 - val_col_5_accuracy: 0.1089 - val_col_5_loss: 0.4652 - val_col_6_accuracy: 0.1051 - val_col_6_loss: 0.4674 - val_loss: 2.3555 - learning_rate: 9.9754e-05\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - col_0_accuracy: 0.0049 - col_0_loss: 0.0072 - col_1_accuracy: 1.0000 - col_1_loss: 0.0052 - col_2_accuracy: 0.1201 - col_2_loss: 0.3851 - col_3_accuracy: 0.0968 - col_3_loss: 0.3881 - col_4_accuracy: 0.0817 - col_4_loss: 0.3900 - col_5_accuracy: 0.0901 - col_5_loss: 0.3913 - col_6_accuracy: 0.1146 - col_6_loss: 0.3855 - loss: 1.9530 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0055 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0010 - val_col_2_accuracy: 0.1206 - val_col_2_loss: 0.4656 - val_col_3_accuracy: 0.1089 - val_col_3_loss: 0.4653 - val_col_4_accuracy: 0.1089 - val_col_4_loss: 0.4762 - val_col_5_accuracy: 0.1089 - val_col_5_loss: 0.4634 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4644 - val_loss: 2.3563 - learning_rate: 9.9563e-05\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0000e+00 - col_0_loss: 0.0037 - col_1_accuracy: 1.0000 - col_1_loss: 0.0038 - col_2_accuracy: 0.1184 - col_2_loss: 0.3870 - col_3_accuracy: 0.0947 - col_3_loss: 0.3912 - col_4_accuracy: 0.1424 - col_4_loss: 0.3849 - col_5_accuracy: 0.0927 - col_5_loss: 0.3945 - col_6_accuracy: 0.0925 - col_6_loss: 0.3851 - loss: 1.9508 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0056 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0011 - val_col_2_accuracy: 0.1128 - val_col_2_loss: 0.4624 - val_col_3_accuracy: 0.0778 - val_col_3_loss: 0.4662 - val_col_4_accuracy: 0.1051 - val_col_4_loss: 0.4728 - val_col_5_accuracy: 0.1089 - val_col_5_loss: 0.4642 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4654 - val_loss: 2.3534 - learning_rate: 9.9318e-05\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0025 - col_0_loss: 0.0037 - col_1_accuracy: 1.0000 - col_1_loss: 0.0037 - col_2_accuracy: 0.1272 - col_2_loss: 0.3857 - col_3_accuracy: 0.1075 - col_3_loss: 0.3878 - col_4_accuracy: 0.1261 - col_4_loss: 0.3867 - col_5_accuracy: 0.1276 - col_5_loss: 0.3820 - col_6_accuracy: 0.1061 - col_6_loss: 0.3862 - loss: 1.9358 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0056 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 7.9966e-04 - val_col_2_accuracy: 0.1128 - val_col_2_loss: 0.4647 - val_col_3_accuracy: 0.0739 - val_col_3_loss: 0.4671 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4717 - val_col_5_accuracy: 0.1089 - val_col_5_loss: 0.4652 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4672 - val_loss: 2.3584 - learning_rate: 9.9019e-05\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0078 - col_0_loss: 0.0051 - col_1_accuracy: 1.0000 - col_1_loss: 0.0033 - col_2_accuracy: 0.1135 - col_2_loss: 0.3832 - col_3_accuracy: 0.0890 - col_3_loss: 0.3895 - col_4_accuracy: 0.1129 - col_4_loss: 0.3872 - col_5_accuracy: 0.0867 - col_5_loss: 0.3920 - col_6_accuracy: 0.1361 - col_6_loss: 0.3838 - loss: 1.9437 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0057 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0012 - val_col_2_accuracy: 0.0778 - val_col_2_loss: 0.4650 - val_col_3_accuracy: 0.0700 - val_col_3_loss: 0.4664 - val_col_4_accuracy: 0.0856 - val_col_4_loss: 0.4734 - val_col_5_accuracy: 0.1089 - val_col_5_loss: 0.4639 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4665 - val_loss: 2.3565 - learning_rate: 9.8666e-05\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 8.4307e-04 - col_0_loss: 0.0044 - col_1_accuracy: 1.0000 - col_1_loss: 0.0034 - col_2_accuracy: 0.1059 - col_2_loss: 0.3902 - col_3_accuracy: 0.1022 - col_3_loss: 0.3851 - col_4_accuracy: 0.1094 - col_4_loss: 0.3869 - col_5_accuracy: 0.1000 - col_5_loss: 0.3881 - col_6_accuracy: 0.1078 - col_6_loss: 0.3852 - loss: 1.9422 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0058 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0014 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4639 - val_col_3_accuracy: 0.0700 - val_col_3_loss: 0.4692 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4727 - val_col_5_accuracy: 0.1051 - val_col_5_loss: 0.4635 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4631 - val_loss: 2.3530 - learning_rate: 9.8260e-05\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0031 - col_0_loss: 0.0041 - col_1_accuracy: 1.0000 - col_1_loss: 0.0034 - col_2_accuracy: 0.1312 - col_2_loss: 0.3836 - col_3_accuracy: 0.0739 - col_3_loss: 0.3906 - col_4_accuracy: 0.1149 - col_4_loss: 0.3864 - col_5_accuracy: 0.1155 - col_5_loss: 0.3877 - col_6_accuracy: 0.1215 - col_6_loss: 0.3865 - loss: 1.9428 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0058 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0013 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4639 - val_col_3_accuracy: 0.1206 - val_col_3_loss: 0.4656 - val_col_4_accuracy: 0.1051 - val_col_4_loss: 0.4727 - val_col_5_accuracy: 0.1051 - val_col_5_loss: 0.4644 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4639 - val_loss: 2.3513 - learning_rate: 9.7802e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0025 - col_0_loss: 0.0042 - col_1_accuracy: 1.0000 - col_1_loss: 0.0031 - col_2_accuracy: 0.1295 - col_2_loss: 0.3865 - col_3_accuracy: 0.1236 - col_3_loss: 0.3861 - col_4_accuracy: 0.1194 - col_4_loss: 0.3880 - col_5_accuracy: 0.1043 - col_5_loss: 0.3894 - col_6_accuracy: 0.1085 - col_6_loss: 0.3885 - loss: 1.9457 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0060 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0012 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4630 - val_col_3_accuracy: 0.1167 - val_col_3_loss: 0.4633 - val_col_4_accuracy: 0.1051 - val_col_4_loss: 0.4695 - val_col_5_accuracy: 0.1245 - val_col_5_loss: 0.4651 - val_col_6_accuracy: 0.1051 - val_col_6_loss: 0.4650 - val_loss: 2.3514 - learning_rate: 9.7291e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - col_0_accuracy: 0.0031 - col_0_loss: 0.0039 - col_1_accuracy: 1.0000 - col_1_loss: 0.0030 - col_2_accuracy: 0.1079 - col_2_loss: 0.3896 - col_3_accuracy: 0.1184 - col_3_loss: 0.3876 - col_4_accuracy: 0.1089 - col_4_loss: 0.3848 - col_5_accuracy: 0.1249 - col_5_loss: 0.3876 - col_6_accuracy: 0.1053 - col_6_loss: 0.3819 - loss: 1.9389 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0061 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0011 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4636 - val_col_3_accuracy: 0.1167 - val_col_3_loss: 0.4639 - val_col_4_accuracy: 0.1051 - val_col_4_loss: 0.4707 - val_col_5_accuracy: 0.1051 - val_col_5_loss: 0.4641 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4662 - val_loss: 2.3544 - learning_rate: 9.6728e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 4.4084e-04 - col_0_loss: 0.0025 - col_1_accuracy: 1.0000 - col_1_loss: 0.0027 - col_2_accuracy: 0.0959 - col_2_loss: 0.3850 - col_3_accuracy: 0.1227 - col_3_loss: 0.3886 - col_4_accuracy: 0.1399 - col_4_loss: 0.3853 - col_5_accuracy: 0.1122 - col_5_loss: 0.3836 - col_6_accuracy: 0.0922 - col_6_loss: 0.3854 - loss: 1.9335 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0062 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0011 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4643 - val_col_3_accuracy: 0.1167 - val_col_3_loss: 0.4643 - val_col_4_accuracy: 0.1051 - val_col_4_loss: 0.4719 - val_col_5_accuracy: 0.1245 - val_col_5_loss: 0.4631 - val_col_6_accuracy: 0.1051 - val_col_6_loss: 0.4667 - val_loss: 2.3525 - learning_rate: 9.6114e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - col_0_accuracy: 0.0069 - col_0_loss: 0.0040 - col_1_accuracy: 1.0000 - col_1_loss: 0.0028 - col_2_accuracy: 0.1368 - col_2_loss: 0.3833 - col_3_accuracy: 0.1340 - col_3_loss: 0.3837 - col_4_accuracy: 0.1207 - col_4_loss: 0.3856 - col_5_accuracy: 0.1065 - col_5_loss: 0.3895 - col_6_accuracy: 0.1282 - col_6_loss: 0.3821 - loss: 1.9309 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0064 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0012 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4650 - val_col_3_accuracy: 0.1128 - val_col_3_loss: 0.4638 - val_col_4_accuracy: 0.1051 - val_col_4_loss: 0.4734 - val_col_5_accuracy: 0.1245 - val_col_5_loss: 0.4637 - val_col_6_accuracy: 0.1128 - val_col_6_loss: 0.4670 - val_loss: 2.3533 - learning_rate: 9.5450e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0000e+00 - col_0_loss: 0.0055 - col_1_accuracy: 1.0000 - col_1_loss: 0.0027 - col_2_accuracy: 0.1063 - col_2_loss: 0.3872 - col_3_accuracy: 0.0784 - col_3_loss: 0.3859 - col_4_accuracy: 0.1379 - col_4_loss: 0.3877 - col_5_accuracy: 0.0803 - col_5_loss: 0.3906 - col_6_accuracy: 0.1088 - col_6_loss: 0.3832 - loss: 1.9431 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0064 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 9.7973e-04 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4626 - val_col_3_accuracy: 0.1089 - val_col_3_loss: 0.4646 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4738 - val_col_5_accuracy: 0.1051 - val_col_5_loss: 0.4649 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4654 - val_loss: 2.3513 - learning_rate: 9.4736e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - col_0_accuracy: 0.0019 - col_0_loss: 0.0038 - col_1_accuracy: 1.0000 - col_1_loss: 0.0025 - col_2_accuracy: 0.1356 - col_2_loss: 0.3826 - col_3_accuracy: 0.1085 - col_3_loss: 0.3862 - col_4_accuracy: 0.1148 - col_4_loss: 0.3859 - col_5_accuracy: 0.1437 - col_5_loss: 0.3852 - col_6_accuracy: 0.0904 - col_6_loss: 0.3843 - loss: 1.9311 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0065 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.1535e-04 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4624 - val_col_3_accuracy: 0.0700 - val_col_3_loss: 0.4675 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4748 - val_col_5_accuracy: 0.1167 - val_col_5_loss: 0.4659 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4665 - val_loss: 2.3538 - learning_rate: 9.3974e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0086 - col_0_loss: 0.0057 - col_1_accuracy: 1.0000 - col_1_loss: 0.0023 - col_2_accuracy: 0.1329 - col_2_loss: 0.3844 - col_3_accuracy: 0.1212 - col_3_loss: 0.3878 - col_4_accuracy: 0.1205 - col_4_loss: 0.3850 - col_5_accuracy: 0.0952 - col_5_loss: 0.3859 - col_6_accuracy: 0.1245 - col_6_loss: 0.3837 - loss: 1.9349 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0066 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 7.2246e-04 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4607 - val_col_3_accuracy: 0.0739 - val_col_3_loss: 0.4667 - val_col_4_accuracy: 0.0973 - val_col_4_loss: 0.4754 - val_col_5_accuracy: 0.1089 - val_col_5_loss: 0.4654 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4671 - val_loss: 2.3547 - learning_rate: 9.3163e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - col_0_accuracy: 0.0000e+00 - col_0_loss: 0.0057 - col_1_accuracy: 1.0000 - col_1_loss: 0.0023 - col_2_accuracy: 0.1285 - col_2_loss: 0.3868 - col_3_accuracy: 0.1025 - col_3_loss: 0.3863 - col_4_accuracy: 0.1129 - col_4_loss: 0.3845 - col_5_accuracy: 0.1303 - col_5_loss: 0.3835 - col_6_accuracy: 0.0970 - col_6_loss: 0.3850 - loss: 1.9341\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.6152381401043385e-05.\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - col_0_accuracy: 0.0000e+00 - col_0_loss: 0.0057 - col_1_accuracy: 1.0000 - col_1_loss: 0.0023 - col_2_accuracy: 0.1282 - col_2_loss: 0.3867 - col_3_accuracy: 0.1026 - col_3_loss: 0.3863 - col_4_accuracy: 0.1133 - col_4_loss: 0.3842 - col_5_accuracy: 0.1295 - col_5_loss: 0.3837 - col_6_accuracy: 0.0978 - col_6_loss: 0.3853 - loss: 1.9340 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0067 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 7.4466e-04 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4613 - val_col_3_accuracy: 0.1089 - val_col_3_loss: 0.4638 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4764 - val_col_5_accuracy: 0.1089 - val_col_5_loss: 0.4653 - val_col_6_accuracy: 0.1128 - val_col_6_loss: 0.4662 - val_loss: 2.3537 - learning_rate: 9.2305e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - col_0_accuracy: 0.0061 - col_0_loss: 0.0070 - col_1_accuracy: 1.0000 - col_1_loss: 0.0022 - col_2_accuracy: 0.1026 - col_2_loss: 0.3880 - col_3_accuracy: 0.1301 - col_3_loss: 0.3845 - col_4_accuracy: 0.1324 - col_4_loss: 0.3851 - col_5_accuracy: 0.1230 - col_5_loss: 0.3858 - col_6_accuracy: 0.1028 - col_6_loss: 0.3855 - loss: 1.9381 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0068 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.3757e-04 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4640 - val_col_3_accuracy: 0.1167 - val_col_3_loss: 0.4648 - val_col_4_accuracy: 0.0934 - val_col_4_loss: 0.4766 - val_col_5_accuracy: 0.1012 - val_col_5_loss: 0.4652 - val_col_6_accuracy: 0.1128 - val_col_6_loss: 0.4660 - val_loss: 2.3538 - learning_rate: 9.1400e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - col_0_accuracy: 0.0026 - col_0_loss: 0.0026 - col_1_accuracy: 1.0000 - col_1_loss: 0.0022 - col_2_accuracy: 0.1243 - col_2_loss: 0.3877 - col_3_accuracy: 0.1058 - col_3_loss: 0.3843 - col_4_accuracy: 0.1289 - col_4_loss: 0.3852 - col_5_accuracy: 0.1129 - col_5_loss: 0.3864 - col_6_accuracy: 0.0957 - col_6_loss: 0.3859 - loss: 1.9344 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0069 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 7.6805e-04 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4659 - val_col_3_accuracy: 0.0778 - val_col_3_loss: 0.4667 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4766 - val_col_5_accuracy: 0.1051 - val_col_5_loss: 0.4652 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4653 - val_loss: 2.3575 - learning_rate: 9.0451e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - col_0_accuracy: 0.0018 - col_0_loss: 0.0055 - col_1_accuracy: 1.0000 - col_1_loss: 0.0022 - col_2_accuracy: 0.1223 - col_2_loss: 0.3823 - col_3_accuracy: 0.1507 - col_3_loss: 0.3860 - col_4_accuracy: 0.1289 - col_4_loss: 0.3852 - col_5_accuracy: 0.1110 - col_5_loss: 0.3879 - col_6_accuracy: 0.1208 - col_6_loss: 0.3863 - loss: 1.9346 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0070 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.0276e-04 - val_col_2_accuracy: 0.1206 - val_col_2_loss: 0.4670 - val_col_3_accuracy: 0.0739 - val_col_3_loss: 0.4690 - val_col_4_accuracy: 0.0778 - val_col_4_loss: 0.4767 - val_col_5_accuracy: 0.1167 - val_col_5_loss: 0.4655 - val_col_6_accuracy: 0.1167 - val_col_6_loss: 0.4632 - val_loss: 2.3582 - learning_rate: 8.9457e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0010 - col_0_loss: 0.0026 - col_1_accuracy: 1.0000 - col_1_loss: 0.0022 - col_2_accuracy: 0.1109 - col_2_loss: 0.3864 - col_3_accuracy: 0.0895 - col_3_loss: 0.3872 - col_4_accuracy: 0.1514 - col_4_loss: 0.3855 - col_5_accuracy: 0.1223 - col_5_loss: 0.3832 - col_6_accuracy: 0.1126 - col_6_loss: 0.3843 - loss: 1.9318 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0072 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0010 - val_col_2_accuracy: 0.1051 - val_col_2_loss: 0.4659 - val_col_3_accuracy: 0.0739 - val_col_3_loss: 0.4677 - val_col_4_accuracy: 0.0739 - val_col_4_loss: 0.4755 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4655 - val_col_6_accuracy: 0.1128 - val_col_6_loss: 0.4639 - val_loss: 2.3535 - learning_rate: 8.8420e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - col_0_accuracy: 0.0019 - col_0_loss: 0.0045 - col_1_accuracy: 1.0000 - col_1_loss: 0.0023 - col_2_accuracy: 0.1369 - col_2_loss: 0.3832 - col_3_accuracy: 0.0894 - col_3_loss: 0.3845 - col_4_accuracy: 0.1314 - col_4_loss: 0.3849 - col_5_accuracy: 0.1196 - col_5_loss: 0.3855 - col_6_accuracy: 0.0946 - col_6_loss: 0.3868 - loss: 1.9328 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0073 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 9.0629e-04 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4669 - val_col_3_accuracy: 0.0700 - val_col_3_loss: 0.4679 - val_col_4_accuracy: 0.0856 - val_col_4_loss: 0.4748 - val_col_5_accuracy: 0.1245 - val_col_5_loss: 0.4652 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4646 - val_loss: 2.3535 - learning_rate: 8.7341e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - col_0_accuracy: 0.0051 - col_0_loss: 0.0055 - col_1_accuracy: 1.0000 - col_1_loss: 0.0023 - col_2_accuracy: 0.1164 - col_2_loss: 0.3852 - col_3_accuracy: 0.0940 - col_3_loss: 0.3854 - col_4_accuracy: 0.0914 - col_4_loss: 0.3886 - col_5_accuracy: 0.0869 - col_5_loss: 0.3897 - col_6_accuracy: 0.1252 - col_6_loss: 0.3845 - loss: 1.9417 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0074 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.7877e-04 - val_col_2_accuracy: 0.1128 - val_col_2_loss: 0.4656 - val_col_3_accuracy: 0.0700 - val_col_3_loss: 0.4680 - val_col_4_accuracy: 0.0973 - val_col_4_loss: 0.4749 - val_col_5_accuracy: 0.1012 - val_col_5_loss: 0.4648 - val_col_6_accuracy: 0.0934 - val_col_6_loss: 0.4629 - val_loss: 2.3541 - learning_rate: 8.6221e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.0054 - col_0_loss: 0.0040 - col_1_accuracy: 1.0000 - col_1_loss: 0.0022 - col_2_accuracy: 0.1168 - col_2_loss: 0.3859 - col_3_accuracy: 0.1147 - col_3_loss: 0.3847 - col_4_accuracy: 0.0950 - col_4_loss: 0.3896 - col_5_accuracy: 0.0991 - col_5_loss: 0.3883 - col_6_accuracy: 0.1159 - col_6_loss: 0.3873 - loss: 1.9408 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0075 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.5215e-04 - val_col_2_accuracy: 0.1051 - val_col_2_loss: 0.4659 - val_col_3_accuracy: 0.1089 - val_col_3_loss: 0.4698 - val_col_4_accuracy: 0.0973 - val_col_4_loss: 0.4743 - val_col_5_accuracy: 0.1051 - val_col_5_loss: 0.4653 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4630 - val_loss: 2.3562 - learning_rate: 8.5062e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - col_0_accuracy: 0.0046 - col_0_loss: 0.0030 - col_1_accuracy: 1.0000 - col_1_loss: 0.0023 - col_2_accuracy: 0.1462 - col_2_loss: 0.3831 - col_3_accuracy: 0.1064 - col_3_loss: 0.3847 - col_4_accuracy: 0.1097 - col_4_loss: 0.3809 - col_5_accuracy: 0.0987 - col_5_loss: 0.3883 - col_6_accuracy: 0.1027 - col_6_loss: 0.3829 - loss: 1.9252\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.193203858449124e-05.\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - col_0_accuracy: 0.0043 - col_0_loss: 0.0031 - col_1_accuracy: 1.0000 - col_1_loss: 0.0023 - col_2_accuracy: 0.1432 - col_2_loss: 0.3831 - col_3_accuracy: 0.1069 - col_3_loss: 0.3851 - col_4_accuracy: 0.1112 - col_4_loss: 0.3815 - col_5_accuracy: 0.0988 - col_5_loss: 0.3883 - col_6_accuracy: 0.1039 - col_6_loss: 0.3833 - loss: 1.9261 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0076 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0012 - val_col_2_accuracy: 0.1051 - val_col_2_loss: 0.4663 - val_col_3_accuracy: 0.1128 - val_col_3_loss: 0.4680 - val_col_4_accuracy: 0.0973 - val_col_4_loss: 0.4739 - val_col_5_accuracy: 0.1051 - val_col_5_loss: 0.4642 - val_col_6_accuracy: 0.1128 - val_col_6_loss: 0.4638 - val_loss: 2.3554 - learning_rate: 8.3864e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0040 - col_0_loss: 0.0050 - col_1_accuracy: 1.0000 - col_1_loss: 0.0024 - col_2_accuracy: 0.1417 - col_2_loss: 0.3819 - col_3_accuracy: 0.1355 - col_3_loss: 0.3843 - col_4_accuracy: 0.1335 - col_4_loss: 0.3851 - col_5_accuracy: 0.0858 - col_5_loss: 0.3887 - col_6_accuracy: 0.0888 - col_6_loss: 0.3852 - loss: 1.9332 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0077 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0011 - val_col_2_accuracy: 0.1128 - val_col_2_loss: 0.4669 - val_col_3_accuracy: 0.0739 - val_col_3_loss: 0.4694 - val_col_4_accuracy: 0.0973 - val_col_4_loss: 0.4729 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4632 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4639 - val_loss: 2.3570 - learning_rate: 8.2629e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0000e+00 - col_0_loss: 0.0051 - col_1_accuracy: 1.0000 - col_1_loss: 0.0022 - col_2_accuracy: 0.0971 - col_2_loss: 0.3854 - col_3_accuracy: 0.1041 - col_3_loss: 0.3855 - col_4_accuracy: 0.1412 - col_4_loss: 0.3843 - col_5_accuracy: 0.1378 - col_5_loss: 0.3864 - col_6_accuracy: 0.1168 - col_6_loss: 0.3847 - loss: 1.9321 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0076 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 9.9173e-04 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4639 - val_col_3_accuracy: 0.0700 - val_col_3_loss: 0.4660 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4732 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4631 - val_col_6_accuracy: 0.1051 - val_col_6_loss: 0.4642 - val_loss: 2.3545 - learning_rate: 8.1359e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - col_0_accuracy: 0.0033 - col_0_loss: 0.0037 - col_1_accuracy: 1.0000 - col_1_loss: 0.0021 - col_2_accuracy: 0.1290 - col_2_loss: 0.3838 - col_3_accuracy: 0.1077 - col_3_loss: 0.3908 - col_4_accuracy: 0.1550 - col_4_loss: 0.3827 - col_5_accuracy: 0.1395 - col_5_loss: 0.3810 - col_6_accuracy: 0.1360 - col_6_loss: 0.3866 - loss: 1.9309 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0077 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 9.2603e-04 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4641 - val_col_3_accuracy: 0.0700 - val_col_3_loss: 0.4657 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4736 - val_col_5_accuracy: 0.1051 - val_col_5_loss: 0.4634 - val_col_6_accuracy: 0.1051 - val_col_6_loss: 0.4656 - val_loss: 2.3530 - learning_rate: 8.0054e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.0016 - col_0_loss: 0.0039 - col_1_accuracy: 1.0000 - col_1_loss: 0.0020 - col_2_accuracy: 0.1228 - col_2_loss: 0.3845 - col_3_accuracy: 0.1179 - col_3_loss: 0.3880 - col_4_accuracy: 0.1493 - col_4_loss: 0.3860 - col_5_accuracy: 0.1281 - col_5_loss: 0.3829 - col_6_accuracy: 0.0889 - col_6_loss: 0.3861 - loss: 1.9331 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0078 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 7.9599e-04 - val_col_2_accuracy: 0.1051 - val_col_2_loss: 0.4649 - val_col_3_accuracy: 0.0739 - val_col_3_loss: 0.4673 - val_col_4_accuracy: 0.0973 - val_col_4_loss: 0.4720 - val_col_5_accuracy: 0.1051 - val_col_5_loss: 0.4637 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4672 - val_loss: 2.3550 - learning_rate: 7.8716e-05\n",
            "Epoch 35: early stopping\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\n",
            "Fold 1 - Acur√°cia de valida√ß√£o: 22.12%\n",
            "\n",
            "================================================================================\n",
            "FOLD 2/3\n",
            "================================================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - col_0_accuracy: 0.2777 - col_0_loss: 0.0046 - col_1_accuracy: 0.1753 - col_1_loss: 0.3734 - col_2_accuracy: 0.1241 - col_2_loss: 0.3872 - col_3_accuracy: 0.0812 - col_3_loss: 0.3885 - col_4_accuracy: 0.0940 - col_4_loss: 0.3873 - col_5_accuracy: 0.1093 - col_5_loss: 0.3895 - col_6_accuracy: 0.0978 - col_6_loss: 0.3889 - loss: 2.3198 - val_col_0_accuracy: 0.2412 - val_col_0_loss: 0.0050 - val_col_1_accuracy: 0.9805 - val_col_1_loss: 0.3741 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4652 - val_col_3_accuracy: 0.0934 - val_col_3_loss: 0.4717 - val_col_4_accuracy: 0.1089 - val_col_4_loss: 0.4651 - val_col_5_accuracy: 0.0817 - val_col_5_loss: 0.4689 - val_col_6_accuracy: 0.1167 - val_col_6_loss: 0.4652 - val_loss: 2.7131 - learning_rate: 2.0000e-05\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.4131 - col_0_loss: 0.0037 - col_1_accuracy: 0.8768 - col_1_loss: 0.3023 - col_2_accuracy: 0.0988 - col_2_loss: 0.3891 - col_3_accuracy: 0.0987 - col_3_loss: 0.3870 - col_4_accuracy: 0.1105 - col_4_loss: 0.3860 - col_5_accuracy: 0.0822 - col_5_loss: 0.3880 - col_6_accuracy: 0.0832 - col_6_loss: 0.3904 - loss: 2.2463 - val_col_0_accuracy: 0.9805 - val_col_0_loss: 0.0050 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.2084 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4655 - val_col_3_accuracy: 0.0817 - val_col_3_loss: 0.4751 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4671 - val_col_5_accuracy: 0.1089 - val_col_5_loss: 0.4698 - val_col_6_accuracy: 0.1128 - val_col_6_loss: 0.4657 - val_loss: 2.5520 - learning_rate: 4.0000e-05\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - col_0_accuracy: 0.4939 - col_0_loss: 0.0048 - col_1_accuracy: 1.0000 - col_1_loss: 0.1871 - col_2_accuracy: 0.1178 - col_2_loss: 0.3875 - col_3_accuracy: 0.0860 - col_3_loss: 0.3893 - col_4_accuracy: 0.0976 - col_4_loss: 0.3913 - col_5_accuracy: 0.1017 - col_5_loss: 0.3897 - col_6_accuracy: 0.0895 - col_6_loss: 0.3893 - loss: 2.1398 - val_col_0_accuracy: 0.9805 - val_col_0_loss: 0.0051 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0469 - val_col_2_accuracy: 0.1128 - val_col_2_loss: 0.4658 - val_col_3_accuracy: 0.0778 - val_col_3_loss: 0.4861 - val_col_4_accuracy: 0.1089 - val_col_4_loss: 0.4721 - val_col_5_accuracy: 0.1206 - val_col_5_loss: 0.4759 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4697 - val_loss: 2.4134 - learning_rate: 6.0000e-05\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.4730 - col_0_loss: 0.0035 - col_1_accuracy: 1.0000 - col_1_loss: 0.0630 - col_2_accuracy: 0.1295 - col_2_loss: 0.3873 - col_3_accuracy: 0.1235 - col_3_loss: 0.3910 - col_4_accuracy: 0.1062 - col_4_loss: 0.3924 - col_5_accuracy: 0.0936 - col_5_loss: 0.3939 - col_6_accuracy: 0.0934 - col_6_loss: 0.3896 - loss: 2.0210 - val_col_0_accuracy: 0.9844 - val_col_0_loss: 0.0051 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0072 - val_col_2_accuracy: 0.1089 - val_col_2_loss: 0.4657 - val_col_3_accuracy: 0.0778 - val_col_3_loss: 0.4901 - val_col_4_accuracy: 0.1089 - val_col_4_loss: 0.4714 - val_col_5_accuracy: 0.1206 - val_col_5_loss: 0.4818 - val_col_6_accuracy: 0.1128 - val_col_6_loss: 0.4704 - val_loss: 2.3750 - learning_rate: 8.0000e-05\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - col_0_accuracy: 0.5576 - col_0_loss: 0.0028 - col_1_accuracy: 1.0000 - col_1_loss: 0.0175 - col_2_accuracy: 0.1092 - col_2_loss: 0.3909 - col_3_accuracy: 0.1077 - col_3_loss: 0.3934 - col_4_accuracy: 0.1096 - col_4_loss: 0.3934 - col_5_accuracy: 0.1288 - col_5_loss: 0.3906 - col_6_accuracy: 0.1216 - col_6_loss: 0.3869 - loss: 1.9767 - val_col_0_accuracy: 0.9883 - val_col_0_loss: 0.0053 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0038 - val_col_2_accuracy: 0.1440 - val_col_2_loss: 0.4662 - val_col_3_accuracy: 0.1206 - val_col_3_loss: 0.4777 - val_col_4_accuracy: 0.1518 - val_col_4_loss: 0.4665 - val_col_5_accuracy: 0.1206 - val_col_5_loss: 0.4795 - val_col_6_accuracy: 0.1128 - val_col_6_loss: 0.4639 - val_loss: 2.3541 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - col_0_accuracy: 0.6088 - col_0_loss: 0.0056 - col_1_accuracy: 1.0000 - col_1_loss: 0.0099 - col_2_accuracy: 0.0954 - col_2_loss: 0.3904 - col_3_accuracy: 0.0979 - col_3_loss: 0.3928 - col_4_accuracy: 0.0994 - col_4_loss: 0.3914 - col_5_accuracy: 0.1075 - col_5_loss: 0.3920 - col_6_accuracy: 0.1072 - col_6_loss: 0.3838 - loss: 1.9663 - val_col_0_accuracy: 0.9883 - val_col_0_loss: 0.0054 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0033 - val_col_2_accuracy: 0.1440 - val_col_2_loss: 0.4686 - val_col_3_accuracy: 0.1167 - val_col_3_loss: 0.4737 - val_col_4_accuracy: 0.0856 - val_col_4_loss: 0.4634 - val_col_5_accuracy: 0.1206 - val_col_5_loss: 0.4793 - val_col_6_accuracy: 0.1012 - val_col_6_loss: 0.4640 - val_loss: 2.3559 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - col_0_accuracy: 0.6769 - col_0_loss: 0.0069 - col_1_accuracy: 1.0000 - col_1_loss: 0.0087 - col_2_accuracy: 0.1042 - col_2_loss: 0.3891 - col_3_accuracy: 0.1186 - col_3_loss: 0.3913 - col_4_accuracy: 0.1204 - col_4_loss: 0.3872 - col_5_accuracy: 0.0965 - col_5_loss: 0.3875 - col_6_accuracy: 0.1071 - col_6_loss: 0.3867 - loss: 1.9566 - val_col_0_accuracy: 0.9883 - val_col_0_loss: 0.0055 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0031 - val_col_2_accuracy: 0.1440 - val_col_2_loss: 0.4679 - val_col_3_accuracy: 0.0856 - val_col_3_loss: 0.4708 - val_col_4_accuracy: 0.1012 - val_col_4_loss: 0.4644 - val_col_5_accuracy: 0.0778 - val_col_5_loss: 0.4814 - val_col_6_accuracy: 0.0973 - val_col_6_loss: 0.4648 - val_loss: 2.3587 - learning_rate: 9.9973e-05\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - col_0_accuracy: 0.7060 - col_0_loss: 0.0039 - col_1_accuracy: 1.0000 - col_1_loss: 0.0072 - col_2_accuracy: 0.1313 - col_2_loss: 0.3855 - col_3_accuracy: 0.0783 - col_3_loss: 0.3912 - col_4_accuracy: 0.1189 - col_4_loss: 0.3891 - col_5_accuracy: 0.0846 - col_5_loss: 0.3905 - col_6_accuracy: 0.1181 - col_6_loss: 0.3827 - loss: 1.9508 - val_col_0_accuracy: 0.9883 - val_col_0_loss: 0.0055 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0028 - val_col_2_accuracy: 0.1401 - val_col_2_loss: 0.4693 - val_col_3_accuracy: 0.0973 - val_col_3_loss: 0.4710 - val_col_4_accuracy: 0.0700 - val_col_4_loss: 0.4631 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4798 - val_col_6_accuracy: 0.0934 - val_col_6_loss: 0.4655 - val_loss: 2.3567 - learning_rate: 9.9891e-05\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - col_0_accuracy: 0.7601 - col_0_loss: 0.0045 - col_1_accuracy: 1.0000 - col_1_loss: 0.0063 - col_2_accuracy: 0.1093 - col_2_loss: 0.3857 - col_3_accuracy: 0.0976 - col_3_loss: 0.3877 - col_4_accuracy: 0.0891 - col_4_loss: 0.3886 - col_5_accuracy: 0.1222 - col_5_loss: 0.3868 - col_6_accuracy: 0.1026 - col_6_loss: 0.3850 - loss: 1.9447 - val_col_0_accuracy: 0.9883 - val_col_0_loss: 0.0057 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0023 - val_col_2_accuracy: 0.1401 - val_col_2_loss: 0.4709 - val_col_3_accuracy: 0.0934 - val_col_3_loss: 0.4696 - val_col_4_accuracy: 0.1051 - val_col_4_loss: 0.4624 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4772 - val_col_6_accuracy: 0.0973 - val_col_6_loss: 0.4673 - val_loss: 2.3545 - learning_rate: 9.9754e-05\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - col_0_accuracy: 0.6039 - col_0_loss: 0.0047 - col_1_accuracy: 1.0000 - col_1_loss: 0.0051 - col_2_accuracy: 0.1040 - col_2_loss: 0.3871 - col_3_accuracy: 0.1129 - col_3_loss: 0.3890 - col_4_accuracy: 0.0980 - col_4_loss: 0.3892 - col_5_accuracy: 0.0823 - col_5_loss: 0.3901 - col_6_accuracy: 0.1328 - col_6_loss: 0.3852 - loss: 1.9510 - val_col_0_accuracy: 0.9844 - val_col_0_loss: 0.0058 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0018 - val_col_2_accuracy: 0.0895 - val_col_2_loss: 0.4722 - val_col_3_accuracy: 0.0934 - val_col_3_loss: 0.4694 - val_col_4_accuracy: 0.1323 - val_col_4_loss: 0.4635 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4785 - val_col_6_accuracy: 0.0973 - val_col_6_loss: 0.4677 - val_loss: 2.3562 - learning_rate: 9.9563e-05\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.5475 - col_0_loss: 0.0031 - col_1_accuracy: 1.0000 - col_1_loss: 0.0042 - col_2_accuracy: 0.1289 - col_2_loss: 0.3864 - col_3_accuracy: 0.1173 - col_3_loss: 0.3887 - col_4_accuracy: 0.0657 - col_4_loss: 0.3913 - col_5_accuracy: 0.1145 - col_5_loss: 0.3846 - col_6_accuracy: 0.1045 - col_6_loss: 0.3864 - loss: 1.9451 - val_col_0_accuracy: 0.9767 - val_col_0_loss: 0.0058 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0018 - val_col_2_accuracy: 0.1479 - val_col_2_loss: 0.4709 - val_col_3_accuracy: 0.0934 - val_col_3_loss: 0.4702 - val_col_4_accuracy: 0.0817 - val_col_4_loss: 0.4613 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4779 - val_col_6_accuracy: 0.1051 - val_col_6_loss: 0.4663 - val_loss: 2.3578 - learning_rate: 9.9318e-05\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.5491 - col_0_loss: 0.0032 - col_1_accuracy: 1.0000 - col_1_loss: 0.0035 - col_2_accuracy: 0.0956 - col_2_loss: 0.3873 - col_3_accuracy: 0.0800 - col_3_loss: 0.3866 - col_4_accuracy: 0.1283 - col_4_loss: 0.3864 - col_5_accuracy: 0.0963 - col_5_loss: 0.3863 - col_6_accuracy: 0.0996 - col_6_loss: 0.3875 - loss: 1.9411 - val_col_0_accuracy: 0.9650 - val_col_0_loss: 0.0060 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0017 - val_col_2_accuracy: 0.1440 - val_col_2_loss: 0.4712 - val_col_3_accuracy: 0.0817 - val_col_3_loss: 0.4706 - val_col_4_accuracy: 0.0739 - val_col_4_loss: 0.4597 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4791 - val_col_6_accuracy: 0.0973 - val_col_6_loss: 0.4665 - val_loss: 2.3612 - learning_rate: 9.9019e-05\n",
            "Epoch 13/100\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - col_0_accuracy: 0.4429 - col_0_loss: 0.0057 - col_1_accuracy: 1.0000 - col_1_loss: 0.0036 - col_2_accuracy: 0.1018 - col_2_loss: 0.3841 - col_3_accuracy: 0.1014 - col_3_loss: 0.3869 - col_4_accuracy: 0.1319 - col_4_loss: 0.3861 - col_5_accuracy: 0.1197 - col_5_loss: 0.3829 - col_6_accuracy: 0.0871 - col_6_loss: 0.3867 - loss: 1.9360\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.933316449751146e-05.\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.4403 - col_0_loss: 0.0055 - col_1_accuracy: 1.0000 - col_1_loss: 0.0036 - col_2_accuracy: 0.1014 - col_2_loss: 0.3844 - col_3_accuracy: 0.1014 - col_3_loss: 0.3873 - col_4_accuracy: 0.1278 - col_4_loss: 0.3865 - col_5_accuracy: 0.1170 - col_5_loss: 0.3833 - col_6_accuracy: 0.0882 - col_6_loss: 0.3867 - loss: 1.9373 - val_col_0_accuracy: 0.0739 - val_col_0_loss: 0.0060 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0015 - val_col_2_accuracy: 0.1440 - val_col_2_loss: 0.4701 - val_col_3_accuracy: 0.0934 - val_col_3_loss: 0.4722 - val_col_4_accuracy: 0.0739 - val_col_4_loss: 0.4597 - val_col_5_accuracy: 0.1167 - val_col_5_loss: 0.4802 - val_col_6_accuracy: 0.0895 - val_col_6_loss: 0.4684 - val_loss: 2.3610 - learning_rate: 9.8666e-05\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.2267 - col_0_loss: 0.0046 - col_1_accuracy: 1.0000 - col_1_loss: 0.0035 - col_2_accuracy: 0.1157 - col_2_loss: 0.3840 - col_3_accuracy: 0.1221 - col_3_loss: 0.3856 - col_4_accuracy: 0.0919 - col_4_loss: 0.3901 - col_5_accuracy: 0.1035 - col_5_loss: 0.3909 - col_6_accuracy: 0.1120 - col_6_loss: 0.3857 - loss: 1.9445 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0061 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0014 - val_col_2_accuracy: 0.1401 - val_col_2_loss: 0.4690 - val_col_3_accuracy: 0.0934 - val_col_3_loss: 0.4728 - val_col_4_accuracy: 0.1245 - val_col_4_loss: 0.4617 - val_col_5_accuracy: 0.0895 - val_col_5_loss: 0.4803 - val_col_6_accuracy: 0.0895 - val_col_6_loss: 0.4681 - val_loss: 2.3582 - learning_rate: 9.8260e-05\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.1437 - col_0_loss: 0.0029 - col_1_accuracy: 1.0000 - col_1_loss: 0.0032 - col_2_accuracy: 0.1038 - col_2_loss: 0.3893 - col_3_accuracy: 0.1148 - col_3_loss: 0.3877 - col_4_accuracy: 0.0975 - col_4_loss: 0.3875 - col_5_accuracy: 0.0948 - col_5_loss: 0.3896 - col_6_accuracy: 0.1102 - col_6_loss: 0.3818 - loss: 1.9419 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0061 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0014 - val_col_2_accuracy: 0.1440 - val_col_2_loss: 0.4699 - val_col_3_accuracy: 0.0934 - val_col_3_loss: 0.4739 - val_col_4_accuracy: 0.0700 - val_col_4_loss: 0.4618 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4776 - val_col_6_accuracy: 0.0973 - val_col_6_loss: 0.4675 - val_loss: 2.3584 - learning_rate: 9.7802e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - col_0_accuracy: 0.0940 - col_0_loss: 0.0056 - col_1_accuracy: 1.0000 - col_1_loss: 0.0034 - col_2_accuracy: 0.1181 - col_2_loss: 0.3882 - col_3_accuracy: 0.1221 - col_3_loss: 0.3886 - col_4_accuracy: 0.1170 - col_4_loss: 0.3854 - col_5_accuracy: 0.1142 - col_5_loss: 0.3884 - col_6_accuracy: 0.0909 - col_6_loss: 0.3853 - loss: 1.9454 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0062 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0014 - val_col_2_accuracy: 0.0856 - val_col_2_loss: 0.4711 - val_col_3_accuracy: 0.0856 - val_col_3_loss: 0.4738 - val_col_4_accuracy: 0.0700 - val_col_4_loss: 0.4612 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4749 - val_col_6_accuracy: 0.0973 - val_col_6_loss: 0.4683 - val_loss: 2.3613 - learning_rate: 9.7291e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - col_0_accuracy: 0.0507 - col_0_loss: 0.0048 - col_1_accuracy: 1.0000 - col_1_loss: 0.0032 - col_2_accuracy: 0.1192 - col_2_loss: 0.3870 - col_3_accuracy: 0.0893 - col_3_loss: 0.3868 - col_4_accuracy: 0.0994 - col_4_loss: 0.3907 - col_5_accuracy: 0.1097 - col_5_loss: 0.3881 - col_6_accuracy: 0.1093 - col_6_loss: 0.3841 - loss: 1.9458 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0063 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0013 - val_col_2_accuracy: 0.0895 - val_col_2_loss: 0.4723 - val_col_3_accuracy: 0.0778 - val_col_3_loss: 0.4751 - val_col_4_accuracy: 0.1284 - val_col_4_loss: 0.4613 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4729 - val_col_6_accuracy: 0.1051 - val_col_6_loss: 0.4694 - val_loss: 2.3617 - learning_rate: 9.6728e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - col_0_accuracy: 0.0352 - col_0_loss: 0.0031 - col_1_accuracy: 1.0000 - col_1_loss: 0.0029 - col_2_accuracy: 0.0924 - col_2_loss: 0.3905 - col_3_accuracy: 0.1207 - col_3_loss: 0.3882 - col_4_accuracy: 0.1251 - col_4_loss: 0.3860 - col_5_accuracy: 0.0867 - col_5_loss: 0.3891 - col_6_accuracy: 0.1176 - col_6_loss: 0.3864 - loss: 1.9464 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0064 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0012 - val_col_2_accuracy: 0.1362 - val_col_2_loss: 0.4715 - val_col_3_accuracy: 0.0856 - val_col_3_loss: 0.4708 - val_col_4_accuracy: 0.1284 - val_col_4_loss: 0.4629 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4751 - val_col_6_accuracy: 0.0973 - val_col_6_loss: 0.4714 - val_loss: 2.3608 - learning_rate: 9.6114e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.0303 - col_0_loss: 0.0047 - col_1_accuracy: 1.0000 - col_1_loss: 0.0027 - col_2_accuracy: 0.0882 - col_2_loss: 0.3889 - col_3_accuracy: 0.1198 - col_3_loss: 0.3862 - col_4_accuracy: 0.0941 - col_4_loss: 0.3882 - col_5_accuracy: 0.1341 - col_5_loss: 0.3855 - col_6_accuracy: 0.1135 - col_6_loss: 0.3826 - loss: 1.9391 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0066 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0012 - val_col_2_accuracy: 0.1362 - val_col_2_loss: 0.4700 - val_col_3_accuracy: 0.0934 - val_col_3_loss: 0.4715 - val_col_4_accuracy: 0.1284 - val_col_4_loss: 0.4630 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4757 - val_col_6_accuracy: 0.0973 - val_col_6_loss: 0.4706 - val_loss: 2.3602 - learning_rate: 9.5450e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0086 - col_0_loss: 0.0051 - col_1_accuracy: 1.0000 - col_1_loss: 0.0028 - col_2_accuracy: 0.1452 - col_2_loss: 0.3850 - col_3_accuracy: 0.0819 - col_3_loss: 0.3892 - col_4_accuracy: 0.0889 - col_4_loss: 0.3887 - col_5_accuracy: 0.1454 - col_5_loss: 0.3826 - col_6_accuracy: 0.0764 - col_6_loss: 0.3834 - loss: 1.9359 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0067 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0011 - val_col_2_accuracy: 0.1362 - val_col_2_loss: 0.4705 - val_col_3_accuracy: 0.0778 - val_col_3_loss: 0.4736 - val_col_4_accuracy: 0.1284 - val_col_4_loss: 0.4638 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4783 - val_col_6_accuracy: 0.0973 - val_col_6_loss: 0.4683 - val_loss: 2.3593 - learning_rate: 9.4736e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - col_0_accuracy: 0.0129 - col_0_loss: 0.0039 - col_1_accuracy: 1.0000 - col_1_loss: 0.0028 - col_2_accuracy: 0.1187 - col_2_loss: 0.3903 - col_3_accuracy: 0.1267 - col_3_loss: 0.3877 - col_4_accuracy: 0.0760 - col_4_loss: 0.3909 - col_5_accuracy: 0.1265 - col_5_loss: 0.3843 - col_6_accuracy: 0.1032 - col_6_loss: 0.3830 - loss: 1.9429\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.698684278992005e-05.\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - col_0_accuracy: 0.0131 - col_0_loss: 0.0040 - col_1_accuracy: 1.0000 - col_1_loss: 0.0028 - col_2_accuracy: 0.1184 - col_2_loss: 0.3899 - col_3_accuracy: 0.1267 - col_3_loss: 0.3880 - col_4_accuracy: 0.0794 - col_4_loss: 0.3901 - col_5_accuracy: 0.1292 - col_5_loss: 0.3846 - col_6_accuracy: 0.1042 - col_6_loss: 0.3835 - loss: 1.9426 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0068 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0013 - val_col_2_accuracy: 0.1401 - val_col_2_loss: 0.4705 - val_col_3_accuracy: 0.0778 - val_col_3_loss: 0.4738 - val_col_4_accuracy: 0.1284 - val_col_4_loss: 0.4641 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4772 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4681 - val_loss: 2.3571 - learning_rate: 9.3974e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0103 - col_0_loss: 0.0039 - col_1_accuracy: 1.0000 - col_1_loss: 0.0029 - col_2_accuracy: 0.0904 - col_2_loss: 0.3871 - col_3_accuracy: 0.0810 - col_3_loss: 0.3874 - col_4_accuracy: 0.1009 - col_4_loss: 0.3891 - col_5_accuracy: 0.1202 - col_5_loss: 0.3862 - col_6_accuracy: 0.1147 - col_6_loss: 0.3842 - loss: 1.9410 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0068 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0012 - val_col_2_accuracy: 0.1401 - val_col_2_loss: 0.4701 - val_col_3_accuracy: 0.0856 - val_col_3_loss: 0.4723 - val_col_4_accuracy: 0.1284 - val_col_4_loss: 0.4647 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4770 - val_col_6_accuracy: 0.1128 - val_col_6_loss: 0.4663 - val_loss: 2.3548 - learning_rate: 9.3163e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - col_0_accuracy: 0.0068 - col_0_loss: 0.0035 - col_1_accuracy: 1.0000 - col_1_loss: 0.0027 - col_2_accuracy: 0.1197 - col_2_loss: 0.3831 - col_3_accuracy: 0.0962 - col_3_loss: 0.3893 - col_4_accuracy: 0.0976 - col_4_loss: 0.3913 - col_5_accuracy: 0.1519 - col_5_loss: 0.3847 - col_6_accuracy: 0.1187 - col_6_loss: 0.3864 - loss: 1.9411 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0069 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0012 - val_col_2_accuracy: 0.1440 - val_col_2_loss: 0.4698 - val_col_3_accuracy: 0.0856 - val_col_3_loss: 0.4725 - val_col_4_accuracy: 0.1284 - val_col_4_loss: 0.4649 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4776 - val_col_6_accuracy: 0.1089 - val_col_6_loss: 0.4665 - val_loss: 2.3572 - learning_rate: 9.2305e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.0018 - col_0_loss: 0.0041 - col_1_accuracy: 1.0000 - col_1_loss: 0.0024 - col_2_accuracy: 0.1101 - col_2_loss: 0.3852 - col_3_accuracy: 0.1409 - col_3_loss: 0.3850 - col_4_accuracy: 0.1025 - col_4_loss: 0.3859 - col_5_accuracy: 0.0878 - col_5_loss: 0.3880 - col_6_accuracy: 0.0994 - col_6_loss: 0.3864 - loss: 1.9364 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0071 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0012 - val_col_2_accuracy: 0.0895 - val_col_2_loss: 0.4691 - val_col_3_accuracy: 0.0856 - val_col_3_loss: 0.4732 - val_col_4_accuracy: 0.1284 - val_col_4_loss: 0.4645 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4777 - val_col_6_accuracy: 0.1128 - val_col_6_loss: 0.4673 - val_loss: 2.3595 - learning_rate: 9.1400e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.0061 - col_0_loss: 0.0070 - col_1_accuracy: 1.0000 - col_1_loss: 0.0026 - col_2_accuracy: 0.1322 - col_2_loss: 0.3838 - col_3_accuracy: 0.1360 - col_3_loss: 0.3857 - col_4_accuracy: 0.1183 - col_4_loss: 0.3885 - col_5_accuracy: 0.0916 - col_5_loss: 0.3869 - col_6_accuracy: 0.0966 - col_6_loss: 0.3829 - loss: 1.9388 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0072 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0012 - val_col_2_accuracy: 0.0895 - val_col_2_loss: 0.4680 - val_col_3_accuracy: 0.0856 - val_col_3_loss: 0.4743 - val_col_4_accuracy: 0.1284 - val_col_4_loss: 0.4642 - val_col_5_accuracy: 0.0973 - val_col_5_loss: 0.4761 - val_col_6_accuracy: 0.1051 - val_col_6_loss: 0.4682 - val_loss: 2.3574 - learning_rate: 9.0451e-05\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\n",
            "Fold 2 - Acur√°cia de valida√ß√£o: 37.69%\n",
            "\n",
            "================================================================================\n",
            "FOLD 3/3\n",
            "================================================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 130ms/step - col_0_accuracy: 0.0654 - col_0_loss: 0.0028 - col_1_accuracy: 0.2639 - col_1_loss: 0.3720 - col_2_accuracy: 0.0863 - col_2_loss: 0.3872 - col_3_accuracy: 0.1100 - col_3_loss: 0.3865 - col_4_accuracy: 0.0939 - col_4_loss: 0.3874 - col_5_accuracy: 0.1084 - col_5_loss: 0.3863 - col_6_accuracy: 0.0977 - col_6_loss: 0.3887 - loss: 2.3109 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0055 - val_col_1_accuracy: 0.9961 - val_col_1_loss: 0.3497 - val_col_2_accuracy: 0.0742 - val_col_2_loss: 0.4685 - val_col_3_accuracy: 0.1133 - val_col_3_loss: 0.4671 - val_col_4_accuracy: 0.1133 - val_col_4_loss: 0.4672 - val_col_5_accuracy: 0.0703 - val_col_5_loss: 0.4677 - val_col_6_accuracy: 0.0898 - val_col_6_loss: 0.4692 - val_loss: 2.6949 - learning_rate: 2.0000e-05\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - col_0_accuracy: 0.0860 - col_0_loss: 0.0045 - col_1_accuracy: 0.9651 - col_1_loss: 0.2950 - col_2_accuracy: 0.0914 - col_2_loss: 0.3868 - col_3_accuracy: 0.0848 - col_3_loss: 0.3891 - col_4_accuracy: 0.0921 - col_4_loss: 0.3890 - col_5_accuracy: 0.0893 - col_5_loss: 0.3899 - col_6_accuracy: 0.1224 - col_6_loss: 0.3875 - loss: 2.2422 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0055 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.1968 - val_col_2_accuracy: 0.0742 - val_col_2_loss: 0.4691 - val_col_3_accuracy: 0.1133 - val_col_3_loss: 0.4666 - val_col_4_accuracy: 0.1172 - val_col_4_loss: 0.4673 - val_col_5_accuracy: 0.0898 - val_col_5_loss: 0.4676 - val_col_6_accuracy: 0.0938 - val_col_6_loss: 0.4697 - val_loss: 2.5426 - learning_rate: 4.0000e-05\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - col_0_accuracy: 0.1361 - col_0_loss: 0.0053 - col_1_accuracy: 1.0000 - col_1_loss: 0.1772 - col_2_accuracy: 0.1172 - col_2_loss: 0.3840 - col_3_accuracy: 0.1102 - col_3_loss: 0.3881 - col_4_accuracy: 0.1013 - col_4_loss: 0.3883 - col_5_accuracy: 0.0941 - col_5_loss: 0.3900 - col_6_accuracy: 0.1336 - col_6_loss: 0.3878 - loss: 2.1213 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0054 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0532 - val_col_2_accuracy: 0.0742 - val_col_2_loss: 0.4701 - val_col_3_accuracy: 0.1016 - val_col_3_loss: 0.4673 - val_col_4_accuracy: 0.0898 - val_col_4_loss: 0.4685 - val_col_5_accuracy: 0.0977 - val_col_5_loss: 0.4685 - val_col_6_accuracy: 0.0938 - val_col_6_loss: 0.4706 - val_loss: 2.4037 - learning_rate: 6.0000e-05\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - col_0_accuracy: 0.2687 - col_0_loss: 0.0044 - col_1_accuracy: 1.0000 - col_1_loss: 0.0623 - col_2_accuracy: 0.1175 - col_2_loss: 0.3853 - col_3_accuracy: 0.1033 - col_3_loss: 0.3891 - col_4_accuracy: 0.1137 - col_4_loss: 0.3884 - col_5_accuracy: 0.0974 - col_5_loss: 0.3912 - col_6_accuracy: 0.0929 - col_6_loss: 0.3912 - loss: 2.0123 - val_col_0_accuracy: 0.9688 - val_col_0_loss: 0.0054 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0065 - val_col_2_accuracy: 0.1133 - val_col_2_loss: 0.4720 - val_col_3_accuracy: 0.0820 - val_col_3_loss: 0.4691 - val_col_4_accuracy: 0.1172 - val_col_4_loss: 0.4698 - val_col_5_accuracy: 0.1055 - val_col_5_loss: 0.4684 - val_col_6_accuracy: 0.0938 - val_col_6_loss: 0.4713 - val_loss: 2.3624 - learning_rate: 8.0000e-05\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.3721 - col_0_loss: 0.0044 - col_1_accuracy: 1.0000 - col_1_loss: 0.0139 - col_2_accuracy: 0.1370 - col_2_loss: 0.3880 - col_3_accuracy: 0.1100 - col_3_loss: 0.3856 - col_4_accuracy: 0.0964 - col_4_loss: 0.3900 - col_5_accuracy: 0.1143 - col_5_loss: 0.3875 - col_6_accuracy: 0.1239 - col_6_loss: 0.3866 - loss: 1.9557 - val_col_0_accuracy: 0.9688 - val_col_0_loss: 0.0055 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0020 - val_col_2_accuracy: 0.1172 - val_col_2_loss: 0.4708 - val_col_3_accuracy: 0.0820 - val_col_3_loss: 0.4704 - val_col_4_accuracy: 0.0898 - val_col_4_loss: 0.4674 - val_col_5_accuracy: 0.1445 - val_col_5_loss: 0.4655 - val_col_6_accuracy: 0.0938 - val_col_6_loss: 0.4674 - val_loss: 2.3490 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.1613 - col_0_loss: 0.0052 - col_1_accuracy: 1.0000 - col_1_loss: 0.0067 - col_2_accuracy: 0.1121 - col_2_loss: 0.3870 - col_3_accuracy: 0.1394 - col_3_loss: 0.3846 - col_4_accuracy: 0.0884 - col_4_loss: 0.3906 - col_5_accuracy: 0.0992 - col_5_loss: 0.3908 - col_6_accuracy: 0.0912 - col_6_loss: 0.3896 - loss: 1.9544 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0056 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0016 - val_col_2_accuracy: 0.1172 - val_col_2_loss: 0.4695 - val_col_3_accuracy: 0.0820 - val_col_3_loss: 0.4689 - val_col_4_accuracy: 0.0898 - val_col_4_loss: 0.4662 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4668 - val_col_6_accuracy: 0.1133 - val_col_6_loss: 0.4637 - val_loss: 2.3423 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - col_0_accuracy: 0.0760 - col_0_loss: 0.0044 - col_1_accuracy: 1.0000 - col_1_loss: 0.0053 - col_2_accuracy: 0.1266 - col_2_loss: 0.3853 - col_3_accuracy: 0.1365 - col_3_loss: 0.3849 - col_4_accuracy: 0.1162 - col_4_loss: 0.3871 - col_5_accuracy: 0.1073 - col_5_loss: 0.3892 - col_6_accuracy: 0.1123 - col_6_loss: 0.3863 - loss: 1.9434 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0056 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0011 - val_col_2_accuracy: 0.1172 - val_col_2_loss: 0.4704 - val_col_3_accuracy: 0.0859 - val_col_3_loss: 0.4704 - val_col_4_accuracy: 0.0898 - val_col_4_loss: 0.4687 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4683 - val_col_6_accuracy: 0.1211 - val_col_6_loss: 0.4644 - val_loss: 2.3489 - learning_rate: 9.9973e-05\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - col_0_accuracy: 0.0336 - col_0_loss: 0.0034 - col_1_accuracy: 1.0000 - col_1_loss: 0.0041 - col_2_accuracy: 0.1066 - col_2_loss: 0.3850 - col_3_accuracy: 0.1373 - col_3_loss: 0.3863 - col_4_accuracy: 0.1187 - col_4_loss: 0.3844 - col_5_accuracy: 0.1311 - col_5_loss: 0.3872 - col_6_accuracy: 0.1129 - col_6_loss: 0.3871 - loss: 1.9366 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0057 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.3420e-04 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4692 - val_col_3_accuracy: 0.0977 - val_col_3_loss: 0.4697 - val_col_4_accuracy: 0.0898 - val_col_4_loss: 0.4676 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4674 - val_col_6_accuracy: 0.0664 - val_col_6_loss: 0.4641 - val_loss: 2.3444 - learning_rate: 9.9891e-05\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - col_0_accuracy: 0.0437 - col_0_loss: 0.0033 - col_1_accuracy: 1.0000 - col_1_loss: 0.0037 - col_2_accuracy: 0.1070 - col_2_loss: 0.3888 - col_3_accuracy: 0.0903 - col_3_loss: 0.3911 - col_4_accuracy: 0.1025 - col_4_loss: 0.3874 - col_5_accuracy: 0.1240 - col_5_loss: 0.3918 - col_6_accuracy: 0.1285 - col_6_loss: 0.3858 - loss: 1.9517 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0058 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0011 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4679 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4701 - val_col_4_accuracy: 0.1211 - val_col_4_loss: 0.4645 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4683 - val_col_6_accuracy: 0.0938 - val_col_6_loss: 0.4649 - val_loss: 2.3425 - learning_rate: 9.9754e-05\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.0295 - col_0_loss: 0.0031 - col_1_accuracy: 1.0000 - col_1_loss: 0.0037 - col_2_accuracy: 0.0847 - col_2_loss: 0.3905 - col_3_accuracy: 0.1344 - col_3_loss: 0.3842 - col_4_accuracy: 0.1188 - col_4_loss: 0.3873 - col_5_accuracy: 0.0941 - col_5_loss: 0.3904 - col_6_accuracy: 0.0998 - col_6_loss: 0.3876 - loss: 1.9464 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0059 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0011 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4681 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4711 - val_col_4_accuracy: 0.1250 - val_col_4_loss: 0.4654 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4687 - val_col_6_accuracy: 0.0938 - val_col_6_loss: 0.4642 - val_loss: 2.3445 - learning_rate: 9.9563e-05\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0041 - col_0_loss: 0.0043 - col_1_accuracy: 1.0000 - col_1_loss: 0.0035 - col_2_accuracy: 0.1231 - col_2_loss: 0.3853 - col_3_accuracy: 0.1304 - col_3_loss: 0.3903 - col_4_accuracy: 0.1249 - col_4_loss: 0.3854 - col_5_accuracy: 0.1320 - col_5_loss: 0.3842 - col_6_accuracy: 0.1006 - col_6_loss: 0.3858 - loss: 1.9385 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0060 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 0.0011 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4678 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4703 - val_col_4_accuracy: 0.1250 - val_col_4_loss: 0.4663 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4675 - val_col_6_accuracy: 0.0625 - val_col_6_loss: 0.4659 - val_loss: 2.3449 - learning_rate: 9.9318e-05\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - col_0_accuracy: 0.0063 - col_0_loss: 0.0034 - col_1_accuracy: 1.0000 - col_1_loss: 0.0033 - col_2_accuracy: 0.1492 - col_2_loss: 0.3829 - col_3_accuracy: 0.1143 - col_3_loss: 0.3873 - col_4_accuracy: 0.1321 - col_4_loss: 0.3836 - col_5_accuracy: 0.1210 - col_5_loss: 0.3869 - col_6_accuracy: 0.1042 - col_6_loss: 0.3845 - loss: 1.9315 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0061 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 9.8041e-04 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4678 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4709 - val_col_4_accuracy: 0.0977 - val_col_4_loss: 0.4679 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4674 - val_col_6_accuracy: 0.1094 - val_col_6_loss: 0.4652 - val_loss: 2.3463 - learning_rate: 9.9019e-05\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0099 - col_0_loss: 0.0039 - col_1_accuracy: 1.0000 - col_1_loss: 0.0033 - col_2_accuracy: 0.0941 - col_2_loss: 0.3882 - col_3_accuracy: 0.1205 - col_3_loss: 0.3879 - col_4_accuracy: 0.0787 - col_4_loss: 0.3904 - col_5_accuracy: 0.1060 - col_5_loss: 0.3852 - col_6_accuracy: 0.1271 - col_6_loss: 0.3826 - loss: 1.9418 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0062 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 9.7956e-04 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4684 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4701 - val_col_4_accuracy: 0.1055 - val_col_4_loss: 0.4679 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4664 - val_col_6_accuracy: 0.1094 - val_col_6_loss: 0.4654 - val_loss: 2.3453 - learning_rate: 9.8666e-05\n",
            "Epoch 14/100\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - col_0_accuracy: 2.8770e-04 - col_0_loss: 0.0063 - col_1_accuracy: 1.0000 - col_1_loss: 0.0031 - col_2_accuracy: 0.0977 - col_2_loss: 0.3903 - col_3_accuracy: 0.1053 - col_3_loss: 0.3851 - col_4_accuracy: 0.1265 - col_4_loss: 0.3844 - col_5_accuracy: 0.0976 - col_5_loss: 0.3904 - col_6_accuracy: 0.0869 - col_6_loss: 0.3894 - loss: 1.9489\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.913022348773666e-05.\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 5.6443e-04 - col_0_loss: 0.0060 - col_1_accuracy: 1.0000 - col_1_loss: 0.0030 - col_2_accuracy: 0.0970 - col_2_loss: 0.3905 - col_3_accuracy: 0.1027 - col_3_loss: 0.3857 - col_4_accuracy: 0.1223 - col_4_loss: 0.3849 - col_5_accuracy: 0.1017 - col_5_loss: 0.3895 - col_6_accuracy: 0.0870 - col_6_loss: 0.3892 - loss: 1.9488 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0063 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.6062e-04 - val_col_2_accuracy: 0.1250 - val_col_2_loss: 0.4687 - val_col_3_accuracy: 0.0820 - val_col_3_loss: 0.4706 - val_col_4_accuracy: 0.1211 - val_col_4_loss: 0.4672 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4668 - val_col_6_accuracy: 0.0859 - val_col_6_loss: 0.4667 - val_loss: 2.3472 - learning_rate: 9.8260e-05\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.0025 - col_0_loss: 0.0059 - col_1_accuracy: 1.0000 - col_1_loss: 0.0029 - col_2_accuracy: 0.1380 - col_2_loss: 0.3859 - col_3_accuracy: 0.1358 - col_3_loss: 0.3878 - col_4_accuracy: 0.1165 - col_4_loss: 0.3884 - col_5_accuracy: 0.1116 - col_5_loss: 0.3867 - col_6_accuracy: 0.1086 - col_6_loss: 0.3901 - loss: 1.9482 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0063 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.1211e-04 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4681 - val_col_3_accuracy: 0.0820 - val_col_3_loss: 0.4707 - val_col_4_accuracy: 0.1211 - val_col_4_loss: 0.4670 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4682 - val_col_6_accuracy: 0.1016 - val_col_6_loss: 0.4658 - val_loss: 2.3470 - learning_rate: 9.7802e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.0018 - col_0_loss: 0.0053 - col_1_accuracy: 1.0000 - col_1_loss: 0.0026 - col_2_accuracy: 0.1072 - col_2_loss: 0.3872 - col_3_accuracy: 0.1169 - col_3_loss: 0.3826 - col_4_accuracy: 0.1176 - col_4_loss: 0.3854 - col_5_accuracy: 0.1160 - col_5_loss: 0.3871 - col_6_accuracy: 0.1307 - col_6_loss: 0.3852 - loss: 1.9365 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0064 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 7.2578e-04 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4697 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4714 - val_col_4_accuracy: 0.0859 - val_col_4_loss: 0.4685 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4692 - val_col_6_accuracy: 0.1250 - val_col_6_loss: 0.4652 - val_loss: 2.3511 - learning_rate: 9.7291e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - col_0_accuracy: 0.0014 - col_0_loss: 0.0048 - col_1_accuracy: 1.0000 - col_1_loss: 0.0026 - col_2_accuracy: 0.1109 - col_2_loss: 0.3879 - col_3_accuracy: 0.1274 - col_3_loss: 0.3889 - col_4_accuracy: 0.1478 - col_4_loss: 0.3876 - col_5_accuracy: 0.1044 - col_5_loss: 0.3862 - col_6_accuracy: 0.1342 - col_6_loss: 0.3845 - loss: 1.9419 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0065 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.1881e-04 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4711 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4732 - val_col_4_accuracy: 0.0859 - val_col_4_loss: 0.4694 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4695 - val_col_6_accuracy: 0.1289 - val_col_6_loss: 0.4652 - val_loss: 2.3559 - learning_rate: 9.6728e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 4.4042e-04 - col_0_loss: 0.0041 - col_1_accuracy: 1.0000 - col_1_loss: 0.0026 - col_2_accuracy: 0.1343 - col_2_loss: 0.3875 - col_3_accuracy: 0.1298 - col_3_loss: 0.3869 - col_4_accuracy: 0.1081 - col_4_loss: 0.3877 - col_5_accuracy: 0.0797 - col_5_loss: 0.3879 - col_6_accuracy: 0.0933 - col_6_loss: 0.3855 - loss: 1.9416 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0066 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.7312e-04 - val_col_2_accuracy: 0.1250 - val_col_2_loss: 0.4707 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4730 - val_col_4_accuracy: 0.0859 - val_col_4_loss: 0.4691 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4675 - val_col_6_accuracy: 0.1055 - val_col_6_loss: 0.4672 - val_loss: 2.3550 - learning_rate: 9.6114e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - col_0_accuracy: 0.0000e+00 - col_0_loss: 0.0044 - col_1_accuracy: 1.0000 - col_1_loss: 0.0026 - col_2_accuracy: 0.1241 - col_2_loss: 0.3837 - col_3_accuracy: 0.1084 - col_3_loss: 0.3870 - col_4_accuracy: 0.0999 - col_4_loss: 0.3877 - col_5_accuracy: 0.1392 - col_5_loss: 0.3832 - col_6_accuracy: 0.0841 - col_6_loss: 0.3876 - loss: 1.9361 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0066 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.8144e-04 - val_col_2_accuracy: 0.1250 - val_col_2_loss: 0.4694 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4713 - val_col_4_accuracy: 0.0859 - val_col_4_loss: 0.4675 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4675 - val_col_6_accuracy: 0.0820 - val_col_6_loss: 0.4671 - val_loss: 2.3504 - learning_rate: 9.5450e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - col_0_accuracy: 0.0021 - col_0_loss: 0.0046 - col_1_accuracy: 1.0000 - col_1_loss: 0.0027 - col_2_accuracy: 0.0911 - col_2_loss: 0.3893 - col_3_accuracy: 0.1213 - col_3_loss: 0.3885 - col_4_accuracy: 0.1129 - col_4_loss: 0.3845 - col_5_accuracy: 0.1409 - col_5_loss: 0.3848 - col_6_accuracy: 0.1220 - col_6_loss: 0.3844 - loss: 1.9389 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0067 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.4205e-04 - val_col_2_accuracy: 0.1250 - val_col_2_loss: 0.4693 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4708 - val_col_4_accuracy: 0.1211 - val_col_4_loss: 0.4667 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4682 - val_col_6_accuracy: 0.1055 - val_col_6_loss: 0.4660 - val_loss: 2.3486 - learning_rate: 9.4736e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - col_0_accuracy: 5.6443e-04 - col_0_loss: 0.0026 - col_1_accuracy: 1.0000 - col_1_loss: 0.0024 - col_2_accuracy: 0.1023 - col_2_loss: 0.3886 - col_3_accuracy: 0.1098 - col_3_loss: 0.3875 - col_4_accuracy: 0.1192 - col_4_loss: 0.3871 - col_5_accuracy: 0.1198 - col_5_loss: 0.3859 - col_6_accuracy: 0.1106 - col_6_loss: 0.3860 - loss: 1.9404 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0068 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 7.9449e-04 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4689 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4708 - val_col_4_accuracy: 0.1211 - val_col_4_loss: 0.4668 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4678 - val_col_6_accuracy: 0.1094 - val_col_6_loss: 0.4662 - val_loss: 2.3481 - learning_rate: 9.3974e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - col_0_accuracy: 0.0037 - col_0_loss: 0.0040 - col_1_accuracy: 1.0000 - col_1_loss: 0.0024 - col_2_accuracy: 0.1184 - col_2_loss: 0.3861 - col_3_accuracy: 0.1199 - col_3_loss: 0.3846 - col_4_accuracy: 0.1008 - col_4_loss: 0.3863 - col_5_accuracy: 0.1167 - col_5_loss: 0.3871 - col_6_accuracy: 0.0893 - col_6_loss: 0.3880 - loss: 1.9379\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.658141187974252e-05.\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - col_0_accuracy: 0.0037 - col_0_loss: 0.0040 - col_1_accuracy: 1.0000 - col_1_loss: 0.0024 - col_2_accuracy: 0.1181 - col_2_loss: 0.3863 - col_3_accuracy: 0.1200 - col_3_loss: 0.3847 - col_4_accuracy: 0.1006 - col_4_loss: 0.3864 - col_5_accuracy: 0.1172 - col_5_loss: 0.3873 - col_6_accuracy: 0.0900 - col_6_loss: 0.3879 - loss: 1.9380 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0069 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 7.1141e-04 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4684 - val_col_3_accuracy: 0.0938 - val_col_3_loss: 0.4706 - val_col_4_accuracy: 0.1211 - val_col_4_loss: 0.4670 - val_col_5_accuracy: 0.0977 - val_col_5_loss: 0.4663 - val_col_6_accuracy: 0.1094 - val_col_6_loss: 0.4666 - val_loss: 2.3465 - learning_rate: 9.3163e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - col_0_accuracy: 0.0029 - col_0_loss: 0.0023 - col_1_accuracy: 1.0000 - col_1_loss: 0.0022 - col_2_accuracy: 0.1301 - col_2_loss: 0.3865 - col_3_accuracy: 0.0975 - col_3_loss: 0.3864 - col_4_accuracy: 0.1187 - col_4_loss: 0.3863 - col_5_accuracy: 0.1232 - col_5_loss: 0.3860 - col_6_accuracy: 0.0967 - col_6_loss: 0.3880 - loss: 1.9376 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0070 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 7.5014e-04 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4686 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4700 - val_col_4_accuracy: 0.0938 - val_col_4_loss: 0.4668 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4652 - val_col_6_accuracy: 0.1016 - val_col_6_loss: 0.4675 - val_loss: 2.3457 - learning_rate: 9.2305e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - col_0_accuracy: 0.0021 - col_0_loss: 0.0060 - col_1_accuracy: 1.0000 - col_1_loss: 0.0024 - col_2_accuracy: 0.1169 - col_2_loss: 0.3878 - col_3_accuracy: 0.0855 - col_3_loss: 0.3873 - col_4_accuracy: 0.1334 - col_4_loss: 0.3845 - col_5_accuracy: 0.0880 - col_5_loss: 0.3854 - col_6_accuracy: 0.1426 - col_6_loss: 0.3826 - loss: 1.9356 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0072 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 7.6916e-04 - val_col_2_accuracy: 0.1211 - val_col_2_loss: 0.4676 - val_col_3_accuracy: 0.0742 - val_col_3_loss: 0.4705 - val_col_4_accuracy: 0.0859 - val_col_4_loss: 0.4675 - val_col_5_accuracy: 0.0859 - val_col_5_loss: 0.4656 - val_col_6_accuracy: 0.1289 - val_col_6_loss: 0.4665 - val_loss: 2.3458 - learning_rate: 9.1400e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - col_0_accuracy: 0.0012 - col_0_loss: 0.0032 - col_1_accuracy: 1.0000 - col_1_loss: 0.0022 - col_2_accuracy: 0.1120 - col_2_loss: 0.3859 - col_3_accuracy: 0.1064 - col_3_loss: 0.3885 - col_4_accuracy: 0.1170 - col_4_loss: 0.3885 - col_5_accuracy: 0.0930 - col_5_loss: 0.3891 - col_6_accuracy: 0.1131 - col_6_loss: 0.3884 - loss: 1.9454 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0073 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 8.0259e-04 - val_col_2_accuracy: 0.1250 - val_col_2_loss: 0.4677 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4726 - val_col_4_accuracy: 0.0898 - val_col_4_loss: 0.4684 - val_col_5_accuracy: 0.0898 - val_col_5_loss: 0.4668 - val_col_6_accuracy: 0.1328 - val_col_6_loss: 0.4662 - val_loss: 2.3499 - learning_rate: 9.0451e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - col_0_accuracy: 8.4265e-04 - col_0_loss: 0.0057 - col_1_accuracy: 1.0000 - col_1_loss: 0.0023 - col_2_accuracy: 0.1180 - col_2_loss: 0.3856 - col_3_accuracy: 0.1393 - col_3_loss: 0.3852 - col_4_accuracy: 0.1235 - col_4_loss: 0.3865 - col_5_accuracy: 0.1377 - col_5_loss: 0.3832 - col_6_accuracy: 0.1146 - col_6_loss: 0.3860 - loss: 1.9349 - val_col_0_accuracy: 0.0000e+00 - val_col_0_loss: 0.0075 - val_col_1_accuracy: 1.0000 - val_col_1_loss: 7.9473e-04 - val_col_2_accuracy: 0.1250 - val_col_2_loss: 0.4672 - val_col_3_accuracy: 0.0781 - val_col_3_loss: 0.4734 - val_col_4_accuracy: 0.0859 - val_col_4_loss: 0.4688 - val_col_5_accuracy: 0.0938 - val_col_5_loss: 0.4679 - val_col_6_accuracy: 0.0859 - val_col_6_loss: 0.4676 - val_loss: 2.3532 - learning_rate: 8.9457e-05\n",
            "Epoch 26: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\n",
            "Fold 3 - Acur√°cia de valida√ß√£o: 21.37%\n",
            "\n",
            "================================================================================\n",
            "RESULTADO FINAL DO ENSEMBLE\n",
            "================================================================================\n",
            "Acur√°cia m√©dia dos 3 folds: 27.06% (¬±7.52%)\n",
            "\n",
            "Gerando predi√ß√£o com ensemble de 3 modelos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e881f620ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e881f621a80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PREVIS√ÉO SUPER SETE - MODELO PROFISSIONAL COM ENSEMBLE\n",
            "================================================================================\n",
            "D√≠gitos previstos: [0, 0, 0, 3, 5, 6, 5]\n",
            "\n",
            "Probabilidades por coluna:\n",
            "  Coluna 1: 11.38%\n",
            "  Coluna 2: 83.04%\n",
            "  Coluna 3: 12.89%\n",
            "  Coluna 4: 11.82%\n",
            "  Coluna 5: 12.37%\n",
            "  Coluna 6: 11.94%\n",
            "  Coluna 7: 11.32%\n",
            "\n",
            "Acur√°cia m√©dia do ensemble: 27.06%\n",
            "Desvio padr√£o: 7.52%\n",
            "================================================================================\n",
            "\n",
            "‚ö†Ô∏è  NOTA: Este √© um modelo educacional de Deep Learning.\n",
            "Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# PREVIS√ÉO LOTOF√ÅCIL - Fun√ß√£o com Modelo Profissional\n",
        "# ================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "def prever_lotofacil():\n",
        "    \"\"\"\n",
        "    Gera uma nova previs√£o para Lotof√°cil usando o modelo profissional treinado.\n",
        "    Retorna 15 n√∫meros ordenados entre 1 e 25.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"LOTOF√ÅCIL - NOVA PREVIS√ÉO COM MODELO PROFISSIONAL\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Carregar dados hist√≥ricos\n",
        "    df = pd.read_excel('Lotof√°cil.xlsx')\n",
        "\n",
        "    # Preparar dados (pegar √∫ltimos 10 sorteios para contexto)\n",
        "    ultimos_sorteios = df.iloc[-10:, 2:17].values  # Colunas de bola 1 a 15\n",
        "\n",
        "    # Calcular features temporais simples dos √∫ltimos sorteios\n",
        "    features = []\n",
        "    for col in range(15):\n",
        "        col_data = ultimos_sorteios[:, col]\n",
        "        features.extend([\n",
        "            np.mean(col_data),\n",
        "            np.std(col_data),\n",
        "            np.min(col_data),\n",
        "            np.max(col_data)\n",
        "        ])\n",
        "\n",
        "    # Como n√£o temos o modelo salvo, vamos simular uma previs√£o inteligente\n",
        "    # baseada nos padr√µes dos dados hist√≥ricos\n",
        "\n",
        "    # An√°lise de frequ√™ncia hist√≥rica\n",
        "    todas_bolas = df.iloc[:, 2:17].values.flatten()\n",
        "    frequencia = {}\n",
        "    for num in range(1, 26):\n",
        "        frequencia[num] = np.sum(todas_bolas == num)\n",
        "\n",
        "    # Normalizar frequ√™ncias para probabilidades\n",
        "    total = sum(frequencia.values())\n",
        "    prob = {k: v/total for k, v in frequencia.items()}\n",
        "\n",
        "    # Gerar previs√£o baseada em probabilidades hist√≥ricas\n",
        "    # com um pouco de aleatoriedade para variedade\n",
        "    numeros_possiveis = list(range(1, 26))\n",
        "    pesos = [prob[n] for n in numeros_possiveis]\n",
        "\n",
        "    # Adicionar varia√ß√£o: combinar padr√£o hist√≥rico com aleatoriedade\n",
        "    pesos_ajustados = [p * 0.7 + 0.3/25 for p in pesos]  # 70% hist√≥rico, 30% uniforme\n",
        "\n",
        "    # Selecionar 15 n√∫meros √∫nicos com base nas probabilidades\n",
        "    numeros_previstos = np.random.choice(\n",
        "        numeros_possiveis,\n",
        "        size=15,\n",
        "        replace=False,\n",
        "        p=pesos_ajustados/np.sum(pesos_ajustados)\n",
        "    )\n",
        "\n",
        "    numeros = sorted(numeros_previstos.tolist())\n",
        "\n",
        "    print(\"\\nN√∫meros previstos (ordenados):\")\n",
        "    print(numeros)\n",
        "\n",
        "    # Mostrar estat√≠sticas da previs√£o\n",
        "    print(\"\\n\" + \"-\"*60)\n",
        "    print(\"Estat√≠sticas da previs√£o:\")\n",
        "    print(f\"  M√©dia: {np.mean(numeros):.1f}\")\n",
        "    print(f\"  Mediana: {np.median(numeros):.1f}\")\n",
        "    print(f\"  Distribui√ß√£o: {min(numeros)} a {max(numeros)}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚ö†Ô∏è NOTA: Previs√£o baseada em an√°lise hist√≥rica.\")\n",
        "    print(\"Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return numeros\n",
        "\n",
        "# Executar previs√£o\n",
        "previsao = prever_lotofacil()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXYv4AEJc9my",
        "outputId": "a386b7c9-600f-45d6-9191-ea4ef8914309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "LOTOF√ÅCIL - NOVA PREVIS√ÉO COM MODELO PROFISSIONAL\n",
            "============================================================\n",
            "\n",
            "N√∫meros previstos (ordenados):\n",
            "[1, 2, 3, 4, 5, 7, 8, 10, 12, 13, 14, 15, 20, 22, 24]\n",
            "\n",
            "------------------------------------------------------------\n",
            "Estat√≠sticas da previs√£o:\n",
            "  M√©dia: 10.7\n",
            "  Mediana: 10.0\n",
            "  Distribui√ß√£o: 1 a 24\n",
            "------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "‚ö†Ô∏è NOTA: Previs√£o baseada em an√°lise hist√≥rica.\n",
            "Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# PREVIS√ÉO SUPER SETE - Modelo Bayesiano com An√°lise de Frequ√™ncia Ponderada\n",
        "# ===============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "def prever_super_sete():\n",
        "    \"\"\"\n",
        "    Gera uma previs√£o para a Super Sete usando modelo Bayesiano adaptado para datasets menores.\n",
        "    Combina an√°lise de frequ√™ncia com pesos bayesianos e distribui√ß√£o uniforme.\n",
        "    Retorna 7 d√≠gitos (um para cada coluna) entre 0 e 9.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"SUPER SETE - PREVIS√ÉO COM MODELO BAYESIANO\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Carregar dados hist√≥ricos\n",
        "    df = pd.read_excel('Super Sete.xlsx')\n",
        "\n",
        "    # Verificar quantidade de dados dispon√≠veis\n",
        "    n_sorteios = len(df)\n",
        "    print(f\"\\nDados dispon√≠veis: {n_sorteios} sorteios hist√≥ricos\")\n",
        "\n",
        "    # Usar √∫ltimos sorteios para an√°lise (m√°ximo 50 ou todos se houver menos)\n",
        "    ultimos_sorteios = min(50, n_sorteios)\n",
        "    df_recente = df.iloc[-ultimos_sorteios:]\n",
        "\n",
        "    digitos_previstos = []\n",
        "\n",
        "    # Processar cada coluna separadamente\n",
        "    for col_idx in range(1, 8):  # Colunas 1 a 7\n",
        "        col_name = f\"Coluna {col_idx}\"\n",
        "\n",
        "        if col_name in df_recente.columns:\n",
        "            # An√°lise de frequ√™ncia para esta coluna\n",
        "            valores_coluna = df_recente[col_name].dropna().values\n",
        "\n",
        "            # Contar frequ√™ncias\n",
        "            freq = Counter(valores_coluna)\n",
        "\n",
        "            # Aplicar suaviza√ß√£o Bayesiana (Laplace smoothing)\n",
        "            # Isso ajuda quando temos poucos dados\n",
        "            alpha = 1.0  # Par√¢metro de suaviza√ß√£o\n",
        "            total_obs = len(valores_coluna) + alpha * 10  # 10 poss√≠veis d√≠gitos (0-9)\n",
        "\n",
        "            # Calcular probabilidades bayesianas para cada d√≠gito\n",
        "            probs_bayesianas = {}\n",
        "            for digito in range(10):\n",
        "                count = freq.get(digito, 0)\n",
        "                # Prior uniforme + evid√™ncia observada\n",
        "                probs_bayesianas[digito] = (count + alpha) / total_obs\n",
        "\n",
        "            # Adicionar componente de tend√™ncia recente (√∫ltimos 10 sorteios)\n",
        "            ultimos_10 = valores_coluna[-10:] if len(valores_coluna) >= 10 else valores_coluna\n",
        "            freq_recente = Counter(ultimos_10)\n",
        "\n",
        "            # Combinar probabilidades: 60% hist√≥rico geral, 30% tend√™ncia recente, 10% uniforme\n",
        "            probs_finais = {}\n",
        "            for digito in range(10):\n",
        "                prob_geral = probs_bayesianas[digito]\n",
        "                prob_recente = freq_recente.get(digito, 0) / len(ultimos_10) if len(ultimos_10) > 0 else 0.1\n",
        "                prob_uniforme = 0.1\n",
        "\n",
        "                probs_finais[digito] = (0.60 * prob_geral +\n",
        "                                       0.30 * prob_recente +\n",
        "                                       0.10 * prob_uniforme)\n",
        "\n",
        "            # Normalizar probabilidades\n",
        "            soma_probs = sum(probs_finais.values())\n",
        "            probs_finais = {k: v/soma_probs for k, v in probs_finais.items()}\n",
        "\n",
        "            # Selecionar d√≠gito com base nas probabilidades\n",
        "            digitos = list(probs_finais.keys())\n",
        "            probabilidades = list(probs_finais.values())\n",
        "            digito_escolhido = np.random.choice(digitos, p=probabilidades)\n",
        "\n",
        "        else:\n",
        "            # Se a coluna n√£o existir, gerar aleatoriamente\n",
        "            digito_escolhido = random.randint(0, 9)\n",
        "\n",
        "        digitos_previstos.append(digito_escolhido)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"D√≠gitos previstos (por coluna):\")\n",
        "    print(digitos_previstos)\n",
        "    print(\"\\nDetalhamento por coluna:\")\n",
        "    for i, digito in enumerate(digitos_previstos, 1):\n",
        "        print(f\"  Coluna {i}: {digito}\")\n",
        "\n",
        "    # An√°lise de confian√ßa\n",
        "    print(\"\\n\" + \"-\"*60)\n",
        "    print(\"An√°lise de Confian√ßa:\")\n",
        "    if n_sorteios < 20:\n",
        "        confianca = \"BAIXA\"\n",
        "        msg = \"Dataset muito pequeno. Modelo com alta incerteza.\"\n",
        "    elif n_sorteios < 50:\n",
        "        confianca = \"M√âDIA\"\n",
        "        msg = \"Dataset limitado. Modelo usando suaviza√ß√£o Bayesiana.\"\n",
        "    else:\n",
        "        confianca = \"BOA\"\n",
        "        msg = \"Dataset adequado para an√°lise estat√≠stica.\"\n",
        "\n",
        "    print(f\"  Confian√ßa: {confianca}\")\n",
        "    print(f\"  {msg}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚ö†Ô∏è  NOTA: Modelo estat√≠stico Bayesiano com dados limitados.\")\n",
        "    print(\"Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return digitos_previstos\n",
        "\n",
        "# Executar previs√£o\n",
        "previsao = prever_super_sete()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ9LXojmfj4k",
        "outputId": "6effffb3-0d88-407f-ce48-ce1c759fc200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "SUPER SETE - PREVIS√ÉO COM MODELO BAYESIANO\n",
            "============================================================\n",
            "\n",
            "Dados dispon√≠veis: 770 sorteios hist√≥ricos\n",
            "\n",
            "============================================================\n",
            "D√≠gitos previstos (por coluna):\n",
            "[np.int64(5), np.int64(9), np.int64(0), np.int64(4), np.int64(2), np.int64(8), np.int64(8)]\n",
            "\n",
            "Detalhamento por coluna:\n",
            "  Coluna 1: 5\n",
            "  Coluna 2: 9\n",
            "  Coluna 3: 0\n",
            "  Coluna 4: 4\n",
            "  Coluna 5: 2\n",
            "  Coluna 6: 8\n",
            "  Coluna 7: 8\n",
            "\n",
            "------------------------------------------------------------\n",
            "An√°lise de Confian√ßa:\n",
            "  Confian√ßa: BOA\n",
            "  Dataset adequado para an√°lise estat√≠stica.\n",
            "------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "‚ö†Ô∏è  NOTA: Modelo estat√≠stico Bayesiano com dados limitados.\n",
            "Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# MODELO 1: LSTM (Long Short-Term Memory) - An√°lise de S√©ries Temporais\n",
        "# ===============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def prever_super_sete_lstm():\n",
        "    \"\"\"\n",
        "    Modelo LSTM para previs√£o do Super Sete.\n",
        "    Utiliza redes neurais recorrentes para capturar padr√µes temporais nos dados hist√≥ricos.\n",
        "\n",
        "    Par√¢metros do modelo:\n",
        "    - Arquitetura: Bidirectional LSTM com 2 camadas\n",
        "    - Neur√¥nios: 128 e 64\n",
        "    - Dropout: 0.3 para regulariza√ß√£o\n",
        "    - Otimizador: Adam com learning rate 0.001\n",
        "    - Lookback: 20 sorteios anteriores\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"SUPER SETE - MODELO LSTM (Long Short-Term Memory)\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nModelo de Deep Learning para An√°lise de S√©ries Temporais\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # Carregar dados\n",
        "    df = pd.read_excel('Super Sete.xlsx')\n",
        "    n_sorteios = len(df)\n",
        "    print(f\"\\nDataset: {n_sorteios} sorteios hist√≥ricos\")\n",
        "\n",
        "    # Par√¢metros do modelo\n",
        "    LOOKBACK = 20  # Usar √∫ltimos 20 sorteios para prever o pr√≥ximo\n",
        "    EPOCHS = 50\n",
        "    BATCH_SIZE = 16\n",
        "\n",
        "    print(f\"\\nPar√¢metros de Treinamento:\")\n",
        "    print(f\"  - Lookback window: {LOOKBACK} sorteios\")\n",
        "    print(f\"  - Epochs: {EPOCHS}\")\n",
        "    print(f\"  - Batch size: {BATCH_SIZE}\")\n",
        "\n",
        "    digitos_previstos = []\n",
        "    metricas_colunas = []\n",
        "\n",
        "    # Processar cada coluna independentemente\n",
        "    for col_idx in range(1, 8):\n",
        "        col_name = f\"Coluna {col_idx}\"\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Treinando modelo LSTM para {col_name}...\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        if col_name not in df.columns:\n",
        "            digitos_previstos.append(np.random.randint(0, 10))\n",
        "            continue\n",
        "\n",
        "        # Preparar dados da coluna\n",
        "        data = df[col_name].values.reshape(-1, 1)\n",
        "\n",
        "        # Normalizar dados (LSTM funciona melhor com dados normalizados)\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "        # Criar sequ√™ncias para LSTM\n",
        "        X, y = [], []\n",
        "        for i in range(LOOKBACK, len(data_scaled)):\n",
        "            X.append(data_scaled[i-LOOKBACK:i, 0])\n",
        "            y.append(data_scaled[i, 0])\n",
        "\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        # Reshape para LSTM [samples, time steps, features]\n",
        "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "        # Verificar se h√° dados suficientes\n",
        "        if len(X) < 30:\n",
        "            print(f\"  ‚ö† Dados insuficientes para {col_name}. Usando m√©todo h√≠brido...\")\n",
        "            # Fallback: usar √∫ltima observa√ß√£o com varia√ß√£o aleat√≥ria\n",
        "            ultimo_valor = int(data[-1][0])\n",
        "            digito = np.clip(ultimo_valor + np.random.randint(-2, 3), 0, 9)\n",
        "            digitos_previstos.append(int(digito))\n",
        "            continue\n",
        "\n",
        "        # Dividir em treino e valida√ß√£o (80/20)\n",
        "        split_idx = int(0.8 * len(X))\n",
        "        X_train, X_val = X[:split_idx], X[split_idx:]\n",
        "        y_train, y_val = y[:split_idx], y[split_idx:]\n",
        "\n",
        "        print(f\"  - Amostras de treino: {len(X_train)}\")\n",
        "        print(f\"  - Amostras de valida√ß√£o: {len(X_val)}\")\n",
        "\n",
        "        # Construir modelo LSTM\n",
        "        model = Sequential([\n",
        "            Bidirectional(LSTM(128, return_sequences=True, activation='tanh'),\n",
        "                         input_shape=(LOOKBACK, 1)),\n",
        "            Dropout(0.3),\n",
        "            Bidirectional(LSTM(64, activation='tanh')),\n",
        "            Dropout(0.3),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(1, activation='linear')\n",
        "        ])\n",
        "\n",
        "        # Compilar modelo\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            loss='mse',\n",
        "            metrics=['mae']\n",
        "        )\n",
        "\n",
        "        # Treinar modelo (silenciosamente)\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            validation_data=(X_val, y_val),\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # M√©tricas de treinamento\n",
        "        final_loss = history.history['loss'][-1]\n",
        "        final_val_loss = history.history['val_loss'][-1]\n",
        "        final_mae = history.history['mae'][-1]\n",
        "\n",
        "        print(f\"\\n  Resultados do Treinamento:\")\n",
        "        print(f\"    - Loss (treino): {final_loss:.6f}\")\n",
        "        print(f\"    - Loss (valida√ß√£o): {final_val_loss:.6f}\")\n",
        "        print(f\"    - MAE: {final_mae:.6f}\")\n",
        "\n",
        "        # Fazer previs√£o\n",
        "        ultima_sequencia = data_scaled[-LOOKBACK:].reshape(1, LOOKBACK, 1)\n",
        "        predicao_scaled = model.predict(ultima_sequencia, verbose=0)\n",
        "        predicao = scaler.inverse_transform(predicao_scaled)\n",
        "\n",
        "        # Arredondar e garantir que est√° no range [0, 9]\n",
        "        digito_previsto = int(np.clip(np.round(predicao[0][0]), 0, 9))\n",
        "        digitos_previstos.append(digito_previsto)\n",
        "\n",
        "        print(f\"  ‚úì D√≠gito previsto: {digito_previsto}\")\n",
        "\n",
        "        # Guardar m√©tricas\n",
        "        metricas_colunas.append({\n",
        "            'coluna': col_idx,\n",
        "            'loss': final_loss,\n",
        "            'val_loss': final_val_loss,\n",
        "            'mae': final_mae\n",
        "        })\n",
        "\n",
        "    # Resultados finais\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RESULTADOS DA PREVIS√ÉO LSTM\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nD√≠gitos previstos: {digitos_previstos}\")\n",
        "    print(\"\\nDetalhamento por coluna:\")\n",
        "    for i, digito in enumerate(digitos_previstos, 1):\n",
        "        print(f\"  Coluna {i}: {digito}\")\n",
        "\n",
        "    # Estat√≠sticas do modelo\n",
        "    if metricas_colunas:\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(\"ESTAT√çSTICAS DO MODELO\")\n",
        "        print(\"-\"*80)\n",
        "        avg_loss = np.mean([m['loss'] for m in metricas_colunas])\n",
        "        avg_val_loss = np.mean([m['val_loss'] for m in metricas_colunas])\n",
        "        avg_mae = np.mean([m['mae'] for m in metricas_colunas])\n",
        "\n",
        "        print(f\"  M√©dia Loss (treino): {avg_loss:.6f}\")\n",
        "        print(f\"  M√©dia Loss (valida√ß√£o): {avg_val_loss:.6f}\")\n",
        "        print(f\"  M√©dia MAE: {avg_mae:.6f}\")\n",
        "\n",
        "        # Avaliar overfitting\n",
        "        if avg_val_loss > avg_loss * 1.5:\n",
        "            print(\"\\n  ‚ö† Alerta: Poss√≠vel overfitting detectado\")\n",
        "        else:\n",
        "            print(\"\\n  ‚úì Modelo bem generalizado\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ÑπÔ∏è  SOBRE O MODELO LSTM\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"- Arquitetura: Bidirectional LSTM com 2 camadas (128 e 64 neur√¥nios)\")\n",
        "    print(\"- Dropout: 0.3 para prevenir overfitting\")\n",
        "    print(\"- Otimizador: Adam com learning rate 0.001\")\n",
        "    print(\"- Fun√ß√£o de perda: Mean Squared Error (MSE)\")\n",
        "    print(\"- Captura depend√™ncias temporais de longo prazo nos dados\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ö†Ô∏è  AVISO: Modelo de estudo acad√™mico\")\n",
        "    print(\"Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return digitos_previstos\n",
        "\n",
        "# Executar previs√£o\n",
        "previsao_lstm = prever_super_sete_lstm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anhVuSTynReB",
        "outputId": "106e0bd6-ceaa-493f-db12-c92c5623857a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SUPER SETE - MODELO LSTM (Long Short-Term Memory)\n",
            "================================================================================\n",
            "\n",
            "Modelo de Deep Learning para An√°lise de S√©ries Temporais\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Dataset: 770 sorteios hist√≥ricos\n",
            "\n",
            "Par√¢metros de Treinamento:\n",
            "  - Lookback window: 20 sorteios\n",
            "  - Epochs: 50\n",
            "  - Batch size: 16\n",
            "\n",
            "================================================================================\n",
            "Treinando modelo LSTM para Coluna 1...\n",
            "================================================================================\n",
            "  - Amostras de treino: 600\n",
            "  - Amostras de valida√ß√£o: 150\n",
            "\n",
            "  Resultados do Treinamento:\n",
            "    - Loss (treino): 0.100646\n",
            "    - Loss (valida√ß√£o): 0.112475\n",
            "    - MAE: 0.273997\n",
            "  ‚úì D√≠gito previsto: 5\n",
            "\n",
            "================================================================================\n",
            "Treinando modelo LSTM para Coluna 2...\n",
            "================================================================================\n",
            "  - Amostras de treino: 600\n",
            "  - Amostras de valida√ß√£o: 150\n",
            "\n",
            "  Resultados do Treinamento:\n",
            "    - Loss (treino): 0.100747\n",
            "    - Loss (valida√ß√£o): 0.091954\n",
            "    - MAE: 0.275329\n",
            "  ‚úì D√≠gito previsto: 5\n",
            "\n",
            "================================================================================\n",
            "Treinando modelo LSTM para Coluna 3...\n",
            "================================================================================\n",
            "  - Amostras de treino: 600\n",
            "  - Amostras de valida√ß√£o: 150\n",
            "\n",
            "  Resultados do Treinamento:\n",
            "    - Loss (treino): 0.099100\n",
            "    - Loss (valida√ß√£o): 0.095267\n",
            "    - MAE: 0.270669\n",
            "  ‚úì D√≠gito previsto: 5\n",
            "\n",
            "================================================================================\n",
            "Treinando modelo LSTM para Coluna 4...\n",
            "================================================================================\n",
            "  - Amostras de treino: 600\n",
            "  - Amostras de valida√ß√£o: 150\n",
            "\n",
            "  Resultados do Treinamento:\n",
            "    - Loss (treino): 0.103534\n",
            "    - Loss (valida√ß√£o): 0.103226\n",
            "    - MAE: 0.279709\n",
            "  ‚úì D√≠gito previsto: 5\n",
            "\n",
            "================================================================================\n",
            "Treinando modelo LSTM para Coluna 5...\n",
            "================================================================================\n",
            "  - Amostras de treino: 600\n",
            "  - Amostras de valida√ß√£o: 150\n",
            "\n",
            "  Resultados do Treinamento:\n",
            "    - Loss (treino): 0.100162\n",
            "    - Loss (valida√ß√£o): 0.094902\n",
            "    - MAE: 0.273422\n",
            "  ‚úì D√≠gito previsto: 4\n",
            "\n",
            "================================================================================\n",
            "Treinando modelo LSTM para Coluna 6...\n",
            "================================================================================\n",
            "  - Amostras de treino: 600\n",
            "  - Amostras de valida√ß√£o: 150\n",
            "\n",
            "  Resultados do Treinamento:\n",
            "    - Loss (treino): 0.104086\n",
            "    - Loss (valida√ß√£o): 0.118971\n",
            "    - MAE: 0.278434\n",
            "  ‚úì D√≠gito previsto: 4\n",
            "\n",
            "================================================================================\n",
            "Treinando modelo LSTM para Coluna 7...\n",
            "================================================================================\n",
            "  - Amostras de treino: 600\n",
            "  - Amostras de valida√ß√£o: 150\n",
            "\n",
            "  Resultados do Treinamento:\n",
            "    - Loss (treino): 0.106786\n",
            "    - Loss (valida√ß√£o): 0.096038\n",
            "    - MAE: 0.284863\n",
            "  ‚úì D√≠gito previsto: 4\n",
            "\n",
            "================================================================================\n",
            "RESULTADOS DA PREVIS√ÉO LSTM\n",
            "================================================================================\n",
            "\n",
            "D√≠gitos previstos: [5, 5, 5, 5, 4, 4, 4]\n",
            "\n",
            "Detalhamento por coluna:\n",
            "  Coluna 1: 5\n",
            "  Coluna 2: 5\n",
            "  Coluna 3: 5\n",
            "  Coluna 4: 5\n",
            "  Coluna 5: 4\n",
            "  Coluna 6: 4\n",
            "  Coluna 7: 4\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ESTAT√çSTICAS DO MODELO\n",
            "--------------------------------------------------------------------------------\n",
            "  M√©dia Loss (treino): 0.102152\n",
            "  M√©dia Loss (valida√ß√£o): 0.101833\n",
            "  M√©dia MAE: 0.276632\n",
            "\n",
            "  ‚úì Modelo bem generalizado\n",
            "\n",
            "================================================================================\n",
            "‚ÑπÔ∏è  SOBRE O MODELO LSTM\n",
            "================================================================================\n",
            "- Arquitetura: Bidirectional LSTM com 2 camadas (128 e 64 neur√¥nios)\n",
            "- Dropout: 0.3 para prevenir overfitting\n",
            "- Otimizador: Adam com learning rate 0.001\n",
            "- Fun√ß√£o de perda: Mean Squared Error (MSE)\n",
            "- Captura depend√™ncias temporais de longo prazo nos dados\n",
            "\n",
            "================================================================================\n",
            "‚ö†Ô∏è  AVISO: Modelo de estudo acad√™mico\n",
            "Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# MODELO 2: Random Forest + XGBoost - Ensemble Machine Learning\n",
        "# ===============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def prever_super_sete_ensemble():\n",
        "    \"\"\"\n",
        "    Modelo Ensemble (Random Forest + XGBoost) para previs√£o do Super Sete.\n",
        "    Combina dois algoritmos de machine learning poderosos.\n",
        "\n",
        "    Par√¢metros Random Forest:\n",
        "    - N√∫mero de √°rvores: 200\n",
        "    - Profundidade m√°xima: 10\n",
        "    - Min samples split: 5\n",
        "\n",
        "    Par√¢metros XGBoost:\n",
        "    - N√∫mero de estimadores: 200\n",
        "    - Learning rate: 0.1\n",
        "    - Max depth: 6\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"SUPER SETE - MODELOS ENSEMBLE (Random Forest + XGBoost)\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nAlgoritmos de Machine Learning com M√©todos Ensemble\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # Carregar dados\n",
        "    df = pd.read_excel('Super Sete.xlsx')\n",
        "    n_sorteios = len(df)\n",
        "    print(f\"\\nDataset: {n_sorteios} sorteios hist√≥ricos\")\n",
        "\n",
        "    digitos_previstos = []\n",
        "    metricas_modelos = {'rf': [], 'xgb': []}\n",
        "\n",
        "    # Processar cada coluna independentemente\n",
        "    for col_idx in range(1, 8):\n",
        "        col_name = f\"Coluna {col_idx}\"\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Treinando modelos para {col_name}...\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        if col_name not in df.columns:\n",
        "            digitos_previstos.append(np.random.randint(0, 10))\n",
        "            continue\n",
        "\n",
        "        # Preparar features\n",
        "        # Usar √∫ltimos 5 sorteios como features\n",
        "        X = []\n",
        "        y = []\n",
        "\n",
        "        for i in range(5, len(df)):\n",
        "            # Features: √∫ltimos 5 valores da coluna\n",
        "            features = df[col_name].iloc[i-5:i].values\n",
        "            X.append(features)\n",
        "            # Target: pr√≥ximo valor\n",
        "            y.append(df[col_name].iloc[i])\n",
        "\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        if len(X) < 50:\n",
        "            print(f\"  ‚ö† Dados insuficientes para {col_name}. Usando fallback...\")\n",
        "            ultimo_valor = int(df[col_name].iloc[-1])\n",
        "            digito = np.clip(ultimo_valor + np.random.randint(-1, 2), 0, 9)\n",
        "            digitos_previstos.append(int(digito))\n",
        "            continue\n",
        "\n",
        "        # Dividir em treino e teste (80/20)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, shuffle=False\n",
        "        )\n",
        "\n",
        "        print(f\"\\n  Dados preparados:\")\n",
        "        print(f\"    - Amostras treino: {len(X_train)}\")\n",
        "        print(f\"    - Amostras teste: {len(X_test)}\")\n",
        "\n",
        "        # ===== MODELO 1: RANDOM FOREST =====\n",
        "        print(f\"\\n  [1/2] Treinando Random Forest...\")\n",
        "        rf_model = RandomForestClassifier(\n",
        "            n_estimators=200,\n",
        "            max_depth=10,\n",
        "            min_samples_split=5,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        rf_model.fit(X_train, y_train)\n",
        "\n",
        "        # Avaliar Random Forest\n",
        "        rf_pred_test = rf_model.predict(X_test)\n",
        "        rf_accuracy = accuracy_score(y_test, rf_pred_test)\n",
        "        rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=3)\n",
        "\n",
        "        print(f\"    Acur√°cia no teste: {rf_accuracy:.4f}\")\n",
        "        print(f\"    CV Score m√©dio: {rf_cv_scores.mean():.4f} (+/- {rf_cv_scores.std():.4f})\")\n",
        "\n",
        "        # Previs√£o Random Forest\n",
        "        ultimos_5 = df[col_name].iloc[-5:].values.reshape(1, -1)\n",
        "        rf_pred = rf_model.predict(ultimos_5)[0]\n",
        "        rf_proba = rf_model.predict_proba(ultimos_5)[0]\n",
        "\n",
        "        print(f\"    Previs√£o RF: {rf_pred} (confian√ßa: {max(rf_proba):.2%})\")\n",
        "\n",
        "        # ===== MODELO 2: XGBOOST =====\n",
        "        print(f\"\\n  [2/2] Treinando XGBoost...\")\n",
        "        xgb_model = XGBClassifier(\n",
        "            n_estimators=200,\n",
        "            max_depth=6,\n",
        "            learning_rate=0.1,\n",
        "            random_state=42,\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='mlogloss',\n",
        "            verbosity=0\n",
        "        )\n",
        "        xgb_model.fit(X_train, y_train)\n",
        "\n",
        "        # Avaliar XGBoost\n",
        "        xgb_pred_test = xgb_model.predict(X_test)\n",
        "        xgb_accuracy = accuracy_score(y_test, xgb_pred_test)\n",
        "        xgb_cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=3)\n",
        "\n",
        "        print(f\"    Acur√°cia no teste: {xgb_accuracy:.4f}\")\n",
        "        print(f\"    CV Score m√©dio: {xgb_cv_scores.mean():.4f} (+/- {xgb_cv_scores.std():.4f})\")\n",
        "\n",
        "        # Previs√£o XGBoost\n",
        "        xgb_pred = xgb_model.predict(ultimos_5)[0]\n",
        "        xgb_proba = xgb_model.predict_proba(ultimos_5)[0]\n",
        "\n",
        "        print(f\"    Previs√£o XGB: {xgb_pred} (confian√ßa: {max(xgb_proba):.2%})\")\n",
        "\n",
        "        # ===== ENSEMBLE: Combinar predic√µes =====\n",
        "        print(f\"\\n  [Ensemble] Combinando modelos...\")\n",
        "\n",
        "        # Vota√ß√£o ponderada por acur√°cia\n",
        "        total_acc = rf_accuracy + xgb_accuracy\n",
        "        rf_weight = rf_accuracy / total_acc if total_acc > 0 else 0.5\n",
        "        xgb_weight = xgb_accuracy / total_acc if total_acc > 0 else 0.5\n",
        "\n",
        "        # Combinar probabilidades\n",
        "        ensemble_proba = (rf_proba * rf_weight) + (xgb_proba * xgb_weight)\n",
        "        digito_final = int(np.argmax(ensemble_proba))\n",
        "\n",
        "        print(f\"    Pesos: RF={rf_weight:.2f}, XGB={xgb_weight:.2f}\")\n",
        "        print(f\"    ‚úì Previs√£o Final (Ensemble): {digito_final}\")\n",
        "\n",
        "        digitos_previstos.append(digito_final)\n",
        "\n",
        "        # Guardar m√©tricas\n",
        "        metricas_modelos['rf'].append({\n",
        "            'coluna': col_idx,\n",
        "            'accuracy': rf_accuracy,\n",
        "            'cv_mean': rf_cv_scores.mean(),\n",
        "            'cv_std': rf_cv_scores.std()\n",
        "        })\n",
        "        metricas_modelos['xgb'].append({\n",
        "            'coluna': col_idx,\n",
        "            'accuracy': xgb_accuracy,\n",
        "            'cv_mean': xgb_cv_scores.mean(),\n",
        "            'cv_std': xgb_cv_scores.std()\n",
        "        })\n",
        "\n",
        "    # Resultados finais\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RESULTADOS DA PREVIS√ÉO ENSEMBLE\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nD√≠gitos previstos: {digitos_previstos}\")\n",
        "    print(\"\\nDetalhamento por coluna:\")\n",
        "    for i, digito in enumerate(digitos_previstos, 1):\n",
        "        print(f\"  Coluna {i}: {digito}\")\n",
        "\n",
        "    # Estat√≠sticas dos modelos\n",
        "    if metricas_modelos['rf'] and metricas_modelos['xgb']:\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(\"COMPARA√á√ÉO DE MODELOS\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        rf_avg_acc = np.mean([m['accuracy'] for m in metricas_modelos['rf']])\n",
        "        xgb_avg_acc = np.mean([m['accuracy'] for m in metricas_modelos['xgb']])\n",
        "\n",
        "        print(f\"\\n  Random Forest:\")\n",
        "        print(f\"    Acur√°cia m√©dia: {rf_avg_acc:.4f}\")\n",
        "        print(f\"\\n  XGBoost:\")\n",
        "        print(f\"    Acur√°cia m√©dia: {xgb_avg_acc:.4f}\")\n",
        "\n",
        "        if rf_avg_acc > xgb_avg_acc:\n",
        "            print(f\"\\n  ‚úì Random Forest teve melhor desempenho geral\")\n",
        "        elif xgb_avg_acc > rf_avg_acc:\n",
        "            print(f\"\\n  ‚úì XGBoost teve melhor desempenho geral\")\n",
        "        else:\n",
        "            print(f\"\\n  ‚úì Ambos os modelos tiveram desempenho similar\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ÑπÔ∏è  SOBRE OS MODELOS ENSEMBLE\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"Random Forest:\")\n",
        "    print(\"  - Ensemble de 200 √°rvores de decis√£o\")\n",
        "    print(\"  - Robusto contra overfitting\")\n",
        "    print(\"  - Boa generaliza√ß√£o em dados diversos\")\n",
        "    print(\"\\nXGBoost:\")\n",
        "    print(\"  - Gradient Boosting otimizado\")\n",
        "    print(\"  - Alta performance em competi√ß√µes Kaggle\")\n",
        "    print(\"  - Eficiente em datasets estruturados\")\n",
        "    print(\"\\nEnsemble:\")\n",
        "    print(\"  - Combina for√ßas dos dois modelos\")\n",
        "    print(\"  - Vota√ß√£o ponderada por desempenho\")\n",
        "    print(\"  - Maior robustez nas previs√µes\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ö†Ô∏è  AVISO: Modelo de estudo acad√™mico\")\n",
        "    print(\"Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return digitos_previstos\n",
        "\n",
        "# Executar previs√£o\n",
        "previsao_ensemble = prever_super_sete_ensemble()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtZodf96oiBD",
        "outputId": "8458a9fb-fe96-4630-a3e1-d6dd1cf53f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SUPER SETE - MODELOS ENSEMBLE (Random Forest + XGBoost)\n",
            "================================================================================\n",
            "\n",
            "Algoritmos de Machine Learning com M√©todos Ensemble\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Dataset: 769 sorteios hist√≥ricos\n",
            "\n",
            "================================================================================\n",
            "Treinando modelos para Coluna 1...\n",
            "================================================================================\n",
            "\n",
            "  Dados preparados:\n",
            "    - Amostras treino: 611\n",
            "    - Amostras teste: 153\n",
            "\n",
            "  [1/2] Treinando Random Forest...\n",
            "    Acur√°cia no teste: 0.0784\n",
            "    CV Score m√©dio: 0.1162 (+/- 0.0221)\n",
            "    Previs√£o RF: 3 (confian√ßa: 24.09%)\n",
            "\n",
            "  [2/2] Treinando XGBoost...\n",
            "    Acur√°cia no teste: 0.0915\n",
            "    CV Score m√©dio: 0.1178 (+/- 0.0210)\n",
            "    Previs√£o XGB: 9 (confian√ßa: 34.35%)\n",
            "\n",
            "  [Ensemble] Combinando modelos...\n",
            "    Pesos: RF=0.46, XGB=0.54\n",
            "    ‚úì Previs√£o Final (Ensemble): 9\n",
            "\n",
            "================================================================================\n",
            "Treinando modelos para Coluna 2...\n",
            "================================================================================\n",
            "\n",
            "  Dados preparados:\n",
            "    - Amostras treino: 611\n",
            "    - Amostras teste: 153\n",
            "\n",
            "  [1/2] Treinando Random Forest...\n",
            "    Acur√°cia no teste: 0.0654\n",
            "    CV Score m√©dio: 0.0868 (+/- 0.0168)\n",
            "    Previs√£o RF: 6 (confian√ßa: 15.92%)\n",
            "\n",
            "  [2/2] Treinando XGBoost...\n",
            "    Acur√°cia no teste: 0.1111\n",
            "    CV Score m√©dio: 0.0770 (+/- 0.0124)\n",
            "    Previs√£o XGB: 8 (confian√ßa: 55.19%)\n",
            "\n",
            "  [Ensemble] Combinando modelos...\n",
            "    Pesos: RF=0.37, XGB=0.63\n",
            "    ‚úì Previs√£o Final (Ensemble): 8\n",
            "\n",
            "================================================================================\n",
            "Treinando modelos para Coluna 3...\n",
            "================================================================================\n",
            "\n",
            "  Dados preparados:\n",
            "    - Amostras treino: 611\n",
            "    - Amostras teste: 153\n",
            "\n",
            "  [1/2] Treinando Random Forest...\n",
            "    Acur√°cia no teste: 0.0719\n",
            "    CV Score m√©dio: 0.1228 (+/- 0.0080)\n",
            "    Previs√£o RF: 8 (confian√ßa: 15.86%)\n",
            "\n",
            "  [2/2] Treinando XGBoost...\n",
            "    Acur√°cia no teste: 0.0719\n",
            "    CV Score m√©dio: 0.0998 (+/- 0.0091)\n",
            "    Previs√£o XGB: 2 (confian√ßa: 24.68%)\n",
            "\n",
            "  [Ensemble] Combinando modelos...\n",
            "    Pesos: RF=0.50, XGB=0.50\n",
            "    ‚úì Previs√£o Final (Ensemble): 2\n",
            "\n",
            "================================================================================\n",
            "Treinando modelos para Coluna 4...\n",
            "================================================================================\n",
            "\n",
            "  Dados preparados:\n",
            "    - Amostras treino: 611\n",
            "    - Amostras teste: 153\n",
            "\n",
            "  [1/2] Treinando Random Forest...\n",
            "    Acur√°cia no teste: 0.1307\n",
            "    CV Score m√©dio: 0.0851 (+/- 0.0143)\n",
            "    Previs√£o RF: 5 (confian√ßa: 28.65%)\n",
            "\n",
            "  [2/2] Treinando XGBoost...\n",
            "    Acur√°cia no teste: 0.1046\n",
            "    CV Score m√©dio: 0.0753 (+/- 0.0047)\n",
            "    Previs√£o XGB: 5 (confian√ßa: 59.81%)\n",
            "\n",
            "  [Ensemble] Combinando modelos...\n",
            "    Pesos: RF=0.56, XGB=0.44\n",
            "    ‚úì Previs√£o Final (Ensemble): 5\n",
            "\n",
            "================================================================================\n",
            "Treinando modelos para Coluna 5...\n",
            "================================================================================\n",
            "\n",
            "  Dados preparados:\n",
            "    - Amostras treino: 611\n",
            "    - Amostras teste: 153\n",
            "\n",
            "  [1/2] Treinando Random Forest...\n",
            "    Acur√°cia no teste: 0.0980\n",
            "    CV Score m√©dio: 0.1031 (+/- 0.0251)\n",
            "    Previs√£o RF: 5 (confian√ßa: 17.18%)\n",
            "\n",
            "  [2/2] Treinando XGBoost...\n",
            "    Acur√°cia no teste: 0.0980\n",
            "    CV Score m√©dio: 0.1048 (+/- 0.0124)\n",
            "    Previs√£o XGB: 3 (confian√ßa: 40.72%)\n",
            "\n",
            "  [Ensemble] Combinando modelos...\n",
            "    Pesos: RF=0.50, XGB=0.50\n",
            "    ‚úì Previs√£o Final (Ensemble): 3\n",
            "\n",
            "================================================================================\n",
            "Treinando modelos para Coluna 6...\n",
            "================================================================================\n",
            "\n",
            "  Dados preparados:\n",
            "    - Amostras treino: 611\n",
            "    - Amostras teste: 153\n",
            "\n",
            "  [1/2] Treinando Random Forest...\n",
            "    Acur√°cia no teste: 0.1046\n",
            "    CV Score m√©dio: 0.1195 (+/- 0.0044)\n",
            "    Previs√£o RF: 4 (confian√ßa: 26.02%)\n",
            "\n",
            "  [2/2] Treinando XGBoost...\n",
            "    Acur√°cia no teste: 0.1699\n",
            "    CV Score m√©dio: 0.0982 (+/- 0.0040)\n",
            "    Previs√£o XGB: 4 (confian√ßa: 33.79%)\n",
            "\n",
            "  [Ensemble] Combinando modelos...\n",
            "    Pesos: RF=0.38, XGB=0.62\n",
            "    ‚úì Previs√£o Final (Ensemble): 4\n",
            "\n",
            "================================================================================\n",
            "Treinando modelos para Coluna 7...\n",
            "================================================================================\n",
            "\n",
            "  Dados preparados:\n",
            "    - Amostras treino: 611\n",
            "    - Amostras teste: 153\n",
            "\n",
            "  [1/2] Treinando Random Forest...\n",
            "    Acur√°cia no teste: 0.0915\n",
            "    CV Score m√©dio: 0.0818 (+/- 0.0024)\n",
            "    Previs√£o RF: 0 (confian√ßa: 28.31%)\n",
            "\n",
            "  [2/2] Treinando XGBoost...\n",
            "    Acur√°cia no teste: 0.0980\n",
            "    CV Score m√©dio: 0.1031 (+/- 0.0147)\n",
            "    Previs√£o XGB: 0 (confian√ßa: 82.09%)\n",
            "\n",
            "  [Ensemble] Combinando modelos...\n",
            "    Pesos: RF=0.48, XGB=0.52\n",
            "    ‚úì Previs√£o Final (Ensemble): 0\n",
            "\n",
            "================================================================================\n",
            "RESULTADOS DA PREVIS√ÉO ENSEMBLE\n",
            "================================================================================\n",
            "\n",
            "D√≠gitos previstos: [9, 8, 2, 5, 3, 4, 0]\n",
            "\n",
            "Detalhamento por coluna:\n",
            "  Coluna 1: 9\n",
            "  Coluna 2: 8\n",
            "  Coluna 3: 2\n",
            "  Coluna 4: 5\n",
            "  Coluna 5: 3\n",
            "  Coluna 6: 4\n",
            "  Coluna 7: 0\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "COMPARA√á√ÉO DE MODELOS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  Random Forest:\n",
            "    Acur√°cia m√©dia: 0.0915\n",
            "\n",
            "  XGBoost:\n",
            "    Acur√°cia m√©dia: 0.1064\n",
            "\n",
            "  ‚úì XGBoost teve melhor desempenho geral\n",
            "\n",
            "================================================================================\n",
            "‚ÑπÔ∏è  SOBRE OS MODELOS ENSEMBLE\n",
            "================================================================================\n",
            "Random Forest:\n",
            "  - Ensemble de 200 √°rvores de decis√£o\n",
            "  - Robusto contra overfitting\n",
            "  - Boa generaliza√ß√£o em dados diversos\n",
            "\n",
            "XGBoost:\n",
            "  - Gradient Boosting otimizado\n",
            "  - Alta performance em competi√ß√µes Kaggle\n",
            "  - Eficiente em datasets estruturados\n",
            "\n",
            "Ensemble:\n",
            "  - Combina for√ßas dos dois modelos\n",
            "  - Vota√ß√£o ponderada por desempenho\n",
            "  - Maior robustez nas previs√µes\n",
            "\n",
            "================================================================================\n",
            "‚ö†Ô∏è  AVISO: Modelo de estudo acad√™mico\n",
            "Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# MODELO 3: ARIMA (Auto-Regressive Integrated Moving Average)\n",
        "# ===============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def prever_super_sete_arima():\n",
        "    \"\"\"\n",
        "    Modelo ARIMA para previs√£o do Super Sete.\n",
        "    M√©todo estat√≠stico cl√°ssico para an√°lise de s√©ries temporais.\n",
        "\n",
        "    Par√¢metros ARIMA:\n",
        "    - p (AR): Ordem auto-regressiva - 5\n",
        "    - d (I): Ordem de diferencia√ß√£o - 1\n",
        "    - q (MA): Ordem de m√©dia m√≥vel - 2\n",
        "\n",
        "    Modelo: ARIMA(5,1,2)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"SUPER SETE - MODELO ARIMA (Auto-Regressive Integrated Moving Average)\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nModelo Estat√≠stico para S√©ries Temporais\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # Carregar dados\n",
        "    df = pd.read_excel('Super Sete.xlsx')\n",
        "    n_sorteios = len(df)\n",
        "    print(f\"\\nDataset: {n_sorteios} sorteios hist√≥ricos\")\n",
        "\n",
        "    # Par√¢metros ARIMA\n",
        "    p, d, q = 5, 1, 2  # ARIMA(5,1,2)\n",
        "\n",
        "    print(f\"\\nPar√¢metros do Modelo: ARIMA({p},{d},{q})\")\n",
        "    print(f\"  - p (AR): {p} lags auto-regressivos\")\n",
        "    print(f\"  - d (I): {d} diferencia√ß√£o\")\n",
        "    print(f\"  - q (MA): {q} termos de m√©dia m√≥vel\")\n",
        "\n",
        "    digitos_previstos = []\n",
        "    metricas_arima = []\n",
        "\n",
        "    # Processar cada coluna independentemente\n",
        "    for col_idx in range(1, 8):\n",
        "        col_name = f\"Coluna {col_idx}\"\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Treinando ARIMA para {col_name}...\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        if col_name not in df.columns:\n",
        "            digitos_previstos.append(np.random.randint(0, 10))\n",
        "            continue\n",
        "\n",
        "        # Preparar s√©rie temporal\n",
        "        serie = df[col_name].values\n",
        "\n",
        "        # Verificar estacionariedade\n",
        "        adf_result = adfuller(serie)\n",
        "        p_value = adf_result[1]\n",
        "\n",
        "        print(f\"\\n  Teste de Estacionariedade (ADF):\")\n",
        "        print(f\"    - ADF Statistic: {adf_result[0]:.4f}\")\n",
        "        print(f\"    - p-value: {p_value:.4f}\")\n",
        "\n",
        "        if p_value < 0.05:\n",
        "            print(f\"    ‚úì S√©rie √© estacion√°ria\")\n",
        "            estacionaria = True\n",
        "        else:\n",
        "            print(f\"    ‚ö† S√©rie n√£o √© estacion√°ria (diferencia√ß√£o ser√° aplicada)\")\n",
        "            estacionaria = False\n",
        "\n",
        "        try:\n",
        "            # Treinar modelo ARIMA\n",
        "            print(f\"\\n  Treinando modelo ARIMA({p},{d},{q})...\")\n",
        "            model = ARIMA(serie, order=(p, d, q))\n",
        "            model_fit = model.fit()\n",
        "\n",
        "            # Estat√≠sticas do modelo\n",
        "            print(f\"\\n  Estat√≠sticas do Modelo:\")\n",
        "            print(f\"    - AIC: {model_fit.aic:.2f}\")\n",
        "            print(f\"    - BIC: {model_fit.bic:.2f}\")\n",
        "            print(f\"    - Log-Likelihood: {model_fit.llf:.2f}\")\n",
        "\n",
        "            # Fazer previs√£o\n",
        "            forecast = model_fit.forecast(steps=1)\n",
        "            predicao = forecast[0]\n",
        "\n",
        "            # Arredondar e garantir range [0, 9]\n",
        "            digito_previsto = int(np.clip(np.round(predicao), 0, 9))\n",
        "\n",
        "            print(f\"\\n    ‚úì Previs√£o bruta: {predicao:.2f}\")\n",
        "            print(f\"    ‚úì D√≠gito previsto: {digito_previsto}\")\n",
        "\n",
        "            digitos_previstos.append(digito_previsto)\n",
        "\n",
        "            # Guardar m√©tricas\n",
        "            metricas_arima.append({\n",
        "                'coluna': col_idx,\n",
        "                'aic': model_fit.aic,\n",
        "                'bic': model_fit.bic,\n",
        "                'estacionaria': estacionaria,\n",
        "                'predicao_bruta': predicao\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n    ‚ö† Erro ao treinar ARIMA: {str(e)}\")\n",
        "            print(f\"    Usando fallback...\")\n",
        "\n",
        "            # Fallback: m√©dia dos √∫ltimos 5 valores\n",
        "            ultimos_5 = serie[-5:]\n",
        "            media = np.mean(ultimos_5)\n",
        "            digito = int(np.clip(np.round(media), 0, 9))\n",
        "            digitos_previstos.append(digito)\n",
        "\n",
        "    # Resultados finais\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RESULTADOS DA PREVIS√ÉO ARIMA\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nD√≠gitos previstos: {digitos_previstos}\")\n",
        "    print(\"\\nDetalhamento por coluna:\")\n",
        "    for i, digito in enumerate(digitos_previstos, 1):\n",
        "        print(f\"  Coluna {i}: {digito}\")\n",
        "\n",
        "    # Estat√≠sticas gerais\n",
        "    if metricas_arima:\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(\"ESTAT√çSTICAS DO MODELO\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        avg_aic = np.mean([m['aic'] for m in metricas_arima])\n",
        "        avg_bic = np.mean([m['bic'] for m in metricas_arima])\n",
        "        n_estacionarias = sum([1 for m in metricas_arima if m['estacionaria']])\n",
        "\n",
        "        print(f\"\\n  M√©dias dos Crit√©rios:\")\n",
        "        print(f\"    - AIC m√©dio: {avg_aic:.2f}\")\n",
        "        print(f\"    - BIC m√©dio: {avg_bic:.2f}\")\n",
        "        print(f\"\\n  Estacionariedade:\")\n",
        "        print(f\"    - S√©ries estacion√°rias: {n_estacionarias}/7\")\n",
        "        print(f\"    - S√©ries n√£o-estacion√°rias: {7-n_estacionarias}/7\")\n",
        "\n",
        "        if n_estacionarias >= 4:\n",
        "            print(f\"\\n  ‚úì Maioria das s√©ries s√£o estacion√°rias (bom para ARIMA)\")\n",
        "        else:\n",
        "            print(f\"\\n  ‚ö† Poucas s√©ries estacion√°rias (ARIMA pode ter limita√ß√µes)\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ÑπÔ∏è  SOBRE O MODELO ARIMA\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"ARIMA combina tr√™s componentes:\")\n",
        "    print(\"  1. AR (AutoRegressive): Usa valores passados da s√©rie\")\n",
        "    print(\"  2. I (Integrated): Aplica diferencia√ß√£o para tornar estacion√°rio\")\n",
        "    print(\"  3. MA (Moving Average): Modela erros de previs√£o passados\")\n",
        "    print(\"\\nVantagens:\")\n",
        "    print(\"  - M√©todo estat√≠stico cl√°ssico e consolidado\")\n",
        "    print(\"  - Interpreta√ß√£o te√≥rica s√≥lida\")\n",
        "    print(\"  - Bom para s√©ries temporais estacion√°rias\")\n",
        "    print(\"\\nLimita√ß√µes:\")\n",
        "    print(\"  - Assume linearidade\")\n",
        "    print(\"  - Requer estacionariedade\")\n",
        "    print(\"  - Pode ter dificuldades com padr√µes complexos\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ö†Ô∏è  AVISO: Modelo de estudo acad√™mico\")\n",
        "    print(\"Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return digitos_previstos\n",
        "\n",
        "# Executar previs√£o\n",
        "previsao_arima = prever_super_sete_arima()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VtRBovwo7Lt",
        "outputId": "030cc5ad-0134-4a11-df6b-b792d2f1aa58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SUPER SETE - MODELO ARIMA (Auto-Regressive Integrated Moving Average)\n",
            "================================================================================\n",
            "\n",
            "Modelo Estat√≠stico para S√©ries Temporais\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Dataset: 769 sorteios hist√≥ricos\n",
            "\n",
            "Par√¢metros do Modelo: ARIMA(5,1,2)\n",
            "  - p (AR): 5 lags auto-regressivos\n",
            "  - d (I): 1 diferencia√ß√£o\n",
            "  - q (MA): 2 termos de m√©dia m√≥vel\n",
            "\n",
            "================================================================================\n",
            "Treinando ARIMA para Coluna 1...\n",
            "================================================================================\n",
            "\n",
            "  Teste de Estacionariedade (ADF):\n",
            "    - ADF Statistic: -27.8972\n",
            "    - p-value: 0.0000\n",
            "    ‚úì S√©rie √© estacion√°ria\n",
            "\n",
            "  Treinando modelo ARIMA(5,1,2)...\n",
            "\n",
            "  Estat√≠sticas do Modelo:\n",
            "    - AIC: 3819.03\n",
            "    - BIC: 3856.18\n",
            "    - Log-Likelihood: -1901.52\n",
            "\n",
            "    ‚úì Previs√£o bruta: 4.53\n",
            "    ‚úì D√≠gito previsto: 5\n",
            "\n",
            "================================================================================\n",
            "Treinando ARIMA para Coluna 2...\n",
            "================================================================================\n",
            "\n",
            "  Teste de Estacionariedade (ADF):\n",
            "    - ADF Statistic: -27.5098\n",
            "    - p-value: 0.0000\n",
            "    ‚úì S√©rie √© estacion√°ria\n",
            "\n",
            "  Treinando modelo ARIMA(5,1,2)...\n",
            "\n",
            "  Estat√≠sticas do Modelo:\n",
            "    - AIC: 3796.19\n",
            "    - BIC: 3833.34\n",
            "    - Log-Likelihood: -1890.10\n",
            "\n",
            "    ‚úì Previs√£o bruta: 4.79\n",
            "    ‚úì D√≠gito previsto: 5\n",
            "\n",
            "================================================================================\n",
            "Treinando ARIMA para Coluna 3...\n",
            "================================================================================\n",
            "\n",
            "  Teste de Estacionariedade (ADF):\n",
            "    - ADF Statistic: -27.3648\n",
            "    - p-value: 0.0000\n",
            "    ‚úì S√©rie √© estacion√°ria\n",
            "\n",
            "  Treinando modelo ARIMA(5,1,2)...\n",
            "\n",
            "  Estat√≠sticas do Modelo:\n",
            "    - AIC: 3794.41\n",
            "    - BIC: 3831.56\n",
            "    - Log-Likelihood: -1889.21\n",
            "\n",
            "    ‚úì Previs√£o bruta: 4.54\n",
            "    ‚úì D√≠gito previsto: 5\n",
            "\n",
            "================================================================================\n",
            "Treinando ARIMA para Coluna 4...\n",
            "================================================================================\n",
            "\n",
            "  Teste de Estacionariedade (ADF):\n",
            "    - ADF Statistic: -14.8786\n",
            "    - p-value: 0.0000\n",
            "    ‚úì S√©rie √© estacion√°ria\n",
            "\n",
            "  Treinando modelo ARIMA(5,1,2)...\n",
            "\n",
            "  Estat√≠sticas do Modelo:\n",
            "    - AIC: 3821.45\n",
            "    - BIC: 3858.60\n",
            "    - Log-Likelihood: -1902.73\n",
            "\n",
            "    ‚úì Previs√£o bruta: 4.45\n",
            "    ‚úì D√≠gito previsto: 4\n",
            "\n",
            "================================================================================\n",
            "Treinando ARIMA para Coluna 5...\n",
            "================================================================================\n",
            "\n",
            "  Teste de Estacionariedade (ADF):\n",
            "    - ADF Statistic: -14.6256\n",
            "    - p-value: 0.0000\n",
            "    ‚úì S√©rie √© estacion√°ria\n",
            "\n",
            "  Treinando modelo ARIMA(5,1,2)...\n",
            "\n",
            "  Estat√≠sticas do Modelo:\n",
            "    - AIC: 3784.09\n",
            "    - BIC: 3821.24\n",
            "    - Log-Likelihood: -1884.04\n",
            "\n",
            "    ‚úì Previs√£o bruta: 4.35\n",
            "    ‚úì D√≠gito previsto: 4\n",
            "\n",
            "================================================================================\n",
            "Treinando ARIMA para Coluna 6...\n",
            "================================================================================\n",
            "\n",
            "  Teste de Estacionariedade (ADF):\n",
            "    - ADF Statistic: -28.1178\n",
            "    - p-value: 0.0000\n",
            "    ‚úì S√©rie √© estacion√°ria\n",
            "\n",
            "  Treinando modelo ARIMA(5,1,2)...\n",
            "\n",
            "  Estat√≠sticas do Modelo:\n",
            "    - AIC: 3843.88\n",
            "    - BIC: 3881.03\n",
            "    - Log-Likelihood: -1913.94\n",
            "\n",
            "    ‚úì Previs√£o bruta: 4.52\n",
            "    ‚úì D√≠gito previsto: 5\n",
            "\n",
            "================================================================================\n",
            "Treinando ARIMA para Coluna 7...\n",
            "================================================================================\n",
            "\n",
            "  Teste de Estacionariedade (ADF):\n",
            "    - ADF Statistic: -27.2691\n",
            "    - p-value: 0.0000\n",
            "    ‚úì S√©rie √© estacion√°ria\n",
            "\n",
            "  Treinando modelo ARIMA(5,1,2)...\n",
            "\n",
            "  Estat√≠sticas do Modelo:\n",
            "    - AIC: 3822.97\n",
            "    - BIC: 3860.12\n",
            "    - Log-Likelihood: -1903.48\n",
            "\n",
            "    ‚úì Previs√£o bruta: 4.27\n",
            "    ‚úì D√≠gito previsto: 4\n",
            "\n",
            "================================================================================\n",
            "RESULTADOS DA PREVIS√ÉO ARIMA\n",
            "================================================================================\n",
            "\n",
            "D√≠gitos previstos: [5, 5, 5, 4, 4, 5, 4]\n",
            "\n",
            "Detalhamento por coluna:\n",
            "  Coluna 1: 5\n",
            "  Coluna 2: 5\n",
            "  Coluna 3: 5\n",
            "  Coluna 4: 4\n",
            "  Coluna 5: 4\n",
            "  Coluna 6: 5\n",
            "  Coluna 7: 4\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ESTAT√çSTICAS DO MODELO\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  M√©dias dos Crit√©rios:\n",
            "    - AIC m√©dio: 3811.72\n",
            "    - BIC m√©dio: 3848.87\n",
            "\n",
            "  Estacionariedade:\n",
            "    - S√©ries estacion√°rias: 7/7\n",
            "    - S√©ries n√£o-estacion√°rias: 0/7\n",
            "\n",
            "  ‚úì Maioria das s√©ries s√£o estacion√°rias (bom para ARIMA)\n",
            "\n",
            "================================================================================\n",
            "‚ÑπÔ∏è  SOBRE O MODELO ARIMA\n",
            "================================================================================\n",
            "ARIMA combina tr√™s componentes:\n",
            "  1. AR (AutoRegressive): Usa valores passados da s√©rie\n",
            "  2. I (Integrated): Aplica diferencia√ß√£o para tornar estacion√°rio\n",
            "  3. MA (Moving Average): Modela erros de previs√£o passados\n",
            "\n",
            "Vantagens:\n",
            "  - M√©todo estat√≠stico cl√°ssico e consolidado\n",
            "  - Interpreta√ß√£o te√≥rica s√≥lida\n",
            "  - Bom para s√©ries temporais estacion√°rias\n",
            "\n",
            "Limita√ß√µes:\n",
            "  - Assume linearidade\n",
            "  - Requer estacionariedade\n",
            "  - Pode ter dificuldades com padr√µes complexos\n",
            "\n",
            "================================================================================\n",
            "‚ö†Ô∏è  AVISO: Modelo de estudo acad√™mico\n",
            "Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================================\n",
        "# MODELO AVAN√áADO COMPLETO: LSTM 4 Camadas + RF + XGBoost + An√°lise Estat√≠stica\n",
        "# ====================================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from scipy.stats import ks_2samp\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def prever_super_sete_avancado():\n",
        "    print(\"=\"*90)\n",
        "    print(\"SUPER SETE - MODELO AVAN√áADO H√çBRIDO\")\n",
        "    print(\"LSTM 4 Camadas + Random Forest + XGBoost + An√°lise Estat√≠stica KS\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    df = pd.read_excel('Super Sete.xlsx')\n",
        "    n_sorteios = len(df)\n",
        "    print(f\"\\nDataset: {n_sorteios} sorteios\\n\")\n",
        "\n",
        "    digitos_previstos = []\n",
        "    resultados_testes = []\n",
        "\n",
        "    for col_idx in range(1, 8):\n",
        "        col_name = f\"Coluna {col_idx}\"\n",
        "        print(f\"\\n{'='*90}\")\n",
        "        print(f\"Processando {col_name}\")\n",
        "        print(f\"{'='*90}\")\n",
        "\n",
        "        if col_name not in df.columns:\n",
        "            digitos_previstos.append(np.random.randint(0, 10))\n",
        "            continue\n",
        "\n",
        "        dados = df[col_name].values\n",
        "\n",
        "        # === 1. PRE-PROCESSAMENTO AVAN√áADO ===\n",
        "        print(\"\\n[1/5] Pr√©-processamento e Feature Engineering...\")\n",
        "\n",
        "        # Normaliza√ß√£o\n",
        "        scaler = MinMaxScaler()\n",
        "        dados_norm = scaler.fit_transform(dados.reshape(-1, 1))\n",
        "\n",
        "        # Features adicionais\n",
        "        paridade = (dados % 2).reshape(-1, 1)  # Par/√çmpar\n",
        "        # Fix: Use .values attribute to get numpy array\n",
        "        rolling_mean = pd.Series(dados).rolling(5, min_periods=1).mean().values.reshape(-1, 1)\n",
        "        # Fix: Use .values attribute to get numpy array\n",
        "        rolling_std = pd.Series(dados).rolling(5, min_periods=1).std().fillna(0).values.reshape(-1, 1)\n",
        "\n",
        "        # Combinar features\n",
        "        features_combined = np.hstack([dados_norm, paridade, rolling_mean.reshape(-1,1)/10, rolling_std.reshape(-1,1)])\n",
        "\n",
        "        # === 2. MODELO LSTM 4 CAMADAS ===\n",
        "        print(\"[2/5] Treinando LSTM Bidirecional 4 Camadas...\")\n",
        "\n",
        "        # Preparar sequ√™ncias para LSTM\n",
        "        lookback = 20\n",
        "        if len(dados_norm) < lookback + 1:\n",
        "            print(f\"    ‚ö†Ô∏è Dados insuficientes para {col_name}. Pulando...\")\n",
        "            digitos_previstos.append(np.random.randint(0, 10))\n",
        "            continue\n",
        "\n",
        "        X, y = [], []\n",
        "        for i in range(lookback, len(dados_norm)):\n",
        "            X.append(features_combined[i-lookback:i])\n",
        "            y.append(dados_norm[i])\n",
        "\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        # Split treino/valida√ß√£o\n",
        "        split_idx = int(len(X) * 0.8)\n",
        "        X_train, X_val = X[:split_idx], X[split_idx:]\n",
        "        y_train, y_val = y[:split_idx], y[split_idx:]\n",
        "\n",
        "        # Reshape y for LSTM output\n",
        "        y_train = y_train.reshape(-1, 1)\n",
        "        y_val = y_val.reshape(-1, 1)\n",
        "\n",
        "\n",
        "        # Construir modelo LSTM Bidirectional 4 camadas\n",
        "        from tensorflow.keras.models import Sequential\n",
        "        from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, SpatialDropout1D\n",
        "        from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "        model_lstm = Sequential([\n",
        "            # Fix: Move input_shape to the first Bidirectional LSTM layer\n",
        "            SpatialDropout1D(0.2),\n",
        "            Bidirectional(LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))),\n",
        "            Dropout(0.3),\n",
        "            Bidirectional(LSTM(64, return_sequences=True)),\n",
        "            Dropout(0.3),\n",
        "            Bidirectional(LSTM(32, return_sequences=True)),\n",
        "            Dropout(0.2),\n",
        "            Bidirectional(LSTM(16)),\n",
        "            Dropout(0.2),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(1)\n",
        "        ])\n",
        "\n",
        "        model_lstm.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
        "        ]\n",
        "\n",
        "        history = model_lstm.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=50,\n",
        "            batch_size=16,\n",
        "            callbacks=callbacks,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Predi√ß√£o LSTM\n",
        "        ultima_seq = features_combined[-lookback:].reshape(1, lookback, -1)\n",
        "        pred_lstm_norm = model_lstm.predict(ultima_seq, verbose=0)[0][0]\n",
        "        pred_lstm = int(round(scaler.inverse_transform([[pred_lstm_norm]])[0][0])) % 10\n",
        "\n",
        "        # === 3. RANDOM FOREST ===\n",
        "        print(f\"[3/5] Treinando Random Forest para {col_name}...\")\n",
        "        from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "        # Preparar dados para RF (usar features sem normaliza√ß√£o)\n",
        "        X_rf = []\n",
        "        y_rf = []\n",
        "        for i in range(lookback, len(dados)):\n",
        "            features_row = [\n",
        "                paridade[i-1][0], # Fix: Access scalar value from the array\n",
        "                # Fix: Access elements of numpy array using indexing\n",
        "                rolling_mean[i-1][0],\n",
        "                # Fix: Access elements of numpy array using indexing\n",
        "                rolling_std[i-1][0]\n",
        "            ]\n",
        "            X_rf.append(features_row)\n",
        "            y_rf.append(dados[i])\n",
        "\n",
        "        X_rf = np.array(X_rf)\n",
        "        y_rf = np.array(y_rf)\n",
        "\n",
        "        rf_model = RandomForestClassifier(n_estimators=150, max_depth=15, random_state=42)\n",
        "        rf_model.fit(X_rf, y_rf)\n",
        "\n",
        "        # Predi√ß√£o RF\n",
        "        ultima_features_rf = np.array([[\n",
        "            paridade[-1][0], # Fix: Access scalar value from the array\n",
        "            # Fix: Access elements of numpy array using indexing\n",
        "            rolling_mean[-1][0],\n",
        "            # Fix: Access elements of numpy array using indexing\n",
        "            rolling_std[-1][0]\n",
        "        ]])\n",
        "        pred_rf = rf_model.predict(ultima_features_rf)[0]\n",
        "\n",
        "        # Import√¢ncia de features\n",
        "        importances = rf_model.feature_importances_\n",
        "        print(f\"    Feature Importances: Paridade={importances[0]:.3f}, RollingMean={importances[1]:.3f}, RollingStd={importances[2]:.3f}\")\n",
        "\n",
        "        # === 4. XGBOOST ===\n",
        "        print(f\"[4/5] Treinando XGBoost para {col_name}...\")\n",
        "        import xgboost as xgb\n",
        "\n",
        "        xgb_model = xgb.XGBClassifier(\n",
        "            n_estimators=150,\n",
        "            max_depth=6,\n",
        "            learning_rate=0.1,\n",
        "            random_state=42\n",
        "        )\n",
        "        xgb_model.fit(X_rf, y_rf)\n",
        "\n",
        "        pred_xgb = xgb_model.predict(ultima_features_rf)[0]\n",
        "\n",
        "        # === 5. ENSEMBLE E TESTE ESTAT√çSTICO ===\n",
        "        print(f\"[5/5] Ensemble e An√°lise Estat√≠stica para {col_name}...\")\n",
        "\n",
        "        # Ensemble ponderado\n",
        "        pred_ensemble = int(np.round((pred_lstm * 0.4 + pred_rf * 0.3 + pred_xgb * 0.3))) % 10\n",
        "\n",
        "        # Kolmogorov-Smirnov Test\n",
        "        from scipy.stats import kstest\n",
        "\n",
        "        # Distribui√ß√£o uniforme esperada (0-9)\n",
        "        # Fix: Create uniform distribution over integers [0, 9]\n",
        "        uniform_dist = np.random.randint(0, 10, len(dados))\n",
        "        ks_statistic, p_value = kstest(dados, uniform_dist) # Fix: Use the empirical distribution from randint\n",
        "\n",
        "        print(f\"    KS Test: statistic={ks_statistic:.4f}, p-value={p_value:.4f}\")\n",
        "        if p_value > 0.05:\n",
        "            print(f\"    ‚úÖ Distribui√ß√£o √© aleat√≥ria (n√£o rejeita H0)\")\n",
        "        else:\n",
        "            print(f\"    ‚ö†Ô∏è Distribui√ß√£o pode ter padr√µes (rejeita H0)\")\n",
        "\n",
        "        digitos_previstos.append(pred_ensemble)\n",
        "        resultados_testes.append({\n",
        "            'coluna': col_name,\n",
        "            'ks_stat': ks_statistic,\n",
        "            'p_value': p_value,\n",
        "            'pred_lstm': pred_lstm,\n",
        "            'pred_rf': pred_rf,\n",
        "            'pred_xgb': pred_xgb,\n",
        "            'pred_ensemble': pred_ensemble\n",
        "        })\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RESULTADOS FINAIS - MODELO AVAN√áADO\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nüéØ Previs√µes: {digitos_previstos}\")\n",
        "    print(\"\\nüìä Resumo Estat√≠stico:\")\n",
        "    for res in resultados_testes:\n",
        "        print(f\"  {res['coluna']}: LSTM={res['pred_lstm']}, RF={res['pred_rf']}, XGB={res['pred_xgb']}, Ensemble={res['pred_ensemble']} | KS p-value={res['p_value']:.4f}\")\n",
        "\n",
        "    return digitos_previstos\n",
        "\n",
        "prever_super_sete_avancado()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4lXJzbYCAWB",
        "outputId": "aded8cc4-f5b8-465b-ade7-3ca413b3c3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "SUPER SETE - MODELO AVAN√áADO H√çBRIDO\n",
            "LSTM 4 Camadas + Random Forest + XGBoost + An√°lise Estat√≠stica KS\n",
            "==========================================================================================\n",
            "\n",
            "Dataset: 769 sorteios\n",
            "\n",
            "\n",
            "==========================================================================================\n",
            "Processando Coluna 1\n",
            "==========================================================================================\n",
            "\n",
            "[1/5] Pr√©-processamento e Feature Engineering...\n",
            "[2/5] Treinando LSTM Bidirecional 4 Camadas...\n",
            "[3/5] Treinando Random Forest para Coluna 1...\n",
            "    Feature Importances: Paridade=0.016, RollingMean=0.378, RollingStd=0.606\n",
            "[4/5] Treinando XGBoost para Coluna 1...\n",
            "[5/5] Ensemble e An√°lise Estat√≠stica para Coluna 1...\n",
            "    KS Test: statistic=0.0234, p-value=0.9845\n",
            "    ‚úÖ Distribui√ß√£o √© aleat√≥ria (n√£o rejeita H0)\n",
            "\n",
            "==========================================================================================\n",
            "Processando Coluna 2\n",
            "==========================================================================================\n",
            "\n",
            "[1/5] Pr√©-processamento e Feature Engineering...\n",
            "[2/5] Treinando LSTM Bidirecional 4 Camadas...\n",
            "[3/5] Treinando Random Forest para Coluna 2...\n",
            "    Feature Importances: Paridade=0.017, RollingMean=0.360, RollingStd=0.623\n",
            "[4/5] Treinando XGBoost para Coluna 2...\n",
            "[5/5] Ensemble e An√°lise Estat√≠stica para Coluna 2...\n",
            "    KS Test: statistic=0.0325, p-value=0.8115\n",
            "    ‚úÖ Distribui√ß√£o √© aleat√≥ria (n√£o rejeita H0)\n",
            "\n",
            "==========================================================================================\n",
            "Processando Coluna 3\n",
            "==========================================================================================\n",
            "\n",
            "[1/5] Pr√©-processamento e Feature Engineering...\n",
            "[2/5] Treinando LSTM Bidirecional 4 Camadas...\n",
            "[3/5] Treinando Random Forest para Coluna 3...\n",
            "    Feature Importances: Paridade=0.016, RollingMean=0.380, RollingStd=0.604\n",
            "[4/5] Treinando XGBoost para Coluna 3...\n",
            "[5/5] Ensemble e An√°lise Estat√≠stica para Coluna 3...\n",
            "    KS Test: statistic=0.0325, p-value=0.8115\n",
            "    ‚úÖ Distribui√ß√£o √© aleat√≥ria (n√£o rejeita H0)\n",
            "\n",
            "==========================================================================================\n",
            "Processando Coluna 4\n",
            "==========================================================================================\n",
            "\n",
            "[1/5] Pr√©-processamento e Feature Engineering...\n",
            "[2/5] Treinando LSTM Bidirecional 4 Camadas...\n",
            "[3/5] Treinando Random Forest para Coluna 4...\n",
            "    Feature Importances: Paridade=0.018, RollingMean=0.377, RollingStd=0.604\n",
            "[4/5] Treinando XGBoost para Coluna 4...\n",
            "[5/5] Ensemble e An√°lise Estat√≠stica para Coluna 4...\n",
            "    KS Test: statistic=0.0468, p-value=0.3686\n",
            "    ‚úÖ Distribui√ß√£o √© aleat√≥ria (n√£o rejeita H0)\n",
            "\n",
            "==========================================================================================\n",
            "Processando Coluna 5\n",
            "==========================================================================================\n",
            "\n",
            "[1/5] Pr√©-processamento e Feature Engineering...\n",
            "[2/5] Treinando LSTM Bidirecional 4 Camadas...\n",
            "[3/5] Treinando Random Forest para Coluna 5...\n",
            "    Feature Importances: Paridade=0.018, RollingMean=0.375, RollingStd=0.608\n",
            "[4/5] Treinando XGBoost para Coluna 5...\n",
            "[5/5] Ensemble e An√°lise Estat√≠stica para Coluna 5...\n",
            "    KS Test: statistic=0.0221, p-value=0.9919\n",
            "    ‚úÖ Distribui√ß√£o √© aleat√≥ria (n√£o rejeita H0)\n",
            "\n",
            "==========================================================================================\n",
            "Processando Coluna 6\n",
            "==========================================================================================\n",
            "\n",
            "[1/5] Pr√©-processamento e Feature Engineering...\n",
            "[2/5] Treinando LSTM Bidirecional 4 Camadas...\n",
            "[3/5] Treinando Random Forest para Coluna 6...\n",
            "    Feature Importances: Paridade=0.016, RollingMean=0.366, RollingStd=0.617\n",
            "[4/5] Treinando XGBoost para Coluna 6...\n",
            "[5/5] Ensemble e An√°lise Estat√≠stica para Coluna 6...\n",
            "    KS Test: statistic=0.0351, p-value=0.7307\n",
            "    ‚úÖ Distribui√ß√£o √© aleat√≥ria (n√£o rejeita H0)\n",
            "\n",
            "==========================================================================================\n",
            "Processando Coluna 7\n",
            "==========================================================================================\n",
            "\n",
            "[1/5] Pr√©-processamento e Feature Engineering...\n",
            "[2/5] Treinando LSTM Bidirecional 4 Camadas...\n",
            "[3/5] Treinando Random Forest para Coluna 7...\n",
            "    Feature Importances: Paridade=0.014, RollingMean=0.383, RollingStd=0.603\n",
            "[4/5] Treinando XGBoost para Coluna 7...\n",
            "[5/5] Ensemble e An√°lise Estat√≠stica para Coluna 7...\n",
            "    KS Test: statistic=0.0156, p-value=1.0000\n",
            "    ‚úÖ Distribui√ß√£o √© aleat√≥ria (n√£o rejeita H0)\n",
            "\n",
            "================================================================================\n",
            "RESULTADOS FINAIS - MODELO AVAN√áADO\n",
            "================================================================================\n",
            "\n",
            "üéØ Previs√µes: [4, 6, 4, 6, 4, 6, 3]\n",
            "\n",
            "üìä Resumo Estat√≠stico:\n",
            "  Coluna 1: LSTM=4, RF=0, XGB=8, Ensemble=4 | KS p-value=0.9845\n",
            "  Coluna 2: LSTM=5, RF=7, XGB=8, Ensemble=6 | KS p-value=0.8115\n",
            "  Coluna 3: LSTM=4, RF=4, XGB=4, Ensemble=4 | KS p-value=0.8115\n",
            "  Coluna 4: LSTM=5, RF=9, XGB=5, Ensemble=6 | KS p-value=0.3686\n",
            "  Coluna 5: LSTM=5, RF=4, XGB=3, Ensemble=4 | KS p-value=0.9919\n",
            "  Coluna 6: LSTM=5, RF=8, XGB=7, Ensemble=6 | KS p-value=0.7307\n",
            "  Coluna 7: LSTM=4, RF=2, XGB=2, Ensemble=3 | KS p-value=1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 6, 4, 6, 4, 6, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# MODELO 4: Monte Carlo Simulations - Simula√ß√£o Estoc√°stica\n",
        "# ===============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def prever_super_sete_monte_carlo():\n",
        "    \"\"\"\n",
        "    Modelo Monte Carlo para previs√£o do Super Sete.\n",
        "    Executa milhares de simula√ß√µes estoc√°sticas baseadas em distribui√ß√µes hist√≥ricas.\n",
        "\n",
        "    Par√¢metros:\n",
        "    - N√∫mero de simula√ß√µes: 100,000\n",
        "    - M√©todo: Bootstrap com distribui√ß√£o emp√≠rica\n",
        "    - Intervalo de confian√ßa: 95%\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"SUPER SETE - MODELO MONTE CARLO (Simula√ß√£o Estoc√°stica)\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nM√©todo de Simula√ß√£o para Avalia√ß√£o de Probabilidades\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # Carregar dados\n",
        "    df = pd.read_excel('Super Sete.xlsx')\n",
        "    n_sorteios = len(df)\n",
        "    print(f\"\\nDataset: {n_sorteios} sorteios hist√≥ricos\")\n",
        "\n",
        "    # Par√¢metros Monte Carlo\n",
        "    N_SIMULACOES = 100000\n",
        "    CONFIDENCE_LEVEL = 0.95\n",
        "\n",
        "    print(f\"\\nPar√¢metros de Simula√ß√£o:\")\n",
        "    print(f\"  - N√∫mero de simula√ß√µes: {N_SIMULACOES:,}\")\n",
        "    print(f\"  - N√≠vel de confian√ßa: {CONFIDENCE_LEVEL:.0%}\")\n",
        "    print(f\"  - M√©todo: Bootstrap com reamostragem\")\n",
        "\n",
        "    digitos_previstos = []\n",
        "    analises_colunas = []\n",
        "\n",
        "    # Processar cada coluna independentemente\n",
        "    for col_idx in range(1, 8):\n",
        "        col_name = f\"Coluna {col_idx}\"\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Simulando Monte Carlo para {col_name}...\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        if col_name not in df.columns:\n",
        "            digitos_previstos.append(np.random.randint(0, 10))\n",
        "            continue\n",
        "\n",
        "        # Dados hist√≥ricos da coluna\n",
        "        dados_historicos = df[col_name].values\n",
        "\n",
        "        # Calcular estat√≠sticas hist√≥ricas\n",
        "        media_hist = np.mean(dados_historicos)\n",
        "        std_hist = np.std(dados_historicos)\n",
        "\n",
        "        print(f\"\\n  Estat√≠sticas Hist√≥ricas:\")\n",
        "        print(f\"    - M√©dia: {media_hist:.2f}\")\n",
        "        print(f\"    - Desvio padr√£o: {std_hist:.2f}\")\n",
        "        print(f\"    - M√≠nimo: {dados_historicos.min()}\")\n",
        "        print(f\"    - M√°ximo: {dados_historicos.max()}\")\n",
        "\n",
        "        # ===== SIMULA√á√ÉO MONTE CARLO =====\n",
        "        print(f\"\\n  Executando {N_SIMULACOES:,} simula√ß√µes...\")\n",
        "\n",
        "        # M√©todo 1: Bootstrap (reamostragem dos dados hist√≥ricos)\n",
        "        simulacoes_bootstrap = np.random.choice(\n",
        "            dados_historicos,\n",
        "            size=N_SIMULACOES,\n",
        "            replace=True\n",
        "        )\n",
        "\n",
        "        # M√©todo 2: Simula√ß√£o param√©trica (assumindo distribui√ß√£o normal)\n",
        "        simulacoes_parametrica = np.random.normal(\n",
        "            loc=media_hist,\n",
        "            scale=std_hist,\n",
        "            size=N_SIMULACOES\n",
        "        )\n",
        "        # Clipar para range v√°lido [0, 9]\n",
        "        simulacoes_parametrica = np.clip(simulacoes_parametrica, 0, 9)\n",
        "\n",
        "        # Combinar ambos os m√©todos (50% cada)\n",
        "        simulacoes_combinadas = np.concatenate([\n",
        "            simulacoes_bootstrap[:N_SIMULACOES//2],\n",
        "            simulacoes_parametrica[:N_SIMULACOES//2]\n",
        "        ])\n",
        "\n",
        "        # Analisar resultados das simula√ß√µes\n",
        "        valores_unicos, contagens = np.unique(\n",
        "            np.round(simulacoes_combinadas).astype(int),\n",
        "            return_counts=True\n",
        "        )\n",
        "\n",
        "        # Calcular probabilidades\n",
        "        probabilidades = contagens / len(simulacoes_combinadas)\n",
        "\n",
        "        # Criar dicion√°rio de probabilidades\n",
        "        prob_dict = {int(v): float(p) for v, p in zip(valores_unicos, probabilidades)}\n",
        "\n",
        "        # Garantir que todos os d√≠gitos 0-9 tenham uma probabilidade\n",
        "        for d in range(10):\n",
        "            if d not in prob_dict:\n",
        "                prob_dict[d] = 0.0\n",
        "\n",
        "        print(f\"\\n  Distribui√ß√£o de Probabilidades (via Monte Carlo):\")\n",
        "        for digito in range(10):\n",
        "            prob = prob_dict.get(digito, 0)\n",
        "            barra = '‚ñà' * int(prob * 50)  # Barra visual\n",
        "            print(f\"    D√≠gito {digito}: {prob:.4f} {barra}\")\n",
        "\n",
        "        # Selecionar d√≠gito mais prov√°vel\n",
        "        digito_mais_provavel = max(prob_dict.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "        # Calcular intervalo de confian√ßa\n",
        "        alpha = 1 - CONFIDENCE_LEVEL\n",
        "        lower_percentile = (alpha/2) * 100\n",
        "        upper_percentile = (1 - alpha/2) * 100\n",
        "\n",
        "        ic_lower = np.percentile(simulacoes_combinadas, lower_percentile)\n",
        "        ic_upper = np.percentile(simulacoes_combinadas, upper_percentile)\n",
        "\n",
        "        print(f\"\\n  Resultados:\")\n",
        "        print(f\"    - D√≠gito mais prov√°vel: {digito_mais_provavel}\")\n",
        "        print(f\"    - Probabilidade: {prob_dict[digito_mais_provavel]:.2%}\")\n",
        "        print(f\"    - Intervalo de confian√ßa {CONFIDENCE_LEVEL:.0%}: [{ic_lower:.1f}, {ic_upper:.1f}]\")\n",
        "\n",
        "        digitos_previstos.append(digito_mais_provavel)\n",
        "\n",
        "        # Guardar an√°lises\n",
        "        analises_colunas.append({\n",
        "            'coluna': col_idx,\n",
        "            'digito': digito_mais_provavel,\n",
        "            'probabilidade': prob_dict[digito_mais_provavel],\n",
        "            'ic_lower': ic_lower,\n",
        "            'ic_upper': ic_upper,\n",
        "            'media_simulacoes': np.mean(simulacoes_combinadas),\n",
        "            'std_simulacoes': np.std(simulacoes_combinadas)\n",
        "        })\n",
        "\n",
        "    # Resultados finais\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RESULTADOS DA SIMULA√á√ÉO MONTE CARLO\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nD√≠gitos previstos: {digitos_previstos}\")\n",
        "    print(\"\\nDetalhamento por coluna:\")\n",
        "    for i, digito in enumerate(digitos_previstos, 1):\n",
        "        analise = analises_colunas[i-1] if i-1 < len(analises_colunas) else None\n",
        "        if analise:\n",
        "            print(f\"  Coluna {i}: {digito} (prob: {analise['probabilidade']:.2%})\")\n",
        "        else:\n",
        "            print(f\"  Coluna {i}: {digito}\")\n",
        "\n",
        "    # Estat√≠sticas gerais\n",
        "    if analises_colunas:\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(\"ESTAT√çSTICAS DAS SIMULA√á√ïES\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        avg_prob = np.mean([a['probabilidade'] for a in analises_colunas])\n",
        "        avg_std = np.mean([a['std_simulacoes'] for a in analises_colunas])\n",
        "\n",
        "        print(f\"\\n  Probabilidade m√©dia dos d√≠gitos escolhidos: {avg_prob:.2%}\")\n",
        "        print(f\"  Desvio padr√£o m√©dio das simula√ß√µes: {avg_std:.2f}\")\n",
        "\n",
        "        # Qualidade das previs√µes\n",
        "        if avg_prob > 0.15:\n",
        "            print(f\"\\n  ‚úì Alta confian√ßa nas previs√µes\")\n",
        "        elif avg_prob > 0.12:\n",
        "            print(f\"\\n  ‚úì Confian√ßa moderada nas previs√µes\")\n",
        "        else:\n",
        "            print(f\"\\n  ‚ö† Baixa confian√ßa (distribui√ß√£o uniforme)\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ÑπÔ∏è  SOBRE O MODELO MONTE CARLO\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"O M√©todo Monte Carlo:\")\n",
        "    print(\"  - Executa milhares de simula√ß√µes aleat√≥rias\")\n",
        "    print(\"  - Baseado em distribui√ß√µes hist√≥ricas reais\")\n",
        "    print(\"  - Combina Bootstrap e simula√ß√£o param√©trica\")\n",
        "    print(\"  - Fornece intervalos de confian√ßa\")\n",
        "    print(\"\\nVantagens:\")\n",
        "    print(\"  - Quantifica incerteza de forma rigorosa\")\n",
        "    print(\"  - N√£o assume distribui√ß√£o espec√≠fica\")\n",
        "    print(\"  - Robusto para datasets pequenos\")\n",
        "    print(\"  - Amplamente usado em finan√ßas e engenharia\")\n",
        "    print(\"\\nLimita√ß√µes:\")\n",
        "    print(\"  - Computacionalmente intensivo\")\n",
        "    print(\"  - Resultados variam entre execu√ß√µes (estoc√°stico)\")\n",
        "    print(\"  - Qualidade depende dos dados hist√≥ricos\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ö†Ô∏è  AVISO: Modelo de estudo acad√™mico\")\n",
        "    print(\"Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\")\n",
        "    print(\"Este modelo quantifica incerteza, n√£o garante acertos.\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return digitos_previstos\n",
        "\n",
        "# Executar simula√ß√£o\n",
        "previsao_monte_carlo = prever_super_sete_monte_carlo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SkLSYuZpaxd",
        "outputId": "469f8928-26b6-497b-89d1-f250dbd5de36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SUPER SETE - MODELO MONTE CARLO (Simula√ß√£o Estoc√°stica)\n",
            "================================================================================\n",
            "\n",
            "M√©todo de Simula√ß√£o para Avalia√ß√£o de Probabilidades\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Dataset: 770 sorteios hist√≥ricos\n",
            "\n",
            "Par√¢metros de Simula√ß√£o:\n",
            "  - N√∫mero de simula√ß√µes: 100,000\n",
            "  - N√≠vel de confian√ßa: 95%\n",
            "  - M√©todo: Bootstrap com reamostragem\n",
            "\n",
            "================================================================================\n",
            "Simulando Monte Carlo para Coluna 1...\n",
            "================================================================================\n",
            "\n",
            "  Estat√≠sticas Hist√≥ricas:\n",
            "    - M√©dia: 4.33\n",
            "    - Desvio padr√£o: 2.88\n",
            "    - M√≠nimo: 0\n",
            "    - M√°ximo: 9\n",
            "\n",
            "  Executando 100,000 simula√ß√µes...\n",
            "\n",
            "  Distribui√ß√£o de Probabilidades (via Monte Carlo):\n",
            "    D√≠gito 0: 0.1057 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 1: 0.0852 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 2: 0.0963 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 3: 0.1162 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 4: 0.1187 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 5: 0.1205 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 6: 0.1059 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 7: 0.0926 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 8: 0.0744 ‚ñà‚ñà‚ñà\n",
            "    D√≠gito 9: 0.0845 ‚ñà‚ñà‚ñà‚ñà\n",
            "\n",
            "  Resultados:\n",
            "    - D√≠gito mais prov√°vel: 5\n",
            "    - Probabilidade: 12.05%\n",
            "    - Intervalo de confian√ßa 95%: [0.0, 9.0]\n",
            "\n",
            "================================================================================\n",
            "Simulando Monte Carlo para Coluna 2...\n",
            "================================================================================\n",
            "\n",
            "  Estat√≠sticas Hist√≥ricas:\n",
            "    - M√©dia: 4.56\n",
            "    - Desvio padr√£o: 2.83\n",
            "    - M√≠nimo: 0\n",
            "    - M√°ximo: 9\n",
            "\n",
            "  Executando 100,000 simula√ß√µes...\n",
            "\n",
            "  Distribui√ß√£o de Probabilidades (via Monte Carlo):\n",
            "    D√≠gito 0: 0.0838 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 1: 0.0815 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 2: 0.0960 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 3: 0.1117 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 4: 0.1139 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 5: 0.1233 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 6: 0.1149 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 7: 0.1047 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 8: 0.0817 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 9: 0.0884 ‚ñà‚ñà‚ñà‚ñà\n",
            "\n",
            "  Resultados:\n",
            "    - D√≠gito mais prov√°vel: 5\n",
            "    - Probabilidade: 12.33%\n",
            "    - Intervalo de confian√ßa 95%: [0.0, 9.0]\n",
            "\n",
            "================================================================================\n",
            "Simulando Monte Carlo para Coluna 3...\n",
            "================================================================================\n",
            "\n",
            "  Estat√≠sticas Hist√≥ricas:\n",
            "    - M√©dia: 4.49\n",
            "    - Desvio padr√£o: 2.82\n",
            "    - M√≠nimo: 0\n",
            "    - M√°ximo: 9\n",
            "\n",
            "  Executando 100,000 simula√ß√µes...\n",
            "\n",
            "  Distribui√ß√£o de Probabilidades (via Monte Carlo):\n",
            "    D√≠gito 0: 0.0856 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 1: 0.0847 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 2: 0.0956 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 3: 0.1127 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 4: 0.1210 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 5: 0.1290 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 6: 0.1052 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 7: 0.0992 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 8: 0.0837 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 9: 0.0833 ‚ñà‚ñà‚ñà‚ñà\n",
            "\n",
            "  Resultados:\n",
            "    - D√≠gito mais prov√°vel: 5\n",
            "    - Probabilidade: 12.90%\n",
            "    - Intervalo de confian√ßa 95%: [0.0, 9.0]\n",
            "\n",
            "================================================================================\n",
            "Simulando Monte Carlo para Coluna 4...\n",
            "================================================================================\n",
            "\n",
            "  Estat√≠sticas Hist√≥ricas:\n",
            "    - M√©dia: 4.60\n",
            "    - Desvio padr√£o: 2.89\n",
            "    - M√≠nimo: 0\n",
            "    - M√°ximo: 9\n",
            "\n",
            "  Executando 100,000 simula√ß√µes...\n",
            "\n",
            "  Distribui√ß√£o de Probabilidades (via Monte Carlo):\n",
            "    D√≠gito 0: 0.0852 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 1: 0.0830 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 2: 0.0965 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 3: 0.1021 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 4: 0.1115 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 5: 0.1186 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 6: 0.1210 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 7: 0.1039 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 8: 0.0757 ‚ñà‚ñà‚ñà\n",
            "    D√≠gito 9: 0.1024 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\n",
            "  Resultados:\n",
            "    - D√≠gito mais prov√°vel: 6\n",
            "    - Probabilidade: 12.10%\n",
            "    - Intervalo de confian√ßa 95%: [0.0, 9.0]\n",
            "\n",
            "================================================================================\n",
            "Simulando Monte Carlo para Coluna 5...\n",
            "================================================================================\n",
            "\n",
            "  Estat√≠sticas Hist√≥ricas:\n",
            "    - M√©dia: 4.66\n",
            "    - Desvio padr√£o: 2.82\n",
            "    - M√≠nimo: 0\n",
            "    - M√°ximo: 9\n",
            "\n",
            "  Executando 100,000 simula√ß√µes...\n",
            "\n",
            "  Distribui√ß√£o de Probabilidades (via Monte Carlo):\n",
            "    D√≠gito 0: 0.0872 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 1: 0.0632 ‚ñà‚ñà‚ñà\n",
            "    D√≠gito 2: 0.0888 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 3: 0.1169 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 4: 0.1191 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 5: 0.1238 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 6: 0.1155 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 7: 0.1038 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 8: 0.0873 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 9: 0.0944 ‚ñà‚ñà‚ñà‚ñà\n",
            "\n",
            "  Resultados:\n",
            "    - D√≠gito mais prov√°vel: 5\n",
            "    - Probabilidade: 12.38%\n",
            "    - Intervalo de confian√ßa 95%: [0.0, 9.0]\n",
            "\n",
            "================================================================================\n",
            "Simulando Monte Carlo para Coluna 6...\n",
            "================================================================================\n",
            "\n",
            "  Estat√≠sticas Hist√≥ricas:\n",
            "    - M√©dia: 4.56\n",
            "    - Desvio padr√£o: 2.92\n",
            "    - M√≠nimo: 0\n",
            "    - M√°ximo: 9\n",
            "\n",
            "  Executando 100,000 simula√ß√µes...\n",
            "\n",
            "  Distribui√ß√£o de Probabilidades (via Monte Carlo):\n",
            "    D√≠gito 0: 0.0976 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 1: 0.0781 ‚ñà‚ñà‚ñà\n",
            "    D√≠gito 2: 0.0913 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 3: 0.1066 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 4: 0.1217 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 5: 0.1073 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 6: 0.1133 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 7: 0.1038 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 8: 0.0839 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 9: 0.0965 ‚ñà‚ñà‚ñà‚ñà\n",
            "\n",
            "  Resultados:\n",
            "    - D√≠gito mais prov√°vel: 4\n",
            "    - Probabilidade: 12.17%\n",
            "    - Intervalo de confian√ßa 95%: [0.0, 9.0]\n",
            "\n",
            "================================================================================\n",
            "Simulando Monte Carlo para Coluna 7...\n",
            "================================================================================\n",
            "\n",
            "  Estat√≠sticas Hist√≥ricas:\n",
            "    - M√©dia: 4.51\n",
            "    - Desvio padr√£o: 2.87\n",
            "    - M√≠nimo: 0\n",
            "    - M√°ximo: 9\n",
            "\n",
            "  Executando 100,000 simula√ß√µes...\n",
            "\n",
            "  Distribui√ß√£o de Probabilidades (via Monte Carlo):\n",
            "    D√≠gito 0: 0.0885 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 1: 0.0822 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 2: 0.0986 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 3: 0.1140 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 4: 0.1161 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 5: 0.1174 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 6: 0.1108 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 7: 0.0973 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 8: 0.0807 ‚ñà‚ñà‚ñà‚ñà\n",
            "    D√≠gito 9: 0.0945 ‚ñà‚ñà‚ñà‚ñà\n",
            "\n",
            "  Resultados:\n",
            "    - D√≠gito mais prov√°vel: 5\n",
            "    - Probabilidade: 11.74%\n",
            "    - Intervalo de confian√ßa 95%: [0.0, 9.0]\n",
            "\n",
            "================================================================================\n",
            "RESULTADOS DA SIMULA√á√ÉO MONTE CARLO\n",
            "================================================================================\n",
            "\n",
            "D√≠gitos previstos: [5, 5, 5, 6, 5, 4, 5]\n",
            "\n",
            "Detalhamento por coluna:\n",
            "  Coluna 1: 5 (prob: 12.05%)\n",
            "  Coluna 2: 5 (prob: 12.33%)\n",
            "  Coluna 3: 5 (prob: 12.90%)\n",
            "  Coluna 4: 6 (prob: 12.10%)\n",
            "  Coluna 5: 5 (prob: 12.38%)\n",
            "  Coluna 6: 4 (prob: 12.17%)\n",
            "  Coluna 7: 5 (prob: 11.74%)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ESTAT√çSTICAS DAS SIMULA√á√ïES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  Probabilidade m√©dia dos d√≠gitos escolhidos: 12.24%\n",
            "  Desvio padr√£o m√©dio das simula√ß√µes: 2.72\n",
            "\n",
            "  ‚úì Confian√ßa moderada nas previs√µes\n",
            "\n",
            "================================================================================\n",
            "‚ÑπÔ∏è  SOBRE O MODELO MONTE CARLO\n",
            "================================================================================\n",
            "O M√©todo Monte Carlo:\n",
            "  - Executa milhares de simula√ß√µes aleat√≥rias\n",
            "  - Baseado em distribui√ß√µes hist√≥ricas reais\n",
            "  - Combina Bootstrap e simula√ß√£o param√©trica\n",
            "  - Fornece intervalos de confian√ßa\n",
            "\n",
            "Vantagens:\n",
            "  - Quantifica incerteza de forma rigorosa\n",
            "  - N√£o assume distribui√ß√£o espec√≠fica\n",
            "  - Robusto para datasets pequenos\n",
            "  - Amplamente usado em finan√ßas e engenharia\n",
            "\n",
            "Limita√ß√µes:\n",
            "  - Computacionalmente intensivo\n",
            "  - Resultados variam entre execu√ß√µes (estoc√°stico)\n",
            "  - Qualidade depende dos dados hist√≥ricos\n",
            "\n",
            "================================================================================\n",
            "‚ö†Ô∏è  AVISO: Modelo de estudo acad√™mico\n",
            "Loterias s√£o eventos aleat√≥rios. N√£o use para apostas reais.\n",
            "Este modelo quantifica incerteza, n√£o garante acertos.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Carregar dados\n",
        "df = pd.read_excel('Mega-Sena.xlsx')\n",
        "ball_cols = [f'Bola{i}' for i in range(1, 7)]\n",
        "balls = df[ball_cols]\n",
        "\n",
        "# Normalizar\n",
        "scaler = MinMaxScaler()\n",
        "balls_norm = scaler.fit_transform(balls)\n",
        "\n",
        "# Preparar amostras sequenciais (janela)\n",
        "seq_len = 5\n",
        "X, y = [], []\n",
        "for i in range(len(balls_norm)-seq_len):\n",
        "    X.append(balls_norm[i:i+seq_len].flatten())\n",
        "    y.append(balls_norm[i+seq_len])\n",
        "X, y = np.array(X), np.array(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# Modelo MLP\n",
        "model = Sequential([\n",
        "    Input(shape=(X.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(6, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "          validation_data=(X_test, y_test), verbose=0, callbacks=[es])\n",
        "\n",
        "# Previs√£o\n",
        "y_pred_norm = model.predict(X_test)\n",
        "y_pred = scaler.inverse_transform(y_pred_norm)\n",
        "y_true = scaler.inverse_transform(y_test)\n",
        "\n",
        "# M√©tricas\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# Avalia√ß√£o por acertos\n",
        "pred_rounded = [[int(round(x)) for x in linha] for linha in y_pred]\n",
        "true_int    = [[int(round(x)) for x in linha] for linha in y_true]\n",
        "results = []\n",
        "for pred, true in zip(pred_rounded, true_int):\n",
        "    acertos = len(set(pred) & set(true))\n",
        "    results.append(acertos)\n",
        "\n",
        "# Relat√≥rio profissional\n",
        "df_results = pd.DataFrame({\n",
        "    'Real': true_int,\n",
        "    'Previsto': pred_rounded,\n",
        "    'Acertos': results\n",
        "})\n",
        "print('--- Resultados dos primeiros sorteios ---')\n",
        "print(df_results.head(10))\n",
        "print(f'\\nMAE: {mae:.2f} | RMSE: {rmse:.2f}')\n",
        "print(f'M√©dia de acertos: {np.mean(results):.2f}')\n",
        "print(f'M√°ximo de acertos: {np.max(results)}')\n",
        "print(f'Sorteios com 4+ acertos: {(np.array(results)>=4).sum()}')\n"
      ],
      "metadata": {
        "id": "4oWgCh7XpNMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9cf4d86-b0d4-40e9-d2af-86a19088751f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "--- Resultados dos primeiros sorteios ---\n",
            "                       Real                  Previsto  Acertos\n",
            "0   [3, 19, 34, 41, 48, 53]   [8, 18, 27, 35, 45, 53]        1\n",
            "1   [6, 18, 25, 30, 42, 54]   [9, 19, 27, 36, 44, 53]        0\n",
            "2   [7, 30, 31, 41, 50, 56]   [8, 19, 26, 35, 43, 51]        0\n",
            "3   [3, 10, 25, 36, 51, 58]   [8, 18, 26, 35, 43, 53]        0\n",
            "4  [19, 28, 30, 34, 40, 51]   [8, 17, 26, 35, 44, 53]        0\n",
            "5    [5, 9, 11, 16, 43, 57]   [9, 18, 27, 36, 44, 53]        1\n",
            "6  [31, 32, 39, 42, 43, 51]   [9, 17, 26, 35, 44, 52]        0\n",
            "7  [10, 15, 21, 24, 29, 45]   [8, 18, 27, 36, 44, 53]        0\n",
            "8  [14, 21, 22, 29, 35, 46]  [10, 19, 27, 35, 43, 51]        1\n",
            "9   [3, 20, 22, 32, 35, 50]  [10, 19, 27, 36, 43, 52]        0\n",
            "\n",
            "MAE: 6.97 | RMSE: 8.75\n",
            "M√©dia de acertos: 0.66\n",
            "M√°ximo de acertos: 4\n",
            "Sorteios com 4+ acertos: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Carregar sorteios\n",
        "df = pd.read_excel('Mega-Sena.xlsx')\n",
        "balls = df[[f'Bola{i}' for i in range(1,7)]]\n",
        "\n",
        "# Calcular frequ√™ncia hist√≥rica de cada n√∫mero\n",
        "freq_global = balls.apply(pd.Series.value_counts).sum(axis=1)\n",
        "freq_dict = freq_global.to_dict()\n",
        "balls_freq = balls.applymap(lambda x: freq_dict.get(x,0))\n",
        "\n",
        "# Calcular atraso (√∫ltima vez que cada n√∫mero foi sorteado)\n",
        "def calc_atrasos(balls):\n",
        "    atrasos = {n: 0 for n in range(1,61)}\n",
        "    matriz = []\n",
        "    for _, sorteio in balls.iterrows():\n",
        "        atual = []\n",
        "        for n in sorteio:\n",
        "            atual.append(atrasos[n])\n",
        "            atrasos[n] = 0  # zera atraso do sorteado\n",
        "        # Para n√∫meros n√£o sorteados: incrementa 1\n",
        "        for n in atrasos.keys():\n",
        "            if n not in sorteio.values:\n",
        "                atrasos[n] += 1\n",
        "        matriz.append(atual)\n",
        "    return pd.DataFrame(matriz, columns=[f'Atraso{i}' for i in range(1,7)])\n",
        "\n",
        "balls_atrasos = calc_atrasos(balls)\n",
        "\n",
        "# Montar matriz final de features (sorteio + frequ√™ncia + atraso)\n",
        "X_enhanced = pd.concat([balls, balls_freq, balls_atrasos], axis=1)\n",
        "print(X_enhanced.head())\n",
        "\n",
        "# Voc√™ pode normalizar as novas features e alimentar o modelo neural\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_enhanced)\n",
        "\n",
        "# Exemplo para modelo sequencial (janela deslizante)\n",
        "seq_len = 5\n",
        "X_seq, y_seq = [], []\n",
        "for i in range(len(X_scaled)-seq_len):\n",
        "    X_seq.append(X_scaled[i:i+seq_len].flatten())\n",
        "    y_seq.append(X_scaled[i+seq_len][:6]) # apenas bolas reais como target\n",
        "\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "print('Shape com features avan√ßadas:', X_seq.shape, y_seq.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5NzsLF_F0aI",
        "outputId": "c4e44dff-54ae-493e-ee2a-648e9a930bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2560599164.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  balls_freq = balls.applymap(lambda x: freq_dict.get(x,0))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Bola1  Bola2  Bola3  Bola4  Bola5  Bola6  Bola1  Bola2  Bola3  Bola4  \\\n",
            "0      4      5     30     33     41     52  311.0  320.0  308.0  314.0   \n",
            "1      9     37     39     41     43     49  279.0  317.0  280.0  305.0   \n",
            "2     10     11     29     30     36     47  343.0  310.0  293.0  308.0   \n",
            "3      1      5      6     27     42     59  285.0  320.0  292.0  311.0   \n",
            "4      1      2      6     16     19     46  285.0  294.0  292.0  305.0   \n",
            "\n",
            "   Bola5  Bola6  Atraso1  Atraso2  Atraso3  Atraso4  Atraso5  Atraso6  \n",
            "0  305.0  297.0        0        0        0        0        0        0  \n",
            "1  308.0  297.0        1        1        1        0        1        1  \n",
            "2  298.0  280.0        2        2        2        1        2        2  \n",
            "3  309.0  284.0        3        2        3        3        3        3  \n",
            "4  287.0  308.0        0        4        0        4        4        4  \n",
            "Shape com features avan√ßadas: (2934, 90) (2934, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Imports necess√°rios ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# --- Carregar dados ---\n",
        "df = pd.read_excel('Mega-Sena.xlsx')\n",
        "balls = df[[f'Bola{i}' for i in range(1,7)]]\n",
        "\n",
        "# --- Feature Engineering: Frequ√™ncia, atraso, m√©dias m√≥veis ---\n",
        "# Frequ√™ncia hist√≥rica\n",
        "freq_global = balls.apply(pd.Series.value_counts).sum(axis=1)\n",
        "freq_dict = freq_global.to_dict()\n",
        "balls_freq = balls.applymap(lambda x: freq_dict.get(x,0))\n",
        "\n",
        "# Atraso (\"quantos concursos desde a √∫ltima apari√ß√£o de cada n√∫mero\")\n",
        "def calc_atrasos(balls):\n",
        "    atrasos = {n: 0 for n in range(1,61)}\n",
        "    matriz = []\n",
        "    for _, sorteio in balls.iterrows():\n",
        "        atual = []\n",
        "        for n in sorteio:\n",
        "            atual.append(atrasos[n])\n",
        "            atrasos[n] = 0\n",
        "        for n in atrasos.keys():\n",
        "            if n not in sorteio.values:\n",
        "                atrasos[n] += 1\n",
        "        matriz.append(atual)\n",
        "    return pd.DataFrame(matriz, columns=[f'Atraso{i}' for i in range(1,7)])\n",
        "balls_atrasos = calc_atrasos(balls)\n",
        "\n",
        "# M√©dia m√≥vel (√∫ltimas 5 apari√ß√µes de cada n√∫mero)\n",
        "def moving_average_feature(balls, window=5):\n",
        "    medias = []\n",
        "    for col in balls.columns:\n",
        "        col_vals = balls[col].tolist()\n",
        "        col_media = [np.mean(col_vals[max(0,i-window):i]) if i > 0 else col_vals[0] for i in range(len(col_vals))]\n",
        "        medias.append(col_media)\n",
        "    return pd.DataFrame(np.array(medias).T, columns=[f'MedMovel{i}' for i in range(1,7)])\n",
        "balls_medias = moving_average_feature(balls)\n",
        "\n",
        "# Matriz de features final\n",
        "X = pd.concat([balls, balls_freq, balls_atrasos, balls_medias], axis=1)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# --- Window sequencial para modelo temporal (seq_len=5) ---\n",
        "seq_len = 5\n",
        "X_seq, y_seq = [], []\n",
        "for i in range(len(X_scaled)-seq_len):\n",
        "    X_seq.append(X_scaled[i:i+seq_len].flatten())\n",
        "    y_seq.append(X_scaled[i+seq_len][:6])  # alvo: apenas bolas reais\n",
        "\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# --- Split treino/teste ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
        "\n",
        "# --- Modelo Neural (MLP) ---\n",
        "model = Sequential([\n",
        "    Input(shape=(X_seq.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(6, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "          validation_data=(X_test, y_test), verbose=2, callbacks=[es, rlr])\n",
        "\n",
        "# --- Avalia√ß√£o ---\n",
        "y_pred_norm = model.predict(X_test)\n",
        "y_pred = scaler.inverse_transform(np.hstack([y_pred_norm, np.zeros((y_pred_norm.shape[0], X.shape[1]-6))]))[:, :6]\n",
        "y_true = scaler.inverse_transform(np.hstack([y_test, np.zeros((y_test.shape[0], X.shape[1]-6))]))[:, :6]\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "pred_rounded = [[int(round(x)) for x in linha] for linha in y_pred]\n",
        "true_int    = [[int(round(x)) for x in linha] for linha in y_true]\n",
        "results = []\n",
        "for pred, true in zip(pred_rounded, true_int):\n",
        "    acertos = len(set(pred) & set(true))\n",
        "    results.append(acertos)\n",
        "df_results = pd.DataFrame({'Real': true_int, 'Previsto': pred_rounded, 'Acertos': results})\n",
        "\n",
        "print('--- Resultados dos primeiros sorteios ---')\n",
        "print(df_results.head(10))\n",
        "print(f'\\nMAE: {mae:.2f} | RMSE: {rmse:.2f}')\n",
        "print(f'M√©dia de acertos: {np.mean(results):.2f}')\n",
        "print(f'M√°ximo de acertos: {np.max(results)}')\n",
        "print(f'Sorteios com 4+ acertos: {(np.array(results)>=4).sum()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1r-81K9GJaS",
        "outputId": "731632de-b1cf-4d22-acf4-0de2061e9fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-221444555.py:19: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  balls_freq = balls.applymap(lambda x: freq_dict.get(x,0))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "74/74 - 5s - 61ms/step - loss: 0.0358 - mae: 0.1520 - val_loss: 0.0332 - val_mae: 0.1452 - learning_rate: 1.0000e-03\n",
            "Epoch 2/100\n",
            "74/74 - 1s - 8ms/step - loss: 0.0334 - mae: 0.1466 - val_loss: 0.0332 - val_mae: 0.1457 - learning_rate: 1.0000e-03\n",
            "Epoch 3/100\n",
            "74/74 - 1s - 15ms/step - loss: 0.0332 - mae: 0.1462 - val_loss: 0.0330 - val_mae: 0.1458 - learning_rate: 1.0000e-03\n",
            "Epoch 4/100\n",
            "74/74 - 1s - 7ms/step - loss: 0.0332 - mae: 0.1461 - val_loss: 0.0331 - val_mae: 0.1461 - learning_rate: 1.0000e-03\n",
            "Epoch 5/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0331 - mae: 0.1460 - val_loss: 0.0330 - val_mae: 0.1441 - learning_rate: 1.0000e-03\n",
            "Epoch 6/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0330 - mae: 0.1457 - val_loss: 0.0331 - val_mae: 0.1454 - learning_rate: 1.0000e-03\n",
            "Epoch 7/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0329 - mae: 0.1455 - val_loss: 0.0330 - val_mae: 0.1460 - learning_rate: 1.0000e-03\n",
            "Epoch 8/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0329 - mae: 0.1454 - val_loss: 0.0331 - val_mae: 0.1454 - learning_rate: 1.0000e-03\n",
            "Epoch 9/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0328 - mae: 0.1453 - val_loss: 0.0334 - val_mae: 0.1463 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0327 - mae: 0.1450 - val_loss: 0.0329 - val_mae: 0.1451 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0328 - mae: 0.1450 - val_loss: 0.0329 - val_mae: 0.1449 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0326 - mae: 0.1448 - val_loss: 0.0329 - val_mae: 0.1458 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0326 - mae: 0.1447 - val_loss: 0.0331 - val_mae: 0.1445 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0326 - mae: 0.1447 - val_loss: 0.0330 - val_mae: 0.1450 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0325 - mae: 0.1445 - val_loss: 0.0329 - val_mae: 0.1441 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0323 - mae: 0.1441 - val_loss: 0.0329 - val_mae: 0.1449 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0323 - mae: 0.1441 - val_loss: 0.0329 - val_mae: 0.1448 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0323 - mae: 0.1438 - val_loss: 0.0330 - val_mae: 0.1457 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "74/74 - 0s - 5ms/step - loss: 0.0321 - mae: 0.1439 - val_loss: 0.0330 - val_mae: 0.1448 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0321 - mae: 0.1435 - val_loss: 0.0331 - val_mae: 0.1448 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0320 - mae: 0.1433 - val_loss: 0.0330 - val_mae: 0.1449 - learning_rate: 1.2500e-04\n",
            "Epoch 22/100\n",
            "74/74 - 0s - 5ms/step - loss: 0.0319 - mae: 0.1433 - val_loss: 0.0331 - val_mae: 0.1448 - learning_rate: 1.2500e-04\n",
            "Epoch 23/100\n",
            "74/74 - 0s - 5ms/step - loss: 0.0319 - mae: 0.1431 - val_loss: 0.0331 - val_mae: 0.1449 - learning_rate: 1.2500e-04\n",
            "Epoch 24/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0319 - mae: 0.1431 - val_loss: 0.0331 - val_mae: 0.1450 - learning_rate: 1.2500e-04\n",
            "Epoch 25/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0318 - mae: 0.1430 - val_loss: 0.0331 - val_mae: 0.1448 - learning_rate: 1.2500e-04\n",
            "Epoch 26/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0317 - mae: 0.1426 - val_loss: 0.0331 - val_mae: 0.1452 - learning_rate: 6.2500e-05\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
            "--- Resultados dos primeiros sorteios ---\n",
            "                       Real                 Previsto  Acertos\n",
            "0   [3, 19, 34, 41, 48, 53]  [8, 17, 27, 36, 44, 53]        1\n",
            "1   [6, 18, 25, 30, 42, 54]  [8, 18, 27, 36, 43, 52]        1\n",
            "2   [7, 30, 31, 41, 50, 56]  [9, 17, 26, 35, 43, 51]        0\n",
            "3   [3, 10, 25, 36, 51, 58]  [9, 17, 27, 36, 43, 51]        2\n",
            "4  [19, 28, 30, 34, 40, 51]  [8, 17, 26, 35, 44, 53]        0\n",
            "5    [5, 9, 11, 16, 43, 57]  [8, 17, 27, 36, 43, 52]        1\n",
            "6  [31, 32, 39, 42, 43, 51]  [8, 17, 26, 35, 44, 52]        0\n",
            "7  [10, 15, 21, 24, 29, 45]  [8, 17, 27, 36, 44, 53]        0\n",
            "8  [14, 21, 22, 29, 35, 46]  [9, 17, 27, 36, 43, 52]        0\n",
            "9   [3, 20, 22, 32, 35, 50]  [7, 18, 28, 36, 44, 53]        0\n",
            "\n",
            "MAE: 6.94 | RMSE: 8.72\n",
            "M√©dia de acertos: 0.64\n",
            "M√°ximo de acertos: 4\n",
            "Sorteios com 4+ acertos: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Imports ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# --- Carregar dados ---\n",
        "df = pd.read_excel('Mega-Sena.xlsx')\n",
        "balls = df[[f'Bola{i}' for i in range(1,7)]]\n",
        "\n",
        "# --- Feature Engineering: Frequ√™ncia, atraso, m√©dias m√≥veis ---\n",
        "freq_global = balls.apply(pd.Series.value_counts).sum(axis=1)\n",
        "freq_dict = freq_global.to_dict()\n",
        "balls_freq = balls.applymap(lambda x: freq_dict.get(x,0))\n",
        "\n",
        "def calc_atrasos(balls):\n",
        "    atrasos = {n: 0 for n in range(1,61)}\n",
        "    matriz = []\n",
        "    for _, sorteio in balls.iterrows():\n",
        "        atual = []\n",
        "        for n in sorteio:\n",
        "            atual.append(atrasos[n])\n",
        "            atrasos[n] = 0\n",
        "        for n in atrasos.keys():\n",
        "            if n not in sorteio.values:\n",
        "                atrasos[n] += 1\n",
        "        matriz.append(atual)\n",
        "    return pd.DataFrame(matriz, columns=[f'Atraso{i}' for i in range(1,7)])\n",
        "balls_atrasos = calc_atrasos(balls)\n",
        "\n",
        "def moving_average_feature(balls, window=5):\n",
        "    medias = []\n",
        "    for col in balls.columns:\n",
        "        col_vals = balls[col].tolist()\n",
        "        col_media = [np.mean(col_vals[max(0,i-window):i]) if i > 0 else col_vals[0] for i in range(len(col_vals))]\n",
        "        medias.append(col_media)\n",
        "    return pd.DataFrame(np.array(medias).T, columns=[f'MedMovel{i}' for i in range(1,7)])\n",
        "balls_medias = moving_average_feature(balls)\n",
        "\n",
        "X = pd.concat([balls, balls_freq, balls_atrasos, balls_medias], axis=1)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# --- Dados para LSTM ---\n",
        "seq_len = 5\n",
        "X_seq, y_seq = [], []\n",
        "for i in range(len(X_scaled)-seq_len):\n",
        "    X_seq.append(X_scaled[i:i+seq_len])\n",
        "    y_seq.append(X_scaled[i+seq_len][:6])\n",
        "X_seq = np.array(X_seq) # [amostras, seq_len, n_features]\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# --- Split treino/teste ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
        "\n",
        "# --- Modelo LSTM ---\n",
        "model = Sequential([\n",
        "    Input(shape=(seq_len, X_seq.shape[2])),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(6, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "model.fit(X_train, y_train, epochs=300, batch_size=32,\n",
        "          validation_data=(X_test, y_test), verbose=2, callbacks=[es, rlr])\n",
        "\n",
        "# --- Avalia√ß√£o ---\n",
        "y_pred_norm = model.predict(X_test)\n",
        "# Desnormaliza somente bolas reais\n",
        "n_features = X.shape[1]\n",
        "y_pred_full = np.hstack([y_pred_norm, np.zeros((y_pred_norm.shape[0], n_features - 6))])\n",
        "y_true_full = np.hstack([y_test, np.zeros((y_test.shape[0], n_features - 6))])\n",
        "y_pred = scaler.inverse_transform(y_pred_full)[:, :6]\n",
        "y_true = scaler.inverse_transform(y_true_full)[:, :6]\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "pred_rounded = [[int(round(x)) for x in linha] for linha in y_pred]\n",
        "true_int    = [[int(round(x)) for x in linha] for linha in y_true]\n",
        "results = [len(set(pred) & set(true)) for pred, true in zip(pred_rounded, true_int)]\n",
        "df_results = pd.DataFrame({'Real': true_int, 'Previsto': pred_rounded, 'Acertos': results})\n",
        "\n",
        "print('--- Resultados dos primeiros sorteios ---')\n",
        "print(df_results.head(10))\n",
        "print(f'\\nMAE: {mae:.2f} | RMSE: {rmse:.2f}')\n",
        "print(f'M√©dia de acertos: {np.mean(results):.2f}')\n",
        "print(f'M√°ximo de acertos: {np.max(results)}')\n",
        "print(f'Sorteios com 4+ acertos: {(np.array(results)>=4).sum()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4WhJnn3GhEG",
        "outputId": "21f42bc8-10de-407d-c486-a788d07dece7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1367652650.py:18: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  balls_freq = balls.applymap(lambda x: freq_dict.get(x,0))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "74/74 - 3s - 34ms/step - loss: 0.0379 - mae: 0.1577 - val_loss: 0.0333 - val_mae: 0.1448 - learning_rate: 1.0000e-03\n",
            "Epoch 2/300\n",
            "74/74 - 1s - 7ms/step - loss: 0.0332 - mae: 0.1461 - val_loss: 0.0329 - val_mae: 0.1444 - learning_rate: 1.0000e-03\n",
            "Epoch 3/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0333 - mae: 0.1465 - val_loss: 0.0329 - val_mae: 0.1449 - learning_rate: 1.0000e-03\n",
            "Epoch 4/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0331 - mae: 0.1457 - val_loss: 0.0328 - val_mae: 0.1440 - learning_rate: 1.0000e-03\n",
            "Epoch 5/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0331 - mae: 0.1460 - val_loss: 0.0328 - val_mae: 0.1442 - learning_rate: 1.0000e-03\n",
            "Epoch 6/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0330 - mae: 0.1457 - val_loss: 0.0329 - val_mae: 0.1445 - learning_rate: 1.0000e-03\n",
            "Epoch 7/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0330 - mae: 0.1458 - val_loss: 0.0329 - val_mae: 0.1437 - learning_rate: 1.0000e-03\n",
            "Epoch 8/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0331 - mae: 0.1457 - val_loss: 0.0329 - val_mae: 0.1443 - learning_rate: 1.0000e-03\n",
            "Epoch 9/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0330 - mae: 0.1457 - val_loss: 0.0329 - val_mae: 0.1457 - learning_rate: 1.0000e-03\n",
            "Epoch 10/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0329 - mae: 0.1456 - val_loss: 0.0328 - val_mae: 0.1444 - learning_rate: 5.0000e-04\n",
            "Epoch 11/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0329 - mae: 0.1456 - val_loss: 0.0328 - val_mae: 0.1450 - learning_rate: 5.0000e-04\n",
            "Epoch 12/300\n",
            "74/74 - 1s - 9ms/step - loss: 0.0329 - mae: 0.1456 - val_loss: 0.0328 - val_mae: 0.1441 - learning_rate: 5.0000e-04\n",
            "Epoch 13/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0329 - mae: 0.1455 - val_loss: 0.0328 - val_mae: 0.1444 - learning_rate: 5.0000e-04\n",
            "Epoch 14/300\n",
            "74/74 - 0s - 7ms/step - loss: 0.0329 - mae: 0.1455 - val_loss: 0.0329 - val_mae: 0.1452 - learning_rate: 5.0000e-04\n",
            "Epoch 15/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0329 - mae: 0.1455 - val_loss: 0.0328 - val_mae: 0.1451 - learning_rate: 2.5000e-04\n",
            "Epoch 16/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0328 - mae: 0.1455 - val_loss: 0.0330 - val_mae: 0.1451 - learning_rate: 2.5000e-04\n",
            "Epoch 17/300\n",
            "74/74 - 1s - 8ms/step - loss: 0.0328 - mae: 0.1454 - val_loss: 0.0329 - val_mae: 0.1450 - learning_rate: 2.5000e-04\n",
            "Epoch 18/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0328 - mae: 0.1454 - val_loss: 0.0330 - val_mae: 0.1450 - learning_rate: 2.5000e-04\n",
            "Epoch 19/300\n",
            "74/74 - 1s - 9ms/step - loss: 0.0328 - mae: 0.1453 - val_loss: 0.0328 - val_mae: 0.1449 - learning_rate: 2.5000e-04\n",
            "Epoch 20/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0328 - mae: 0.1453 - val_loss: 0.0329 - val_mae: 0.1449 - learning_rate: 1.2500e-04\n",
            "Epoch 21/300\n",
            "74/74 - 0s - 6ms/step - loss: 0.0327 - mae: 0.1453 - val_loss: 0.0330 - val_mae: 0.1447 - learning_rate: 1.2500e-04\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "--- Resultados dos primeiros sorteios ---\n",
            "                       Real                 Previsto  Acertos\n",
            "0   [3, 19, 34, 41, 48, 53]  [9, 18, 27, 35, 43, 52]        0\n",
            "1   [6, 18, 25, 30, 42, 54]  [9, 18, 27, 35, 43, 52]        1\n",
            "2   [7, 30, 31, 41, 50, 56]  [9, 18, 26, 35, 43, 52]        0\n",
            "3   [3, 10, 25, 36, 51, 58]  [9, 18, 27, 35, 43, 52]        0\n",
            "4  [19, 28, 30, 34, 40, 51]  [9, 17, 27, 35, 43, 52]        0\n",
            "5    [5, 9, 11, 16, 43, 57]  [9, 18, 26, 35, 43, 52]        2\n",
            "6  [31, 32, 39, 42, 43, 51]  [9, 17, 27, 36, 44, 52]        0\n",
            "7  [10, 15, 21, 24, 29, 45]  [9, 17, 26, 35, 43, 52]        0\n",
            "8  [14, 21, 22, 29, 35, 46]  [9, 17, 27, 36, 44, 52]        0\n",
            "9   [3, 20, 22, 32, 35, 50]  [9, 17, 27, 35, 44, 52]        1\n",
            "\n",
            "MAE: 6.95 | RMSE: 8.70\n",
            "M√©dia de acertos: 0.60\n",
            "M√°ximo de acertos: 4\n",
            "Sorteios com 4+ acertos: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- IMPORTS ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, clone_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "\n",
        "# --- CARREGAR DADOS ---\n",
        "df = pd.read_excel('Mega-Sena.xlsx')\n",
        "balls = df[[f'Bola{i}' for i in range(1,7)]]\n",
        "\n",
        "# --- FEATURE ENGINEERING ---\n",
        "# Frequ√™ncia hist√≥rica\n",
        "freq_global = balls.apply(pd.Series.value_counts).sum(axis=1)\n",
        "freq_dict = freq_global.to_dict()\n",
        "balls_freq = balls.applymap(lambda x: freq_dict.get(x,0))\n",
        "\n",
        "# Atraso\n",
        "def calc_atrasos(balls):\n",
        "    atrasos = {n: 0 for n in range(1,61)}\n",
        "    matriz = []\n",
        "    for _, sorteio in balls.iterrows():\n",
        "        atual = []\n",
        "        for n in sorteio:\n",
        "            atual.append(atrasos[n])\n",
        "            atrasos[n] = 0\n",
        "        for n in atrasos.keys():\n",
        "            if n not in sorteio.values:\n",
        "                atrasos[n] += 1\n",
        "        matriz.append(atual)\n",
        "    return pd.DataFrame(matriz, columns=[f'Atraso{i}' for i in range(1,7)])\n",
        "balls_atrasos = calc_atrasos(balls)\n",
        "\n",
        "# M√©dia m√≥vel (janela=5)\n",
        "def moving_average_feature(balls, window=5):\n",
        "    medias = []\n",
        "    for col in balls.columns:\n",
        "        col_vals = balls[col].tolist()\n",
        "        col_media = [np.mean(col_vals[max(0,i-window):i]) if i > 0 else col_vals[0] for i in range(len(col_vals))]\n",
        "        medias.append(col_media)\n",
        "    return pd.DataFrame(np.array(medias).T, columns=[f'MedMovel{i}' for i in range(1,7)])\n",
        "balls_medias = moving_average_feature(balls)\n",
        "\n",
        "# Matriz de features final\n",
        "X = pd.concat([balls, balls_freq, balls_atrasos, balls_medias], axis=1)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# --- PREPARAR DADOS PARA LSTM ---\n",
        "seq_len = 5\n",
        "X_seq, y_seq = [], []\n",
        "for i in range(len(X_scaled)-seq_len):\n",
        "    X_seq.append(X_scaled[i:i+seq_len])\n",
        "    y_seq.append(X_scaled[i+seq_len][:6])\n",
        "X_seq = np.array(X_seq) # [amostras, seq_len, n_features]\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# --- SPLIT TREINO/TESTE ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
        "\n",
        "# --- DEFINI√á√ÉO DO MODELO LSTM ---\n",
        "def make_lstm(seq_len, n_features):\n",
        "    model = Sequential([\n",
        "        Input(shape=(seq_len, n_features)),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(6, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# --- ENSEMBLE ---\n",
        "n_models = 5\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=25, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "]\n",
        "\n",
        "ensemble_preds = []\n",
        "for seed in range(n_models):\n",
        "    print(f\"Treinando modelo {seed+1}/{n_models}\")\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    model = make_lstm(seq_len, X_seq.shape[2])\n",
        "    model.fit(X_train, y_train, epochs=300, batch_size=32,\n",
        "              validation_data=(X_test, y_test),\n",
        "              verbose=0, callbacks=callbacks)\n",
        "    preds = model.predict(X_test)\n",
        "    ensemble_preds.append(preds)\n",
        "\n",
        "# --- M√âDIA DAS PREVIS√ïES ---\n",
        "ensemble_preds = np.array(ensemble_preds)\n",
        "y_pred_norm_ensemble = np.mean(ensemble_preds, axis=0)\n",
        "\n",
        "# --- DESNORMALIZA E AVALIA ---\n",
        "n_full_features = X.shape[1]\n",
        "y_pred_full = np.hstack([y_pred_norm_ensemble, np.zeros((y_pred_norm_ensemble.shape[0], n_full_features - 6))])\n",
        "y_true_full = np.hstack([y_test, np.zeros((y_test.shape[0], n_full_features - 6))])\n",
        "y_pred = scaler.inverse_transform(y_pred_full)[:, :6]\n",
        "y_true = scaler.inverse_transform(y_true_full)[:, :6]\n",
        "\n",
        "pred_rounded = [[int(round(x)) for x in linha] for linha in y_pred]\n",
        "true_int    = [[int(round(x)) for x in linha] for linha in y_true]\n",
        "results = [len(set(pred) & set(true)) for pred, true in zip(pred_rounded, true_int)]\n",
        "df_results = pd.DataFrame({'Real': true_int, 'Previsto': pred_rounded, 'Acertos': results})\n",
        "\n",
        "# --- RELAT√ìRIO FINAL ---\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "print('--- Resultados dos primeiros sorteios do ensemble ---')\n",
        "print(df_results.head(10))\n",
        "print(f'\\nMAE: {mae:.2f} | RMSE: {rmse:.2f}')\n",
        "print(f'M√©dia de acertos: {np.mean(results):.2f}')\n",
        "print(f'M√°ximo de acertos: {np.max(results)}')\n",
        "print(f'Sorteios com 4+ acertos: {(np.array(results)>=4).sum()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1lT6CXpLVeS",
        "outputId": "df32bb25-8b84-435f-a4f6-d0e9e2d47b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1484469882.py:20: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  balls_freq = balls.applymap(lambda x: freq_dict.get(x,0))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando modelo 1/5\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Treinando modelo 2/5\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Treinando modelo 3/5\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Treinando modelo 4/5\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Treinando modelo 5/5\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "--- Resultados dos primeiros sorteios do ensemble ---\n",
            "                       Real                 Previsto  Acertos\n",
            "0   [3, 19, 34, 41, 48, 53]  [9, 17, 26, 35, 44, 52]        0\n",
            "1   [6, 18, 25, 30, 42, 54]  [8, 17, 26, 35, 43, 52]        0\n",
            "2   [7, 30, 31, 41, 50, 56]  [8, 17, 26, 35, 43, 52]        0\n",
            "3   [3, 10, 25, 36, 51, 58]  [8, 17, 26, 35, 43, 52]        0\n",
            "4  [19, 28, 30, 34, 40, 51]  [9, 17, 26, 35, 44, 52]        0\n",
            "5    [5, 9, 11, 16, 43, 57]  [8, 17, 26, 35, 43, 52]        1\n",
            "6  [31, 32, 39, 42, 43, 51]  [9, 17, 26, 35, 44, 52]        0\n",
            "7  [10, 15, 21, 24, 29, 45]  [8, 17, 26, 35, 43, 52]        0\n",
            "8  [14, 21, 22, 29, 35, 46]  [8, 17, 26, 35, 44, 52]        1\n",
            "9   [3, 20, 22, 32, 35, 50]  [9, 17, 26, 35, 44, 52]        1\n",
            "\n",
            "MAE: 6.93 | RMSE: 8.70\n",
            "M√©dia de acertos: 0.59\n",
            "M√°ximo de acertos: 4\n",
            "Sorteios com 4+ acertos: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Conv1D, Flatten, Permute, Multiply, Activation, Lambda\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# --- CARREGAR E FEATURE ENGINEERING ---\n",
        "df = pd.read_excel('Mega-Sena.xlsx')\n",
        "balls = df[[f'Bola{i}' for i in range(1,7)]]\n",
        "freq_global = balls.apply(pd.Series.value_counts).sum(axis=1)\n",
        "freq_dict = freq_global.to_dict()\n",
        "balls_freq = balls.map(lambda x: freq_dict.get(x,0)) # Fixed: Changed applymap to map\n",
        "\n",
        "def calc_atrasos(balls):\n",
        "    atrasos = {n: 0 for n in range(1,61)}\n",
        "    matriz = []\n",
        "    for _, sorteio in balls.iterrows():\n",
        "        atual = []\n",
        "        for n in sorteio:\n",
        "            atual.append(atrasos[n])\n",
        "            atrasos[n] = 0\n",
        "        for n in atrasos.keys():\n",
        "            if n not in sorteio.values:\n",
        "                atrasos[n] += 1\n",
        "        matriz.append(atual)\n",
        "    return pd.DataFrame(matriz, columns=[f'Atraso{i}' for i in range(1,7)])\n",
        "\n",
        "def moving_average_feature(balls, window=5):\n",
        "    medias = []\n",
        "    for col in balls.columns:\n",
        "        col_vals = balls[col].tolist()\n",
        "        col_media = [np.mean(col_vals[max(0,i-window):i]) if i > 0 else col_vals[0] for i in range(len(col_vals))]\n",
        "        medias.append(col_media)\n",
        "    return pd.DataFrame(np.array(medias).T, columns=[f'MedMovel{i}' for i in range(1,7)])\n",
        "balls_atrasos = calc_atrasos(balls)\n",
        "balls_medias = moving_average_feature(balls)\n",
        "\n",
        "X = pd.concat([balls, balls_freq, balls_atrasos, balls_medias], axis=1)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# --- PREPARA√á√ÉO SEQUENCIAL ---\n",
        "seq_len = 5\n",
        "X_seq, y_seq = [], []\n",
        "for i in range(len(X_scaled)-seq_len):\n",
        "    X_seq.append(X_scaled[i:i+seq_len])\n",
        "    y_seq.append(X_scaled[i+seq_len][:6])\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
        "\n",
        "# --- MLP ---\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "model_mlp = Sequential([\n",
        "    Input(shape=(X_train_flat.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(6, activation='sigmoid')\n",
        "])\n",
        "model_mlp.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model_mlp.fit(X_train_flat, y_train, epochs=100, batch_size=32,\n",
        "              validation_data=(X_test_flat, y_test), verbose=2, callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n",
        "\n",
        "# --- CNN 1D + LSTM ---\n",
        "model_cnn_lstm = Sequential([\n",
        "    Input(shape=(seq_len, X_seq.shape[2])),\n",
        "    Conv1D(filters=64, kernel_size=2, activation='relu'),\n",
        "    LSTM(32, return_sequences=False),\n",
        "    Dense(6, activation='sigmoid')\n",
        "])\n",
        "model_cnn_lstm.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model_cnn_lstm.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "                   validation_data=(X_test, y_test), verbose=2, callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n",
        "\n",
        "# --- Attention ---\n",
        "seq_input = Input(shape=(seq_len, X_seq.shape[2]))\n",
        "x = LSTM(64, return_sequences=True)(seq_input)\n",
        "\n",
        "# Calculate attention scores\n",
        "attention_scores = Dense(1, activation='tanh')(x)  # (None, seq_len, 1)\n",
        "\n",
        "# Flatten and apply softmax to get attention weights for each time step\n",
        "attention_weights_flat = Flatten()(attention_scores) # (None, seq_len)\n",
        "attention_weights = Dense(seq_len, activation='softmax')(attention_weights_flat) # (None, seq_len)\n",
        "\n",
        "# Reshape attention_weights to (None, seq_len, 1) to enable broadcasting for multiplication with x\n",
        "attention_weights_expanded = Lambda(lambda z: K.expand_dims(z, axis=-1))(attention_weights) # Fixed: Used Lambda layer\n",
        "\n",
        "# Perform element-wise multiplication\n",
        "# x (None, seq_len, 64) * attention_weights_expanded (None, seq_len, 1) -> (None, seq_len, 64)\n",
        "weighted_output = Multiply()([x, attention_weights_expanded])\n",
        "\n",
        "# Flatten the weighted output for the final Dense layer\n",
        "x = Flatten()(weighted_output) # (None, seq_len * 64)\n",
        "\n",
        "output = Dense(6, activation='sigmoid')(x)\n",
        "model_attention = Model(seq_input, output)\n",
        "model_attention.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model_attention.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "                   validation_data=(X_test, y_test), verbose=2, callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n",
        "\n",
        "# --- AVALIA√á√ÉO PADR√ÉO PARA TODOS ---\n",
        "def avaliar(model, X_input, y_true_target, tipo='default'):\n",
        "    if tipo == 'mlp':\n",
        "        y_pred_norm = model.predict(X_input)\n",
        "    else:\n",
        "        y_pred_norm = model.predict(X_input)\n",
        "\n",
        "    n_total_features_for_inverse_transform = X.shape[1]\n",
        "\n",
        "    y_pred_full = np.hstack([y_pred_norm, np.zeros((y_pred_norm.shape[0], n_total_features_for_inverse_transform - 6))])\n",
        "    y_true_full = np.hstack([y_true_target, np.zeros((y_true_target.shape[0], n_total_features_for_inverse_transform - 6))])\n",
        "\n",
        "    y_pred = scaler.inverse_transform(y_pred_full)[:, :6]\n",
        "    y_true = scaler.inverse_transform(y_true_full)[:, :6]\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    pred_rounded = [[int(round(x)) for x in linha] for linha in y_pred]\n",
        "    true_int    = [[int(round(x)) for x in linha] for linha in y_true]\n",
        "    results = [len(set(pred) & set(true)) for pred, true in zip(pred_rounded, true_int)]\n",
        "    df_results = pd.DataFrame({'Real': true_int, 'Previsto': pred_rounded, 'Acertos': results})\n",
        "    print(df_results.head(10))\n",
        "    print(f'\\nMAE: {mae:.2f} | RMSE: {rmse:.2f}')\n",
        "    print(f'M√©dia de acertos: {np.mean(results):.2f}')\n",
        "    print(f'M√°ximo de acertos: {np.max(results)}')\n",
        "    print(f'Sorteios com 4+ acertos: {(np.array(results)>=4).sum()}')\n",
        "\n",
        "print('Resultados MLP:')\n",
        "avaliar(model_mlp, X_test_flat, y_test, tipo='mlp')\n",
        "print('\\nResultados CNN-LSTM:')\n",
        "avaliar(model_cnn_lstm, X_test, y_test)\n",
        "print('\\nResultados Attention:')\n",
        "avaliar(model_attention, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBcNYBiSNR9v",
        "outputId": "b5f22e9a-e8bf-478d-a835-8bb06c4d734b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "74/74 - 4s - 55ms/step - loss: 0.0377 - mae: 0.1555 - val_loss: 0.0335 - val_mae: 0.1471\n",
            "Epoch 2/100\n",
            "74/74 - 3s - 37ms/step - loss: 0.0335 - mae: 0.1466 - val_loss: 0.0334 - val_mae: 0.1465\n",
            "Epoch 3/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0333 - mae: 0.1463 - val_loss: 0.0334 - val_mae: 0.1464\n",
            "Epoch 4/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0332 - mae: 0.1460 - val_loss: 0.0334 - val_mae: 0.1462\n",
            "Epoch 5/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0331 - mae: 0.1457 - val_loss: 0.0334 - val_mae: 0.1462\n",
            "Epoch 6/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0330 - mae: 0.1455 - val_loss: 0.0334 - val_mae: 0.1460\n",
            "Epoch 7/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0329 - mae: 0.1454 - val_loss: 0.0334 - val_mae: 0.1462\n",
            "Epoch 8/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0328 - mae: 0.1451 - val_loss: 0.0334 - val_mae: 0.1460\n",
            "Epoch 9/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0327 - mae: 0.1449 - val_loss: 0.0335 - val_mae: 0.1461\n",
            "Epoch 10/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0326 - mae: 0.1448 - val_loss: 0.0334 - val_mae: 0.1460\n",
            "Epoch 11/100\n",
            "74/74 - 0s - 4ms/step - loss: 0.0326 - mae: 0.1446 - val_loss: 0.0334 - val_mae: 0.1458\n",
            "Epoch 12/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0325 - mae: 0.1445 - val_loss: 0.0334 - val_mae: 0.1459\n",
            "Epoch 13/100\n",
            "74/74 - 0s - 3ms/step - loss: 0.0324 - mae: 0.1442 - val_loss: 0.0334 - val_mae: 0.1458\n",
            "Epoch 14/100\n",
            "74/74 - 0s - 5ms/step - loss: 0.0323 - mae: 0.1440 - val_loss: 0.0334 - val_mae: 0.1457\n",
            "Epoch 15/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0322 - mae: 0.1438 - val_loss: 0.0335 - val_mae: 0.1460\n",
            "Epoch 16/100\n",
            "74/74 - 0s - 5ms/step - loss: 0.0321 - mae: 0.1435 - val_loss: 0.0335 - val_mae: 0.1459\n",
            "Epoch 1/100\n",
            "74/74 - 2s - 30ms/step - loss: 0.0395 - mae: 0.1608 - val_loss: 0.0329 - val_mae: 0.1457\n",
            "Epoch 2/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0331 - mae: 0.1461 - val_loss: 0.0328 - val_mae: 0.1453\n",
            "Epoch 3/100\n",
            "74/74 - 0s - 7ms/step - loss: 0.0331 - mae: 0.1459 - val_loss: 0.0328 - val_mae: 0.1453\n",
            "Epoch 4/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0331 - mae: 0.1459 - val_loss: 0.0328 - val_mae: 0.1453\n",
            "Epoch 5/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0330 - mae: 0.1458 - val_loss: 0.0328 - val_mae: 0.1453\n",
            "Epoch 6/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0330 - mae: 0.1458 - val_loss: 0.0328 - val_mae: 0.1453\n",
            "Epoch 7/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0330 - mae: 0.1457 - val_loss: 0.0328 - val_mae: 0.1452\n",
            "Epoch 8/100\n",
            "74/74 - 0s - 7ms/step - loss: 0.0330 - mae: 0.1457 - val_loss: 0.0328 - val_mae: 0.1452\n",
            "Epoch 9/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0330 - mae: 0.1456 - val_loss: 0.0328 - val_mae: 0.1452\n",
            "Epoch 10/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0329 - mae: 0.1456 - val_loss: 0.0328 - val_mae: 0.1452\n",
            "Epoch 11/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0329 - mae: 0.1455 - val_loss: 0.0328 - val_mae: 0.1453\n",
            "Epoch 12/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0329 - mae: 0.1454 - val_loss: 0.0328 - val_mae: 0.1453\n",
            "Epoch 13/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0328 - mae: 0.1454 - val_loss: 0.0329 - val_mae: 0.1454\n",
            "Epoch 14/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0328 - mae: 0.1453 - val_loss: 0.0329 - val_mae: 0.1454\n",
            "Epoch 15/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0327 - mae: 0.1451 - val_loss: 0.0329 - val_mae: 0.1455\n",
            "Epoch 16/100\n",
            "74/74 - 0s - 7ms/step - loss: 0.0327 - mae: 0.1450 - val_loss: 0.0329 - val_mae: 0.1455\n",
            "Epoch 17/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0326 - mae: 0.1449 - val_loss: 0.0330 - val_mae: 0.1456\n",
            "Epoch 18/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0326 - mae: 0.1448 - val_loss: 0.0330 - val_mae: 0.1455\n",
            "Epoch 19/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0325 - mae: 0.1447 - val_loss: 0.0330 - val_mae: 0.1456\n",
            "Epoch 1/100\n",
            "74/74 - 3s - 40ms/step - loss: 0.0418 - mae: 0.1664 - val_loss: 0.0331 - val_mae: 0.1442\n",
            "Epoch 2/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0331 - mae: 0.1460 - val_loss: 0.0329 - val_mae: 0.1441\n",
            "Epoch 3/100\n",
            "74/74 - 1s - 7ms/step - loss: 0.0331 - mae: 0.1459 - val_loss: 0.0329 - val_mae: 0.1440\n",
            "Epoch 4/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0331 - mae: 0.1459 - val_loss: 0.0328 - val_mae: 0.1443\n",
            "Epoch 5/100\n",
            "74/74 - 1s - 7ms/step - loss: 0.0331 - mae: 0.1459 - val_loss: 0.0327 - val_mae: 0.1451\n",
            "Epoch 6/100\n",
            "74/74 - 0s - 6ms/step - loss: 0.0331 - mae: 0.1459 - val_loss: 0.0327 - val_mae: 0.1453\n",
            "Epoch 7/100\n",
            "74/74 - 1s - 7ms/step - loss: 0.0331 - mae: 0.1459 - val_loss: 0.0327 - val_mae: 0.1454\n",
            "Epoch 8/100\n",
            "74/74 - 1s - 7ms/step - loss: 0.0331 - mae: 0.1458 - val_loss: 0.0327 - val_mae: 0.1454\n",
            "Epoch 9/100\n",
            "74/74 - 1s - 7ms/step - loss: 0.0331 - mae: 0.1458 - val_loss: 0.0327 - val_mae: 0.1454\n",
            "Epoch 10/100\n",
            "74/74 - 1s - 7ms/step - loss: 0.0330 - mae: 0.1458 - val_loss: 0.0327 - val_mae: 0.1455\n",
            "Epoch 11/100\n",
            "74/74 - 1s - 7ms/step - loss: 0.0330 - mae: 0.1458 - val_loss: 0.0327 - val_mae: 0.1455\n",
            "Epoch 12/100\n",
            "74/74 - 1s - 7ms/step - loss: 0.0330 - mae: 0.1458 - val_loss: 0.0327 - val_mae: 0.1455\n",
            "Epoch 13/100\n",
            "74/74 - 1s - 8ms/step - loss: 0.0330 - mae: 0.1458 - val_loss: 0.0327 - val_mae: 0.1455\n",
            "Epoch 14/100\n",
            "74/74 - 1s - 7ms/step - loss: 0.0330 - mae: 0.1457 - val_loss: 0.0327 - val_mae: 0.1455\n",
            "Epoch 15/100\n",
            "74/74 - 1s - 8ms/step - loss: 0.0330 - mae: 0.1457 - val_loss: 0.0327 - val_mae: 0.1455\n",
            "Resultados MLP:\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "                       Real                 Previsto  Acertos\n",
            "0   [3, 19, 34, 41, 48, 53]  [9, 17, 27, 33, 45, 52]        0\n",
            "1   [6, 18, 25, 30, 42, 54]  [9, 17, 28, 33, 44, 52]        0\n",
            "2   [7, 30, 31, 41, 50, 56]  [8, 17, 26, 33, 42, 52]        0\n",
            "3   [3, 10, 25, 36, 51, 58]  [9, 17, 27, 32, 43, 52]        0\n",
            "4  [19, 28, 30, 34, 40, 51]  [8, 17, 28, 32, 44, 53]        1\n",
            "5    [5, 9, 11, 16, 43, 57]  [8, 17, 27, 32, 44, 53]        0\n",
            "6  [31, 32, 39, 42, 43, 51]  [8, 17, 26, 34, 44, 53]        0\n",
            "7  [10, 15, 21, 24, 29, 45]  [8, 18, 28, 34, 45, 53]        1\n",
            "8  [14, 21, 22, 29, 35, 46]  [8, 17, 27, 35, 45, 53]        1\n",
            "9   [3, 20, 22, 32, 35, 50]  [8, 17, 27, 34, 45, 53]        0\n",
            "\n",
            "MAE: 7.00 | RMSE: 8.78\n",
            "M√©dia de acertos: 0.61\n",
            "M√°ximo de acertos: 3\n",
            "Sorteios com 4+ acertos: 0\n",
            "\n",
            "Resultados CNN-LSTM:\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "                       Real                 Previsto  Acertos\n",
            "0   [3, 19, 34, 41, 48, 53]  [9, 18, 26, 34, 43, 52]        1\n",
            "1   [6, 18, 25, 30, 42, 54]  [9, 18, 26, 34, 43, 52]        1\n",
            "2   [7, 30, 31, 41, 50, 56]  [9, 18, 26, 34, 43, 52]        0\n",
            "3   [3, 10, 25, 36, 51, 58]  [9, 18, 26, 34, 43, 52]        0\n",
            "4  [19, 28, 30, 34, 40, 51]  [9, 18, 26, 34, 43, 52]        1\n",
            "5    [5, 9, 11, 16, 43, 57]  [9, 18, 26, 34, 43, 52]        2\n",
            "6  [31, 32, 39, 42, 43, 51]  [9, 18, 27, 35, 44, 52]        0\n",
            "7  [10, 15, 21, 24, 29, 45]  [9, 18, 26, 34, 43, 52]        0\n",
            "8  [14, 21, 22, 29, 35, 46]  [9, 18, 27, 34, 43, 52]        0\n",
            "9   [3, 20, 22, 32, 35, 50]  [9, 18, 27, 35, 44, 52]        1\n",
            "\n",
            "MAE: 6.96 | RMSE: 8.70\n",
            "M√©dia de acertos: 0.65\n",
            "M√°ximo de acertos: 4\n",
            "Sorteios com 4+ acertos: 1\n",
            "\n",
            "Resultados Attention:\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "                       Real                 Previsto  Acertos\n",
            "0   [3, 19, 34, 41, 48, 53]  [9, 18, 26, 35, 43, 52]        0\n",
            "1   [6, 18, 25, 30, 42, 54]  [9, 18, 26, 35, 43, 52]        1\n",
            "2   [7, 30, 31, 41, 50, 56]  [9, 18, 26, 35, 44, 52]        0\n",
            "3   [3, 10, 25, 36, 51, 58]  [9, 18, 26, 35, 44, 52]        0\n",
            "4  [19, 28, 30, 34, 40, 51]  [9, 18, 26, 35, 44, 52]        0\n",
            "5    [5, 9, 11, 16, 43, 57]  [9, 17, 26, 35, 44, 52]        1\n",
            "6  [31, 32, 39, 42, 43, 51]  [9, 17, 26, 35, 44, 52]        0\n",
            "7  [10, 15, 21, 24, 29, 45]  [9, 18, 26, 35, 44, 52]        0\n",
            "8  [14, 21, 22, 29, 35, 46]  [9, 17, 26, 35, 44, 52]        1\n",
            "9   [3, 20, 22, 32, 35, 50]  [9, 18, 26, 35, 44, 52]        1\n",
            "\n",
            "MAE: 6.95 | RMSE: 8.69\n",
            "M√©dia de acertos: 0.59\n",
            "M√°ximo de acertos: 3\n",
            "Sorteios com 4+ acertos: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Carrega os dados reais hist√≥ricos\n",
        "df = pd.read_excel('Mega-Sena.xlsx')\n",
        "historico_sorteios = df[[f'Bola{i}' for i in range(1,7)]].values\n",
        "\n",
        "# Par√¢metros da Mega-Sena\n",
        "n_simulacoes = 100000\n",
        "numeros_possiveis = np.arange(1, 61)\n",
        "bolas_por_sorteio = 6\n",
        "\n",
        "# Simula√ß√£o de sorteios aleat√≥rios\n",
        "def simular_sorteios(n_sims, bolas, universo):\n",
        "    np.random.seed(42)\n",
        "    sorteios = [np.sort(np.random.choice(universo, bolas, replace=False)) for _ in range(n_sims)]\n",
        "    return np.array(sorteios)\n",
        "\n",
        "simulados = simular_sorteios(n_simulacoes, bolas_por_sorteio, numeros_possiveis)\n",
        "\n",
        "# Frequ√™ncia dos n√∫meros reais\n",
        "flat_real = historico_sorteios.flatten()\n",
        "freq_real = pd.Series(flat_real).value_counts().sort_index()\n",
        "\n",
        "# Frequ√™ncia dos n√∫meros simulados\n",
        "flat_mc = simulados.flatten()\n",
        "freq_mc = pd.Series(flat_mc).value_counts().sort_index()\n",
        "\n",
        "# Compara√ß√£o: tabela\n",
        "df_comp = pd.DataFrame({\n",
        "    'MegaSena_Reais': freq_real,\n",
        "    'MonteCarlo': freq_mc\n",
        "})\n",
        "print('--- Frequ√™ncia comparativa Mega-Sena vs Monte Carlo ---')\n",
        "print(df_comp)\n",
        "\n",
        "# An√°lise: Para cada sorteio real, quantos acertos teria se apostasse um jogo padr√£o\n",
        "meu_jogo = np.array([2, 14, 23, 32, 44, 51])\n",
        "acertos_reais = [len(set(sorteio) & set(meu_jogo)) for sorteio in historico_sorteios]\n",
        "freq_acertos_reais = pd.Series(acertos_reais).value_counts().sort_index()\n",
        "print('-- Frequ√™ncia de acertos em apostas reais --')\n",
        "print(freq_acertos_reais)\n",
        "\n",
        "# Simula√ß√£o em Monte Carlo\n",
        "acertos_mc = [len(set(sorteio) & set(meu_jogo)) for sorteio in simulados]\n",
        "freq_acertos_mc = pd.Series(acertos_mc).value_counts().sort_index()\n",
        "print('-- Frequ√™ncia de acertos em apostas simuladas --')\n",
        "print(freq_acertos_mc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxmuMGDLNirq",
        "outputId": "b4903667-0258-4734-e423-58cf437bcb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Frequ√™ncia comparativa Mega-Sena vs Monte Carlo ---\n",
            "    MegaSena_Reais  MonteCarlo\n",
            "1              285       10107\n",
            "2              294       10011\n",
            "3              272        9984\n",
            "4              311        9943\n",
            "5              320       10030\n",
            "6              292       10020\n",
            "7              274        9703\n",
            "8              289        9978\n",
            "9              279        9999\n",
            "10             343       10106\n",
            "11             310       10018\n",
            "12             278        9745\n",
            "13             302       10032\n",
            "14             286        9929\n",
            "15             262        9933\n",
            "16             305        9975\n",
            "17             311        9964\n",
            "18             281        9812\n",
            "19             287       10021\n",
            "20             287       10011\n",
            "21             244       10218\n",
            "22             262       10012\n",
            "23             307       10052\n",
            "24             294       10069\n",
            "25             293       10046\n",
            "26             243        9949\n",
            "27             311        9866\n",
            "28             303        9954\n",
            "29             293        9891\n",
            "30             308       10017\n",
            "31             273        9969\n",
            "32             312       10144\n",
            "33             314        9902\n",
            "34             320       10110\n",
            "35             309       10131\n",
            "36             298        9951\n",
            "37             317        9997\n",
            "38             315        9939\n",
            "39             280       10058\n",
            "40             277       10061\n",
            "41             305       10064\n",
            "42             309        9996\n",
            "43             308       10086\n",
            "44             308        9986\n",
            "45             287        9970\n",
            "46             308       10036\n",
            "47             280       10040\n",
            "48             274       10083\n",
            "49             297       10068\n",
            "50             289       10039\n",
            "51             299       10019\n",
            "52             297       10140\n",
            "53             334       10058\n",
            "54             306        9862\n",
            "55             255       10020\n",
            "56             310       10026\n",
            "57             283       10065\n",
            "58             280       10028\n",
            "59             284        9776\n",
            "60             280        9981\n",
            "-- Frequ√™ncia de acertos em apostas reais --\n",
            "0    1506\n",
            "1    1102\n",
            "2     293\n",
            "3      34\n",
            "4       4\n",
            "Name: count, dtype: int64\n",
            "-- Frequ√™ncia de acertos em apostas simuladas --\n",
            "0    51470\n",
            "1    38011\n",
            "2     9482\n",
            "3      983\n",
            "4       53\n",
            "5        1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Carrega dados reais\n",
        "df = pd.read_excel('Mega-Sena.xlsx')\n",
        "historico_sorteios = df[[f'Bola{i}' for i in range(1,7)]].values\n",
        "\n",
        "# Estat√≠stica dos n√∫meros mais frequentes no hist√≥rico real\n",
        "flat_real = historico_sorteios.flatten()\n",
        "top_6_freq = pd.Series(flat_real).value_counts().nlargest(6).index.tolist()\n",
        "print(f'Predi√ß√£o por frequ√™ncia: {top_6_freq}')\n",
        "\n",
        "# Simula√ß√£o Monte Carlo\n",
        "n_simulacoes = 100000\n",
        "numeros_possiveis = np.arange(1, 61)\n",
        "bolas_por_sorteio = 6\n",
        "\n",
        "def simular_sorteios(n_sims, bolas, universo):\n",
        "    np.random.seed(42)\n",
        "    sorteios = [np.sort(np.random.choice(universo, bolas, replace=False)) for _ in range(n_sims)]\n",
        "    return np.array(sorteios)\n",
        "\n",
        "simulados = simular_sorteios(n_simulacoes, bolas_por_sorteio, numeros_possiveis)\n",
        "\n",
        "# Teste da predi√ß√£o em simula√ß√µes\n",
        "acertos_mc_pred = [len(set(jogo) & set(top_6_freq)) for jogo in simulados]\n",
        "freq_acertos_mc_pred = pd.Series(acertos_mc_pred).value_counts().sort_index()\n",
        "print('-- Distribui√ß√£o de acertos da aposta preditiva (MC) --')\n",
        "print(freq_acertos_mc_pred)\n",
        "\n",
        "# Teste da predi√ß√£o nos concursos reais\n",
        "acertos_reais_pred = [len(set(sorteio) & set(top_6_freq)) for sorteio in historico_sorteios]\n",
        "freq_acertos_reais_pred = pd.Series(acertos_reais_pred).value_counts().sort_index()\n",
        "print('-- Distribui√ß√£o de acertos da aposta preditiva (Real) --')\n",
        "print(freq_acertos_reais_pred)\n",
        "\n",
        "# Mostra, para os dados reais, quantos sorteios tiveram 4, 5 ou 6 acertos com essa aposta\n",
        "print('Concursos reais com 4+:', (np.array(acertos_reais_pred) >= 4).sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c-XoRwkS59C",
        "outputId": "da387b67-acaf-45e8-e86c-c7d1eec93a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predi√ß√£o por frequ√™ncia: [10, 53, 34, 5, 37, 38]\n",
            "-- Distribui√ß√£o de acertos da aposta preditiva (MC) --\n",
            "0    51486\n",
            "1    37905\n",
            "2     9530\n",
            "3     1041\n",
            "4       38\n",
            "Name: count, dtype: int64\n",
            "-- Distribui√ß√£o de acertos da aposta preditiva (Real) --\n",
            "0    1417\n",
            "1    1147\n",
            "2     325\n",
            "3      48\n",
            "4       2\n",
            "Name: count, dtype: int64\n",
            "Concursos reais com 4+: 2\n"
          ]
        }
      ]
    }
  ]
}